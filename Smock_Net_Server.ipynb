{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import pandas as pd \n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from itertools import product\n",
    "import random\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "# data_root = \"C:\\\\Users\\\\Tigran PC\\\\Desktop\\\\MicrobiomicsData\\\\data\\\\\" # notebook\n",
    "# data_root = \"/Users/tigran/Desktop/sbv/data/\" # imac\n",
    "data_root = \"C:\\\\Users\\\\Administrator\\\\\" # istc pc\n",
    "\n",
    "sub_data_root = data_root + \"sample01split/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_lables(labels):\n",
    "    num_labels = len(np.unique(labels))\n",
    "    # Map 0 to [1.0, 0.0, 0.0 ...], 1 to [0.0, 1.0, 0.0 ...]\n",
    "    labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "    return labels\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1)) / predictions.shape[0])\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First reload the data we generated in Feature_Engineering.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (54997, 4097)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = data_root + \"DNA_data.pickle\"\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "    all_dataset = save.astype(np.float32)\n",
    "    del save  # hint to help gc free up memory\n",
    "    print('Training set', all_dataset.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:164: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:181: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (43997, 4096) (43997,)\n",
      "Validation set (5500, 4096) (5500,)\n",
      "Test set (5500, 4096) (5500,)\n"
     ]
    }
   ],
   "source": [
    "X = all_dataset.values[:, :-1]\n",
    "X = preprocessing.scale(X)\n",
    "y = all_dataset.values[:, -1]\n",
    "\n",
    "train_dataset, all_test_dataset, train_labels, all_test_labels = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "valid_dataset, test_dataset, valid_labels, test_labels =  train_test_split(all_test_dataset, all_test_labels, test_size=0.5)\n",
    "\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = reformat_lables(train_labels)\n",
    "valid_labels = reformat_lables(valid_labels)\n",
    "test_labels = reformat_lables(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (43997, 4096) (43997, 2)\n",
      "Validation set (5500, 4096) (5500, 2)\n",
      "Test set (5500, 4096) (5500, 2)\n"
     ]
    }
   ],
   "source": [
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial logistic regression using stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "features_size = train_dataset.shape[1]\n",
    "num_labels = train_labels.shape[1]\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, features_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "\n",
    "    # Variables.\n",
    "    weights = tf.Variable(tf.truncated_normal([features_size, num_labels]))\n",
    "    biases = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "    # Training computation.\n",
    "    logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits))\n",
    "    \n",
    "\n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction = tf.nn.softmax(tf.matmul(tf_valid_dataset, weights) + biases)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 29.339027\n",
      "Minibatch accuracy: 56.2%\n",
      "Validation accuracy: 53.7%\n",
      "Minibatch loss at step 500: 7.886947\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 86.9%\n",
      "Minibatch loss at step 1000: 7.281765\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.1%\n",
      "Minibatch loss at step 1500: 13.153898\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 87.9%\n",
      "Minibatch loss at step 2000: 4.650497\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 2500: 4.469972\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 3000: 13.210006\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 88.2%\n",
      "Test accuracy: 88.4%\n",
      "(5500, 2)\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "\n",
    "predictions = None\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "            # Pick an offset within the training data, which has been randomized.\n",
    "            # Note: we could use better randomization across epochs.\n",
    "            offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "            # Generate a minibatch.\n",
    "            batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "            batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "            # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "            # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "            # and the value is the numpy array to feed to it.\n",
    "            feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "            _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "            if (step % 500 == 0):\n",
    "                print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "                print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "                print(\"Validation accuracy: %.1f%%\" % accuracy(valid_prediction.eval(), valid_labels))\n",
    "    print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))\n",
    "    print(test_prediction.eval().shape)\n",
    "    predictions = test_prediction.eval()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8843636363636364\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2787,  321],\n",
       "       [ 315, 2077]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = np.argmax(predictions, 1) \n",
    "label = np.dot(test_labels, range(num_labels))\n",
    "print(accuracy_score(pred, label))\n",
    "confusion_matrix(pred, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[0.89845261 0.10154739]\n",
      " [0.13386155 0.86613845]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(confusion_matrix(label, pred), ['a','b'], normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-hidden layer neural network with rectified linear units nn.relu() and 1024 hidden nodes. using stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "features_size = train_dataset.shape[1]\n",
    "num_labels = train_labels.shape[1]\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, features_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    \n",
    "    # Variables.\n",
    "    hidden_layer_size = 1024\n",
    "    hidden_weights = tf.Variable(tf.truncated_normal([features_size, hidden_layer_size]))\n",
    "    hidden_biases = tf.Variable(tf.zeros([hidden_layer_size]))\n",
    "    \n",
    "    hidden_logits = tf.nn.relu(tf.matmul(tf_train_dataset, hidden_weights) + hidden_biases)\n",
    "\n",
    "    # Variables.\n",
    "    weights = tf.Variable(tf.truncated_normal([hidden_layer_size, num_labels]))\n",
    "    biases = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "    # Training computation.\n",
    "    logits = tf.matmul(hidden_logits, weights) + biases\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits))\n",
    "\n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    hidden_valid_weights = tf.nn.relu(tf.matmul(tf_valid_dataset, hidden_weights) + hidden_biases)\n",
    "    valid_prediction = tf.nn.softmax(tf.matmul(hidden_valid_weights, weights) + biases)\n",
    "    hidden_test_weights = tf.nn.relu(tf.matmul(tf_test_dataset, hidden_weights) + hidden_biases)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(hidden_test_weights, weights) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 648.910950\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 56.6%\n",
      "Minibatch loss at step 500: 28852178271368801056485028235575296.000000\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 66.9%\n",
      "Minibatch loss at step 1000: nan\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 56.6%\n",
      "Minibatch loss at step 1500: nan\n",
      "Minibatch accuracy: 46.9%\n",
      "Validation accuracy: 56.6%\n",
      "Minibatch loss at step 2000: nan\n",
      "Minibatch accuracy: 65.6%\n",
      "Validation accuracy: 56.6%\n",
      "Minibatch loss at step 2500: nan\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 56.6%\n",
      "Minibatch loss at step 3000: nan\n",
      "Minibatch accuracy: 53.1%\n",
      "Validation accuracy: 56.6%\n",
      "Test accuracy: 56.4%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "            # Pick an offset within the training data, which has been randomized.\n",
    "            # Note: we could use better randomization across epochs.\n",
    "            offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "            # Generate a minibatch.\n",
    "            batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "            batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "            # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "            # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "            # and the value is the numpy array to feed to it.\n",
    "            feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "            _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "            if (step % 500 == 0):\n",
    "                print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "                print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "                print(\"Validation accuracy: %.1f%%\" % accuracy(valid_prediction.eval(), valid_labels))\n",
    "    print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
