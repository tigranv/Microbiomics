{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Bio\n",
    "from Bio import SeqIO\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import pandas as pd \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from itertools import product\n",
    "import random\n",
    "from six.moves import cPickle as pickle\n",
    "import xgboost as xgb\n",
    "from Bio.SeqIO.FastaIO import SimpleFastaParser\n",
    "import gc\n",
    "\n",
    "\n",
    "# data_root = \"C:\\\\Users\\\\Tigran PC\\\\Desktop\\\\MicrobiomicsData\\\\data\\\\\" # notebook\n",
    "# data_root = \"/Users/tigran/Desktop/sbv/data/\" # imac\n",
    "data_root = \"C:\\\\Users\\\\Administrator\\\\Repos\\\\Microbiomics\\\\data\\\\\" # server\n",
    "\n",
    "sub_data_root = data_root + \"sample01split/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features(seq, sub_seq_bank, lable):\n",
    "    sub_seq_count = []\n",
    "    for sub_seq in sub_seq_bank:\n",
    "        sub_seq_count.append(seq.count(sub_seq))\n",
    "#         sub_seq_count.append(my_count(seq, sub_seq))\n",
    "    sub_seq_count.append(lable)\n",
    "    return sub_seq_count\n",
    "\n",
    "\n",
    "def make_sub_seq_bank(initial_string, sub_seq_len):\n",
    "    return [''.join(tup) for tup in  list(set(product(set(initial_string), repeat = sub_seq_len)))]\n",
    "\n",
    "def my_count(string, substring):\n",
    "    string_size = len(string)\n",
    "    substring_size = len(substring)\n",
    "    count = 0\n",
    "    for i in xrange(0,string_size-substring_size+1):\n",
    "        if string[i:i+substring_size] == substring:\n",
    "            count+=1\n",
    "    return count\n",
    "            \n",
    "    \n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap, aspect='auto')\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "def convert_read_to_numb(dataframe, sub_str_len):\n",
    "    ss_bank = make_sub_seq_bank(\"ATCG\", sub_str_len)\n",
    "    data_list = []\n",
    "    for i, val in enumerate(dataframe.values):        \n",
    "        tmp_counts = make_features(val[0], ss_bank, val[1])\n",
    "        data_list.append(tmp_counts)\n",
    "    return pd.DataFrame(data_list, columns=ss_bank.append(\"lable\"))\n",
    "    gc.collect()\n",
    "\n",
    "def make_data_frame(features, lable):\n",
    "    df = pd.DataFrame(features)\n",
    "    df['lable'] = lable    \n",
    "    return df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = pd.read_pickle(data_root + \"DNA_data1.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = pd.read_pickle(data_root + \"DNA_data2.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39341870, 2)\n",
      "(39389753, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>lable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TTACGACACCTGGTCGACGGTGTACAACCAGCTCGAGGGCACTTGG...</td>\n",
       "      <td>1768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GAACGGCCGCAGCTCGTCGATCACCCCGGTCAGCGCCCGCGTCTCC...</td>\n",
       "      <td>1751294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AGCCTATATTAAATTGCTACCGCCTGAAAAACGAGGAGCGGAGAAC...</td>\n",
       "      <td>189834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TGGTATTTCTCTGTATCAAAATTGGCGTTTTGATAATAATACGGGA...</td>\n",
       "      <td>1954172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GTAAAGGTCAGTACGGCCACGTGGTCTTCACGCTCGAACCATTGCC...</td>\n",
       "      <td>741091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0    lable\n",
       "0  TTACGACACCTGGTCGACGGTGTACAACCAGCTCGAGGGCACTTGG...     1768\n",
       "1  GAACGGCCGCAGCTCGTCGATCACCCCGGTCAGCGCCCGCGTCTCC...  1751294\n",
       "2  AGCCTATATTAAATTGCTACCGCCTGAAAAACGAGGAGCGGAGAAC...   189834\n",
       "3  TGGTATTTCTCTGTATCAAAATTGGCGTTTTGATAATAATACGGGA...  1954172\n",
       "4  GTAAAGGTCAGTACGGCCACGTGGTCTTCACGCTCGAACCATTGCC...   741091"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df1.shape)\n",
    "print(df2.shape)\n",
    "df = pd.concat([df1, df2]) \n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78731623, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_root + 'taxid.txt') as f:\n",
    "    keys = f.readlines()\n",
    "keys = [x.strip() for x in keys] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_values = keys[:10]\n",
    "df1 = df.loc[df['lable'].isin(some_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>lable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>GGATGATTGGCACGTCTCGCCGCAGTACGTACGTCAGGCCTCAACG...</td>\n",
       "      <td>1004901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>GTCCTGGCAAATCGATTTGGGTAGCGTCACCATTTACAATCATTTT...</td>\n",
       "      <td>1007676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>GAACGCCTCGAACCCCGCCTCGCAGCGACCGCGACGGCGGTCGCGG...</td>\n",
       "      <td>1004901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>ATATAAATAGGAAAATAAGGCACTATTTCACGAGCGGCATAATAGC...</td>\n",
       "      <td>1019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1815</th>\n",
       "      <td>TTGCTGAAACAATTCAACCCTTCAATAACTGTTGTTTTCACCATTT...</td>\n",
       "      <td>1019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1872</th>\n",
       "      <td>GTGAGGGGGTACAAACTAATAGCATAACCCCCGCCTGCTACTGAGT...</td>\n",
       "      <td>1019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2215</th>\n",
       "      <td>ACTATCAACACCGAGAGTCCTGCTTGGGCAGTGGATAGACTTTCGA...</td>\n",
       "      <td>1019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2249</th>\n",
       "      <td>CAGAAATAGCTCCAAAATCAAAGGCTAAAGCCGAACGAATCCCCTT...</td>\n",
       "      <td>1017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2910</th>\n",
       "      <td>GGTTCCCACAAGCGTTTGAGCTCTAATACTTCAGATGATTTTTTTT...</td>\n",
       "      <td>1019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3392</th>\n",
       "      <td>CCACTTGGTCGGAGTGAACATCAGGAACAGCAGTGACGCGAAGGTG...</td>\n",
       "      <td>1004901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0    lable\n",
       "827   GGATGATTGGCACGTCTCGCCGCAGTACGTACGTCAGGCCTCAACG...  1004901\n",
       "1037  GTCCTGGCAAATCGATTTGGGTAGCGTCACCATTTACAATCATTTT...  1007676\n",
       "1251  GAACGCCTCGAACCCCGCCTCGCAGCGACCGCGACGGCGGTCGCGG...  1004901\n",
       "1572  ATATAAATAGGAAAATAAGGCACTATTTCACGAGCGGCATAATAGC...     1019\n",
       "1815  TTGCTGAAACAATTCAACCCTTCAATAACTGTTGTTTTCACCATTT...     1019\n",
       "1872  GTGAGGGGGTACAAACTAATAGCATAACCCCCGCCTGCTACTGAGT...     1019\n",
       "2215  ACTATCAACACCGAGAGTCCTGCTTGGGCAGTGGATAGACTTTCGA...     1019\n",
       "2249  CAGAAATAGCTCCAAAATCAAAGGCTAAAGCCGAACGAATCCCCTT...     1017\n",
       "2910  GGTTCCCACAAGCGTTTGAGCTCTAATACTTCAGATGATTTTTTTT...     1019\n",
       "3392  CCACTTGGTCGGAGTGAACATCAGGAACAGCAGTGACGCGAAGGTG...  1004901"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(214419, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 8s\n"
     ]
    }
   ],
   "source": [
    "%time df1 =  convert_read_to_numb(df1, 4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "      <th>256</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1004901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1007676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1004901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1004901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 257 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9     ...     247  248  249  \\\n",
       "0    0    0    1    0    4    0    0    0    0    0   ...       0    0    0   \n",
       "1    0    0    1    1    0    0    0    0    1    4   ...       4    1    0   \n",
       "2    0    0    0    2    1    1    1    0    0    0   ...       1    0    0   \n",
       "3    1    4    2    2    0    1    0    1    0    2   ...       3    1    2   \n",
       "4    1    1    0    0    0    1    1    0    1    2   ...       2    0    0   \n",
       "5    0    3    2    0    0    0    1    2    1    3   ...       1    1    0   \n",
       "6    1    1    1    0    1    0    0    0    2    0   ...       0    1    0   \n",
       "7    2    1    0    0    0    3    2    0    0    1   ...       3    1    0   \n",
       "8    1    1    0    2    1    3    1    0    0    2   ...       0    1    1   \n",
       "9    0    0    0    1    1    0    0    0    1    0   ...       0    0    0   \n",
       "\n",
       "   250  251  252  253  254  255      256  \n",
       "0    0    1    0    2    3    1  1004901  \n",
       "1    0    0    0    2    0    0  1007676  \n",
       "2    1    0    0    0    0    0  1004901  \n",
       "3    0    0    0    0    0    0     1019  \n",
       "4    0    0    1    0    0    0     1019  \n",
       "5    0    0    2    0    1    0     1019  \n",
       "6    3    1    2    0    0    0     1019  \n",
       "7    0    1    0    0    0    0     1017  \n",
       "8    0    0    0    1    1    0     1019  \n",
       "9    1    2    0    0    1    1  1004901  \n",
       "\n",
       "[10 rows x 257 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "(214419, 257)\n",
      "(214409, 257)\n"
     ]
    }
   ],
   "source": [
    "columns = list(df1.columns.values)\n",
    "print(type(columns))\n",
    "df1 = df1.sample(frac=1).reset_index(drop=True)\n",
    "print(df1.shape)\n",
    "df1 = df1.drop_duplicates(subset=columns[:-1])\n",
    "print(df1.shape)\n",
    "\n",
    "# df.to_csv(data_root + \"DNA_data.csv\")\n",
    "\n",
    "\n",
    "# df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1.values[:, :-1]\n",
    "y = df1.values[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "X_scaled = preprocessing.scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle_file = data_root + \"DNA_data.pickle\"\n",
    "\n",
    "# try:   \n",
    "#     f = open(pickle_file, 'wb')\n",
    "#     pickle.dump(df1, f, pickle.HIGHEST_PROTOCOL)\n",
    "#     f.close()\n",
    "# except Exception as e:\n",
    "#     print('Unable to save data to', pickle_file, ':', e)\n",
    "#     raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %time gbm = xgb.XGBClassifier(max_depth=4, n_estimators=100, learning_rate=0.5, n_jobs=32).fit(x_train, y_train)\n",
    "# print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %time y_pred = gbm.predict(x_test)\n",
    "# print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_confusion_matrix(confusion_matrix(y_test, y_pred), ['a','b'], normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = OneVsRestClassifier(SVC(kernel='linear', probability=True, class_weight='None'))\n",
    "# %time clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %time y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_confusion_matrix(confusion_matrix(y_test, y_pred), ['a','b'], normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_estimators = 10\n",
    "# clf = OneVsRestClassifier(BaggingClassifier(SVC(kernel='linear', probability=True), max_samples=1.0 /\n",
    "#                                             n_estimators, n_estimators=n_estimators, n_jobs=16), n_jobs=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %time clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %time y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_confusion_matrix(confusion_matrix(y_test, y_pred), ['a','b'], normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(min_samples_leaf=2, n_jobs = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.39 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=2, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=32,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 208 ms\n"
     ]
    }
   ],
   "source": [
    "%time y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6550767221678093"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 421,    0,  238,   10,  177,   29,  420,    0,   56,  319],\n",
       "       [   0, 4621,    0,  166,    2,    0,    7,  536,    3,    4],\n",
       "       [ 149,    3,  922,   22,  213,   53,  565,    1,  132,  636],\n",
       "       [   2,  130,    5, 4198,   38,    0,  244,  308,   38,  129],\n",
       "       [  78,    5,  171,   81, 1450,   30,  992,    0,  115,  573],\n",
       "       [  76,    0,  199,    4,  117,  205,  246,    0,   61,  348],\n",
       "       [ 104,    5,  260,  292,  419,   36, 4055,   10,  277,  850],\n",
       "       [   0,  630,    1,  547,   16,    0,   52, 4142,    8,   39],\n",
       "       [  44,    2,  135,  154,  116,   11,  623,    3, 1428, 1252],\n",
       "       [  54,    1,  194,   79,  139,   20,  378,    8,  301, 6649]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(confusion_matrix(y_test, y_pred), some_values, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "ename": "JoblibMemoryError",
     "evalue": "JoblibMemoryError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x0000018D63144F60, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\ProgramD...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x0000018D63144F60, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\ProgramD...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    122         except (RuntimeError, AssertionError):\n    123             old_loop = None\n    124         try:\n    125             self._setup_logging()\n    126             asyncio.set_event_loop(self.asyncio_loop)\n--> 127             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Win...EventLoop running=True closed=False debug=False>>\n    128         finally:\n    129             asyncio.set_event_loop(old_loop)\n    130 \n    131     def stop(self):\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py in run_forever(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n    417             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    418                                    finalizer=self._asyncgen_finalizer_hook)\n    419         try:\n    420             events._set_running_loop(self)\n    421             while True:\n--> 422                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_Windo...EventLoop running=True closed=False debug=False>>\n    423                 if self._stopping:\n    424                     break\n    425         finally:\n    426             self._stopping = False\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py in _run_once(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n   1427                         logger.warning('Executing %s took %.3f seconds',\n   1428                                        _format_handle(handle), dt)\n   1429                 finally:\n   1430                     self._current_handle = None\n   1431             else:\n-> 1432                 handle._run()\n        handle._run = <bound method Handle._run of <Handle BaseAsyncIOLoop._handle_events(616, 1)>>\n   1433         handle = None  # Needed to break cycles when an exception occurs.\n   1434 \n   1435     def _set_coroutine_wrapper(self, enabled):\n   1436         try:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\asyncio\\events.py in _run(self=<Handle BaseAsyncIOLoop._handle_events(616, 1)>)\n    140             self._callback = None\n    141             self._args = None\n    142 \n    143     def _run(self):\n    144         try:\n--> 145             self._callback(*self._args)\n        self._callback = <bound method BaseAsyncIOLoop._handle_events of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (616, 1)\n    146         except Exception as exc:\n    147             cb = _format_callback_source(self._callback, self._args)\n    148             msg = 'Exception in callback {}'.format(cb)\n    149             context = {\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in _handle_events(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, fd=616, events=1)\n    112             self.writers.remove(fd)\n    113         del self.handlers[fd]\n    114 \n    115     def _handle_events(self, fd, events):\n    116         fileobj, handler_func = self.handlers[fd]\n--> 117         handler_func(fileobj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fileobj = <zmq.sugar.socket.Socket object>\n        events = 1\n    118 \n    119     def start(self):\n    120         try:\n    121             old_loop = asyncio.get_event_loop()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': '# Use the random grid to search for best hyperpa...earch model\\n%time rf_random.fit(x_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 6, 12, 19, 16, 2, 206172, tzinfo=tzutc()), 'msg_id': '8c68f77a9eaa4ab8809daecedaed75ad', 'msg_type': 'execute_request', 'session': '80fbe17cc4434eb688e083bb3a3ea874', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '8c68f77a9eaa4ab8809daecedaed75ad', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'80fbe17cc4434eb688e083bb3a3ea874']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': '# Use the random grid to search for best hyperpa...earch model\\n%time rf_random.fit(x_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 6, 12, 19, 16, 2, 206172, tzinfo=tzutc()), 'msg_id': '8c68f77a9eaa4ab8809daecedaed75ad', 'msg_type': 'execute_request', 'session': '80fbe17cc4434eb688e083bb3a3ea874', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '8c68f77a9eaa4ab8809daecedaed75ad', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'80fbe17cc4434eb688e083bb3a3ea874'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': '# Use the random grid to search for best hyperpa...earch model\\n%time rf_random.fit(x_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 6, 12, 19, 16, 2, 206172, tzinfo=tzutc()), 'msg_id': '8c68f77a9eaa4ab8809daecedaed75ad', 'msg_type': 'execute_request', 'session': '80fbe17cc4434eb688e083bb3a3ea874', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '8c68f77a9eaa4ab8809daecedaed75ad', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='# Use the random grid to search for best hyperpa...earch model\\n%time rf_random.fit(x_train, y_train)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = '# Use the random grid to search for best hyperpa...earch model\\n%time rf_random.fit(x_train, y_train)'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('# Use the random grid to search for best hyperpa...earch model\\n%time rf_random.fit(x_train, y_train)',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('# Use the random grid to search for best hyperpa...earch model\\n%time rf_random.fit(x_train, y_train)',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='# Use the random grid to search for best hyperpa...earch model\\n%time rf_random.fit(x_train, y_train)', store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = '# Use the random grid to search for best hyperpa...earch model\\n%time rf_random.fit(x_train, y_train)'\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='# Use the random grid to search for best hyperpa...earch model\\n%time rf_random.fit(x_train, y_train)', store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-77-8187a86681d1>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 18ff785d4a8, executio...rue silent=False shell_futures=True> result=None>)\n   2904                     return True\n   2905 \n   2906             for i, node in enumerate(to_run_interactive):\n   2907                 mod = ast.Interactive([node])\n   2908                 code = compiler(mod, cell_name, \"single\")\n-> 2909                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x0000018F76905B70, file \"<ipython-input-77-8187a86681d1>\", line 8>\n        result = <ExecutionResult object at 18ff785d4a8, executio...rue silent=False shell_futures=True> result=None>\n   2910                     return True\n   2911 \n   2912             # Flush softspace\n   2913             if softspace(sys.stdout, 0):\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x0000018F76905B70, file \"<ipython-input-77-8187a86681d1>\", line 8>, result=<ExecutionResult object at 18ff785d4a8, executio...rue silent=False shell_futures=True> result=None>)\n   2958         outflag = True  # happens in more places, so it's easier as default\n   2959         try:\n   2960             try:\n   2961                 self.hooks.pre_run_code_hook()\n   2962                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2963                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x0000018F76905B70, file \"<ipython-input-77-8187a86681d1>\", line 8>\n        self.user_global_ns = {'BaggingClassifier': <class 'sklearn.ensemble.bagging.BaggingClassifier'>, 'Bio': <module 'Bio' from 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\Bio\\\\__init__.py'>, 'Evaluator': <class 'mlens.model_selection.model_selection.Evaluator'>, 'In': ['', 'import Bio\\nfrom Bio import SeqIO\\nimport numpy as...ver\\n\\nsub_data_root = data_root + \"sample01split/\"', \"def make_features(seq, sub_seq_bank, lable):\\n   ...s)\\n    df['lable'] = lable    \\n    return df\\n    \", 'df1 = pd.read_pickle(data_root + \"DNA_data1.pickle\")', 'df2 = pd.read_pickle(data_root + \"DNA_data2.pickle\")', 'print(df1.shape)\\nprint(df2.shape)\\ndf = pd.concat([df1, df2]) \\n\\ndf.head()', 'df.shape', \"with open(data_root + 'taxid.txt') as f:\\n    keys = f.readlines()\\nkeys = [x.strip() for x in keys] \", \"some_values = keys[:10]\\ndf1 = df.loc[df['lable'].isin(some_values)]\", 'df1.head(10)', 'gc.collect()\\ndf1.shape', \"get_ipython().run_line_magic('time', 'df1 =  convert_read_to_numb(df1, 4)')\", 'df1.head(10)', 'columns = list(df1.columns.values)\\nprint(type(co...alues[:, :-1]\\ny = df1.values[:, -1]\\n# df.head(20)', '# pickle_file = data_root + \"DNA_data.pickle\"\\n\\n#...o save data to\\', pickle_file, \\':\\', e)\\n#     raise', 'x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)', '# %time gbm = xgb.XGBClassifier(max_depth=4, n_e... n_jobs=32).fit(x_train, y_train)\\n# print(\"done\")', '# %time y_pred = gbm.predict(x_test)\\n# print(\"done\")', '# accuracy_score(y_test, y_pred)', \"# plot_confusion_matrix(confusion_matrix(y_test, y_pred), ['a','b'], normalize=True)\", ...], 'LGBMClassifier': <class 'lightgbm.sklearn.LGBMClassifier'>, 'OneVsRestClassifier': <class 'sklearn.multiclass.OneVsRestClassifier'>, 'Out': {5:                                                 ...AGTACGGCCACGTGGTCTTCACGCTCGAACCATTGCC...   741091, 6: (78731623, 2), 9:                                                 ...CGGAGTGAACATCAGGAACAGCAGTGACGCGAAGGTG...  1004901, 10: (214419, 2), 12:    0    1    2    3    4    5    6    7    8    ...  0    1    1  1004901  \n\n[10 rows x 257 columns], 35: RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), 37: 0.6566624691012546, 38: array([[ 447,    0,  235,    8,  159,   39,  441... 20,  396,    6,  277, 6681]],\n      dtype=int64), 60: RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), 62: 0.6550767221678093, ...}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'RandomizedSearchCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, 'SVC': <class 'sklearn.svm.classes.SVC'>, ...}\n        self.user_ns = {'BaggingClassifier': <class 'sklearn.ensemble.bagging.BaggingClassifier'>, 'Bio': <module 'Bio' from 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\Bio\\\\__init__.py'>, 'Evaluator': <class 'mlens.model_selection.model_selection.Evaluator'>, 'In': ['', 'import Bio\\nfrom Bio import SeqIO\\nimport numpy as...ver\\n\\nsub_data_root = data_root + \"sample01split/\"', \"def make_features(seq, sub_seq_bank, lable):\\n   ...s)\\n    df['lable'] = lable    \\n    return df\\n    \", 'df1 = pd.read_pickle(data_root + \"DNA_data1.pickle\")', 'df2 = pd.read_pickle(data_root + \"DNA_data2.pickle\")', 'print(df1.shape)\\nprint(df2.shape)\\ndf = pd.concat([df1, df2]) \\n\\ndf.head()', 'df.shape', \"with open(data_root + 'taxid.txt') as f:\\n    keys = f.readlines()\\nkeys = [x.strip() for x in keys] \", \"some_values = keys[:10]\\ndf1 = df.loc[df['lable'].isin(some_values)]\", 'df1.head(10)', 'gc.collect()\\ndf1.shape', \"get_ipython().run_line_magic('time', 'df1 =  convert_read_to_numb(df1, 4)')\", 'df1.head(10)', 'columns = list(df1.columns.values)\\nprint(type(co...alues[:, :-1]\\ny = df1.values[:, -1]\\n# df.head(20)', '# pickle_file = data_root + \"DNA_data.pickle\"\\n\\n#...o save data to\\', pickle_file, \\':\\', e)\\n#     raise', 'x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)', '# %time gbm = xgb.XGBClassifier(max_depth=4, n_e... n_jobs=32).fit(x_train, y_train)\\n# print(\"done\")', '# %time y_pred = gbm.predict(x_test)\\n# print(\"done\")', '# accuracy_score(y_test, y_pred)', \"# plot_confusion_matrix(confusion_matrix(y_test, y_pred), ['a','b'], normalize=True)\", ...], 'LGBMClassifier': <class 'lightgbm.sklearn.LGBMClassifier'>, 'OneVsRestClassifier': <class 'sklearn.multiclass.OneVsRestClassifier'>, 'Out': {5:                                                 ...AGTACGGCCACGTGGTCTTCACGCTCGAACCATTGCC...   741091, 6: (78731623, 2), 9:                                                 ...CGGAGTGAACATCAGGAACAGCAGTGACGCGAAGGTG...  1004901, 10: (214419, 2), 12:    0    1    2    3    4    5    6    7    8    ...  0    1    1  1004901  \n\n[10 rows x 257 columns], 35: RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), 37: 0.6566624691012546, 38: array([[ 447,    0,  235,    8,  159,   39,  441... 20,  396,    6,  277, 6681]],\n      dtype=int64), 60: RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), 62: 0.6550767221678093, ...}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'RandomizedSearchCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, 'SVC': <class 'sklearn.svm.classes.SVC'>, ...}\n   2964             finally:\n   2965                 # Reset our crash handler in place\n   2966                 sys.excepthook = old_excepthook\n   2967         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\Administrator\\Repos\\Microbiomics\\<ipython-input-77-8187a86681d1> in <module>()\n      3 rf = RandomForestClassifier()\n      4 # Random search of parameters, using 3 fold cross validation, \n      5 # search across 100 different combinations, and use all available cores\n      6 rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n      7 # Fit the random search model\n----> 8 get_ipython().run_line_magic('time', 'rf_random.fit(x_train, y_train)')\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_line_magic(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, magic_name='time', line='rf_random.fit(x_train, y_train)', _stack_depth=1)\n   2126             kwargs = {}\n   2127             # Grab local namespace if we need it:\n   2128             if getattr(fn, \"needs_local_scope\", False):\n   2129                 kwargs['local_ns'] = sys._getframe(stack_depth).f_locals\n   2130             with self.builtin_trap:\n-> 2131                 result = fn(*args,**kwargs)\n        result = undefined\n        fn = <bound method ExecutionMagics.time of <IPython.core.magics.execution.ExecutionMagics object>>\n        args = ['rf_random.fit(x_train, y_train)']\n        kwargs = {'local_ns': {'BaggingClassifier': <class 'sklearn.ensemble.bagging.BaggingClassifier'>, 'Bio': <module 'Bio' from 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\Bio\\\\__init__.py'>, 'Evaluator': <class 'mlens.model_selection.model_selection.Evaluator'>, 'In': ['', 'import Bio\\nfrom Bio import SeqIO\\nimport numpy as...ver\\n\\nsub_data_root = data_root + \"sample01split/\"', \"def make_features(seq, sub_seq_bank, lable):\\n   ...s)\\n    df['lable'] = lable    \\n    return df\\n    \", 'df1 = pd.read_pickle(data_root + \"DNA_data1.pickle\")', 'df2 = pd.read_pickle(data_root + \"DNA_data2.pickle\")', 'print(df1.shape)\\nprint(df2.shape)\\ndf = pd.concat([df1, df2]) \\n\\ndf.head()', 'df.shape', \"with open(data_root + 'taxid.txt') as f:\\n    keys = f.readlines()\\nkeys = [x.strip() for x in keys] \", \"some_values = keys[:10]\\ndf1 = df.loc[df['lable'].isin(some_values)]\", 'df1.head(10)', 'gc.collect()\\ndf1.shape', \"get_ipython().run_line_magic('time', 'df1 =  convert_read_to_numb(df1, 4)')\", 'df1.head(10)', 'columns = list(df1.columns.values)\\nprint(type(co...alues[:, :-1]\\ny = df1.values[:, -1]\\n# df.head(20)', '# pickle_file = data_root + \"DNA_data.pickle\"\\n\\n#...o save data to\\', pickle_file, \\':\\', e)\\n#     raise', 'x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)', '# %time gbm = xgb.XGBClassifier(max_depth=4, n_e... n_jobs=32).fit(x_train, y_train)\\n# print(\"done\")', '# %time y_pred = gbm.predict(x_test)\\n# print(\"done\")', '# accuracy_score(y_test, y_pred)', \"# plot_confusion_matrix(confusion_matrix(y_test, y_pred), ['a','b'], normalize=True)\", ...], 'LGBMClassifier': <class 'lightgbm.sklearn.LGBMClassifier'>, 'OneVsRestClassifier': <class 'sklearn.multiclass.OneVsRestClassifier'>, 'Out': {5:                                                 ...AGTACGGCCACGTGGTCTTCACGCTCGAACCATTGCC...   741091, 6: (78731623, 2), 9:                                                 ...CGGAGTGAACATCAGGAACAGCAGTGACGCGAAGGTG...  1004901, 10: (214419, 2), 12:    0    1    2    3    4    5    6    7    8    ...  0    1    1  1004901  \n\n[10 rows x 257 columns], 35: RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), 37: 0.6566624691012546, 38: array([[ 447,    0,  235,    8,  159,   39,  441... 20,  396,    6,  277, 6681]],\n      dtype=int64), 60: RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), 62: 0.6550767221678093, ...}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'RandomizedSearchCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, 'SVC': <class 'sklearn.svm.classes.SVC'>, ...}}\n   2132             return result\n   2133 \n   2134     def run_cell_magic(self, magic_name, line, cell):\n   2135         \"\"\"Execute the given cell magic.\n\n...........................................................................\nC:\\Users\\Administrator\\Repos\\Microbiomics\\<decorator-gen-63> in time(self=<IPython.core.magics.execution.ExecutionMagics object>, line='rf_random.fit(x_train, y_train)', cell=None, local_ns={'BaggingClassifier': <class 'sklearn.ensemble.bagging.BaggingClassifier'>, 'Bio': <module 'Bio' from 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\Bio\\\\__init__.py'>, 'Evaluator': <class 'mlens.model_selection.model_selection.Evaluator'>, 'In': ['', 'import Bio\\nfrom Bio import SeqIO\\nimport numpy as...ver\\n\\nsub_data_root = data_root + \"sample01split/\"', \"def make_features(seq, sub_seq_bank, lable):\\n   ...s)\\n    df['lable'] = lable    \\n    return df\\n    \", 'df1 = pd.read_pickle(data_root + \"DNA_data1.pickle\")', 'df2 = pd.read_pickle(data_root + \"DNA_data2.pickle\")', 'print(df1.shape)\\nprint(df2.shape)\\ndf = pd.concat([df1, df2]) \\n\\ndf.head()', 'df.shape', \"with open(data_root + 'taxid.txt') as f:\\n    keys = f.readlines()\\nkeys = [x.strip() for x in keys] \", \"some_values = keys[:10]\\ndf1 = df.loc[df['lable'].isin(some_values)]\", 'df1.head(10)', 'gc.collect()\\ndf1.shape', \"get_ipython().run_line_magic('time', 'df1 =  convert_read_to_numb(df1, 4)')\", 'df1.head(10)', 'columns = list(df1.columns.values)\\nprint(type(co...alues[:, :-1]\\ny = df1.values[:, -1]\\n# df.head(20)', '# pickle_file = data_root + \"DNA_data.pickle\"\\n\\n#...o save data to\\', pickle_file, \\':\\', e)\\n#     raise', 'x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)', '# %time gbm = xgb.XGBClassifier(max_depth=4, n_e... n_jobs=32).fit(x_train, y_train)\\n# print(\"done\")', '# %time y_pred = gbm.predict(x_test)\\n# print(\"done\")', '# accuracy_score(y_test, y_pred)', \"# plot_confusion_matrix(confusion_matrix(y_test, y_pred), ['a','b'], normalize=True)\", ...], 'LGBMClassifier': <class 'lightgbm.sklearn.LGBMClassifier'>, 'OneVsRestClassifier': <class 'sklearn.multiclass.OneVsRestClassifier'>, 'Out': {5:                                                 ...AGTACGGCCACGTGGTCTTCACGCTCGAACCATTGCC...   741091, 6: (78731623, 2), 9:                                                 ...CGGAGTGAACATCAGGAACAGCAGTGACGCGAAGGTG...  1004901, 10: (214419, 2), 12:    0    1    2    3    4    5    6    7    8    ...  0    1    1  1004901  \n\n[10 rows x 257 columns], 35: RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), 37: 0.6566624691012546, 38: array([[ 447,    0,  235,    8,  159,   39,  441... 20,  396,    6,  277, 6681]],\n      dtype=int64), 60: RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), 62: 0.6550767221678093, ...}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'RandomizedSearchCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, 'SVC': <class 'sklearn.svm.classes.SVC'>, ...})\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\magic.py in <lambda>(f=<function ExecutionMagics.time>, *a=(<IPython.core.magics.execution.ExecutionMagics object>, 'rf_random.fit(x_train, y_train)', None, {'BaggingClassifier': <class 'sklearn.ensemble.bagging.BaggingClassifier'>, 'Bio': <module 'Bio' from 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\Bio\\\\__init__.py'>, 'Evaluator': <class 'mlens.model_selection.model_selection.Evaluator'>, 'In': ['', 'import Bio\\nfrom Bio import SeqIO\\nimport numpy as...ver\\n\\nsub_data_root = data_root + \"sample01split/\"', \"def make_features(seq, sub_seq_bank, lable):\\n   ...s)\\n    df['lable'] = lable    \\n    return df\\n    \", 'df1 = pd.read_pickle(data_root + \"DNA_data1.pickle\")', 'df2 = pd.read_pickle(data_root + \"DNA_data2.pickle\")', 'print(df1.shape)\\nprint(df2.shape)\\ndf = pd.concat([df1, df2]) \\n\\ndf.head()', 'df.shape', \"with open(data_root + 'taxid.txt') as f:\\n    keys = f.readlines()\\nkeys = [x.strip() for x in keys] \", \"some_values = keys[:10]\\ndf1 = df.loc[df['lable'].isin(some_values)]\", 'df1.head(10)', 'gc.collect()\\ndf1.shape', \"get_ipython().run_line_magic('time', 'df1 =  convert_read_to_numb(df1, 4)')\", 'df1.head(10)', 'columns = list(df1.columns.values)\\nprint(type(co...alues[:, :-1]\\ny = df1.values[:, -1]\\n# df.head(20)', '# pickle_file = data_root + \"DNA_data.pickle\"\\n\\n#...o save data to\\', pickle_file, \\':\\', e)\\n#     raise', 'x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)', '# %time gbm = xgb.XGBClassifier(max_depth=4, n_e... n_jobs=32).fit(x_train, y_train)\\n# print(\"done\")', '# %time y_pred = gbm.predict(x_test)\\n# print(\"done\")', '# accuracy_score(y_test, y_pred)', \"# plot_confusion_matrix(confusion_matrix(y_test, y_pred), ['a','b'], normalize=True)\", ...], 'LGBMClassifier': <class 'lightgbm.sklearn.LGBMClassifier'>, 'OneVsRestClassifier': <class 'sklearn.multiclass.OneVsRestClassifier'>, 'Out': {5:                                                 ...AGTACGGCCACGTGGTCTTCACGCTCGAACCATTGCC...   741091, 6: (78731623, 2), 9:                                                 ...CGGAGTGAACATCAGGAACAGCAGTGACGCGAAGGTG...  1004901, 10: (214419, 2), 12:    0    1    2    3    4    5    6    7    8    ...  0    1    1  1004901  \n\n[10 rows x 257 columns], 35: RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), 37: 0.6566624691012546, 38: array([[ 447,    0,  235,    8,  159,   39,  441... 20,  396,    6,  277, 6681]],\n      dtype=int64), 60: RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), 62: 0.6550767221678093, ...}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'RandomizedSearchCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, 'SVC': <class 'sklearn.svm.classes.SVC'>, ...}), **k={})\n    182     validate_type(magic_kind)\n    183 \n    184     # This is a closure to capture the magic_kind.  We could also use a class,\n    185     # but it's overkill for just that one bit of state.\n    186     def magic_deco(arg):\n--> 187         call = lambda f, *a, **k: f(*a, **k)\n        f = <function ExecutionMagics.time>\n        a = (<IPython.core.magics.execution.ExecutionMagics object>, 'rf_random.fit(x_train, y_train)', None, {'BaggingClassifier': <class 'sklearn.ensemble.bagging.BaggingClassifier'>, 'Bio': <module 'Bio' from 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\Bio\\\\__init__.py'>, 'Evaluator': <class 'mlens.model_selection.model_selection.Evaluator'>, 'In': ['', 'import Bio\\nfrom Bio import SeqIO\\nimport numpy as...ver\\n\\nsub_data_root = data_root + \"sample01split/\"', \"def make_features(seq, sub_seq_bank, lable):\\n   ...s)\\n    df['lable'] = lable    \\n    return df\\n    \", 'df1 = pd.read_pickle(data_root + \"DNA_data1.pickle\")', 'df2 = pd.read_pickle(data_root + \"DNA_data2.pickle\")', 'print(df1.shape)\\nprint(df2.shape)\\ndf = pd.concat([df1, df2]) \\n\\ndf.head()', 'df.shape', \"with open(data_root + 'taxid.txt') as f:\\n    keys = f.readlines()\\nkeys = [x.strip() for x in keys] \", \"some_values = keys[:10]\\ndf1 = df.loc[df['lable'].isin(some_values)]\", 'df1.head(10)', 'gc.collect()\\ndf1.shape', \"get_ipython().run_line_magic('time', 'df1 =  convert_read_to_numb(df1, 4)')\", 'df1.head(10)', 'columns = list(df1.columns.values)\\nprint(type(co...alues[:, :-1]\\ny = df1.values[:, -1]\\n# df.head(20)', '# pickle_file = data_root + \"DNA_data.pickle\"\\n\\n#...o save data to\\', pickle_file, \\':\\', e)\\n#     raise', 'x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)', '# %time gbm = xgb.XGBClassifier(max_depth=4, n_e... n_jobs=32).fit(x_train, y_train)\\n# print(\"done\")', '# %time y_pred = gbm.predict(x_test)\\n# print(\"done\")', '# accuracy_score(y_test, y_pred)', \"# plot_confusion_matrix(confusion_matrix(y_test, y_pred), ['a','b'], normalize=True)\", ...], 'LGBMClassifier': <class 'lightgbm.sklearn.LGBMClassifier'>, 'OneVsRestClassifier': <class 'sklearn.multiclass.OneVsRestClassifier'>, 'Out': {5:                                                 ...AGTACGGCCACGTGGTCTTCACGCTCGAACCATTGCC...   741091, 6: (78731623, 2), 9:                                                 ...CGGAGTGAACATCAGGAACAGCAGTGACGCGAAGGTG...  1004901, 10: (214419, 2), 12:    0    1    2    3    4    5    6    7    8    ...  0    1    1  1004901  \n\n[10 rows x 257 columns], 35: RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), 37: 0.6566624691012546, 38: array([[ 447,    0,  235,    8,  159,   39,  441... 20,  396,    6,  277, 6681]],\n      dtype=int64), 60: RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), 62: 0.6550767221678093, ...}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'RandomizedSearchCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, 'SVC': <class 'sklearn.svm.classes.SVC'>, ...})\n        k = {}\n    188 \n    189         if callable(arg):\n    190             # \"Naked\" decorator call (just @foo, no args)\n    191             func = arg\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\magics\\execution.py in time(self=<IPython.core.magics.execution.ExecutionMagics object>, line='rf_random.fit(x_train, y_train)', cell=None, local_ns={'BaggingClassifier': <class 'sklearn.ensemble.bagging.BaggingClassifier'>, 'Bio': <module 'Bio' from 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\Bio\\\\__init__.py'>, 'Evaluator': <class 'mlens.model_selection.model_selection.Evaluator'>, 'In': ['', 'import Bio\\nfrom Bio import SeqIO\\nimport numpy as...ver\\n\\nsub_data_root = data_root + \"sample01split/\"', \"def make_features(seq, sub_seq_bank, lable):\\n   ...s)\\n    df['lable'] = lable    \\n    return df\\n    \", 'df1 = pd.read_pickle(data_root + \"DNA_data1.pickle\")', 'df2 = pd.read_pickle(data_root + \"DNA_data2.pickle\")', 'print(df1.shape)\\nprint(df2.shape)\\ndf = pd.concat([df1, df2]) \\n\\ndf.head()', 'df.shape', \"with open(data_root + 'taxid.txt') as f:\\n    keys = f.readlines()\\nkeys = [x.strip() for x in keys] \", \"some_values = keys[:10]\\ndf1 = df.loc[df['lable'].isin(some_values)]\", 'df1.head(10)', 'gc.collect()\\ndf1.shape', \"get_ipython().run_line_magic('time', 'df1 =  convert_read_to_numb(df1, 4)')\", 'df1.head(10)', 'columns = list(df1.columns.values)\\nprint(type(co...alues[:, :-1]\\ny = df1.values[:, -1]\\n# df.head(20)', '# pickle_file = data_root + \"DNA_data.pickle\"\\n\\n#...o save data to\\', pickle_file, \\':\\', e)\\n#     raise', 'x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)', '# %time gbm = xgb.XGBClassifier(max_depth=4, n_e... n_jobs=32).fit(x_train, y_train)\\n# print(\"done\")', '# %time y_pred = gbm.predict(x_test)\\n# print(\"done\")', '# accuracy_score(y_test, y_pred)', \"# plot_confusion_matrix(confusion_matrix(y_test, y_pred), ['a','b'], normalize=True)\", ...], 'LGBMClassifier': <class 'lightgbm.sklearn.LGBMClassifier'>, 'OneVsRestClassifier': <class 'sklearn.multiclass.OneVsRestClassifier'>, 'Out': {5:                                                 ...AGTACGGCCACGTGGTCTTCACGCTCGAACCATTGCC...   741091, 6: (78731623, 2), 9:                                                 ...CGGAGTGAACATCAGGAACAGCAGTGACGCGAAGGTG...  1004901, 10: (214419, 2), 12:    0    1    2    3    4    5    6    7    8    ...  0    1    1  1004901  \n\n[10 rows x 257 columns], 35: RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), 37: 0.6566624691012546, 38: array([[ 447,    0,  235,    8,  159,   39,  441... 20,  396,    6,  277, 6681]],\n      dtype=int64), 60: RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), 62: 0.6550767221678093, ...}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'RandomizedSearchCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, 'SVC': <class 'sklearn.svm.classes.SVC'>, ...})\n   1225         # time execution\n   1226         wall_st = wtime()\n   1227         if mode=='eval':\n   1228             st = clock2()\n   1229             try:\n-> 1230                 out = eval(code, glob, local_ns)\n        out = undefined\n        code = <code object <module> at 0x0000019211076030, file \"<timed eval>\", line 1>\n        glob = {'BaggingClassifier': <class 'sklearn.ensemble.bagging.BaggingClassifier'>, 'Bio': <module 'Bio' from 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\Bio\\\\__init__.py'>, 'Evaluator': <class 'mlens.model_selection.model_selection.Evaluator'>, 'In': ['', 'import Bio\\nfrom Bio import SeqIO\\nimport numpy as...ver\\n\\nsub_data_root = data_root + \"sample01split/\"', \"def make_features(seq, sub_seq_bank, lable):\\n   ...s)\\n    df['lable'] = lable    \\n    return df\\n    \", 'df1 = pd.read_pickle(data_root + \"DNA_data1.pickle\")', 'df2 = pd.read_pickle(data_root + \"DNA_data2.pickle\")', 'print(df1.shape)\\nprint(df2.shape)\\ndf = pd.concat([df1, df2]) \\n\\ndf.head()', 'df.shape', \"with open(data_root + 'taxid.txt') as f:\\n    keys = f.readlines()\\nkeys = [x.strip() for x in keys] \", \"some_values = keys[:10]\\ndf1 = df.loc[df['lable'].isin(some_values)]\", 'df1.head(10)', 'gc.collect()\\ndf1.shape', \"get_ipython().run_line_magic('time', 'df1 =  convert_read_to_numb(df1, 4)')\", 'df1.head(10)', 'columns = list(df1.columns.values)\\nprint(type(co...alues[:, :-1]\\ny = df1.values[:, -1]\\n# df.head(20)', '# pickle_file = data_root + \"DNA_data.pickle\"\\n\\n#...o save data to\\', pickle_file, \\':\\', e)\\n#     raise', 'x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)', '# %time gbm = xgb.XGBClassifier(max_depth=4, n_e... n_jobs=32).fit(x_train, y_train)\\n# print(\"done\")', '# %time y_pred = gbm.predict(x_test)\\n# print(\"done\")', '# accuracy_score(y_test, y_pred)', \"# plot_confusion_matrix(confusion_matrix(y_test, y_pred), ['a','b'], normalize=True)\", ...], 'LGBMClassifier': <class 'lightgbm.sklearn.LGBMClassifier'>, 'OneVsRestClassifier': <class 'sklearn.multiclass.OneVsRestClassifier'>, 'Out': {5:                                                 ...AGTACGGCCACGTGGTCTTCACGCTCGAACCATTGCC...   741091, 6: (78731623, 2), 9:                                                 ...CGGAGTGAACATCAGGAACAGCAGTGACGCGAAGGTG...  1004901, 10: (214419, 2), 12:    0    1    2    3    4    5    6    7    8    ...  0    1    1  1004901  \n\n[10 rows x 257 columns], 35: RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), 37: 0.6566624691012546, 38: array([[ 447,    0,  235,    8,  159,   39,  441... 20,  396,    6,  277, 6681]],\n      dtype=int64), 60: RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), 62: 0.6550767221678093, ...}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'RandomizedSearchCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, 'SVC': <class 'sklearn.svm.classes.SVC'>, ...}\n        local_ns = {'BaggingClassifier': <class 'sklearn.ensemble.bagging.BaggingClassifier'>, 'Bio': <module 'Bio' from 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\Bio\\\\__init__.py'>, 'Evaluator': <class 'mlens.model_selection.model_selection.Evaluator'>, 'In': ['', 'import Bio\\nfrom Bio import SeqIO\\nimport numpy as...ver\\n\\nsub_data_root = data_root + \"sample01split/\"', \"def make_features(seq, sub_seq_bank, lable):\\n   ...s)\\n    df['lable'] = lable    \\n    return df\\n    \", 'df1 = pd.read_pickle(data_root + \"DNA_data1.pickle\")', 'df2 = pd.read_pickle(data_root + \"DNA_data2.pickle\")', 'print(df1.shape)\\nprint(df2.shape)\\ndf = pd.concat([df1, df2]) \\n\\ndf.head()', 'df.shape', \"with open(data_root + 'taxid.txt') as f:\\n    keys = f.readlines()\\nkeys = [x.strip() for x in keys] \", \"some_values = keys[:10]\\ndf1 = df.loc[df['lable'].isin(some_values)]\", 'df1.head(10)', 'gc.collect()\\ndf1.shape', \"get_ipython().run_line_magic('time', 'df1 =  convert_read_to_numb(df1, 4)')\", 'df1.head(10)', 'columns = list(df1.columns.values)\\nprint(type(co...alues[:, :-1]\\ny = df1.values[:, -1]\\n# df.head(20)', '# pickle_file = data_root + \"DNA_data.pickle\"\\n\\n#...o save data to\\', pickle_file, \\':\\', e)\\n#     raise', 'x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)', '# %time gbm = xgb.XGBClassifier(max_depth=4, n_e... n_jobs=32).fit(x_train, y_train)\\n# print(\"done\")', '# %time y_pred = gbm.predict(x_test)\\n# print(\"done\")', '# accuracy_score(y_test, y_pred)', \"# plot_confusion_matrix(confusion_matrix(y_test, y_pred), ['a','b'], normalize=True)\", ...], 'LGBMClassifier': <class 'lightgbm.sklearn.LGBMClassifier'>, 'OneVsRestClassifier': <class 'sklearn.multiclass.OneVsRestClassifier'>, 'Out': {5:                                                 ...AGTACGGCCACGTGGTCTTCACGCTCGAACCATTGCC...   741091, 6: (78731623, 2), 9:                                                 ...CGGAGTGAACATCAGGAACAGCAGTGACGCGAAGGTG...  1004901, 10: (214419, 2), 12:    0    1    2    3    4    5    6    7    8    ...  0    1    1  1004901  \n\n[10 rows x 257 columns], 35: RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), 37: 0.6566624691012546, 38: array([[ 447,    0,  235,    8,  159,   39,  441... 20,  396,    6,  277, 6681]],\n      dtype=int64), 60: RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), 62: 0.6550767221678093, ...}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'RandomizedSearchCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, 'SVC': <class 'sklearn.svm.classes.SVC'>, ...}\n   1231             except:\n   1232                 self.shell.showtraceback()\n   1233                 return\n   1234             end = clock2()\n\n...........................................................................\nC:\\Users\\Administrator\\Repos\\Microbiomics\\<timed eval> in <module>()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py in fit(self=RandomizedSearchCV(cv=3, error_score='raise',\n  ...turn_train_score='warn', scoring=None, verbose=2), X=array([[-0.64711261, -0.67223719, -0.74219387, .... -0.62177941,\n        -0.61905645,  0.60391137]]), y=array(['1004901', '1017', '1017', ..., '100901', '1019', '1007676'],\n      dtype=object), groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=3, random_state=None, shuffle=False)>\n        X = array([[-0.64711261, -0.67223719, -0.74219387, .... -0.62177941,\n        -0.61905645,  0.60391137]])\n        y = array(['1004901', '1017', '1017', ..., '100901', '1019', '1007676'],\n      dtype=object)\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nMemoryError                                        Tue Jun 12 12:36:29 2018\nPID: 9936                 Python 3.6.5: C:\\ProgramData\\Anaconda3\\python.exe\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645,  0.60391137]]), array(['1004901', '1017', '1017', ..., '100901', '1019', '1007676'],\n      dtype=object), {'score': <function _passthrough_scorer>}, array([     0,      1,      2, ..., 115156, 115171, 115183]), array([112744, 112746, 112763, ..., 171524, 171525, 171526]), 2, {'bootstrap': True, 'max_depth': 30, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 400}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645,  0.60391137]]), array(['1004901', '1017', '1017', ..., '100901', '1019', '1007676'],\n      dtype=object), {'score': <function _passthrough_scorer>}, array([     0,      1,      2, ..., 115156, 115171, 115183]), array([112744, 112746, 112763, ..., 171524, 171525, 171526]), 2, {'bootstrap': True, 'max_depth': 30, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 400})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645,  0.60391137]]), y=array(['1004901', '1017', '1017', ..., '100901', '1019', '1007676'],\n      dtype=object), scorer={'score': <function _passthrough_scorer>}, train=array([     0,      1,      2, ..., 115156, 115171, 115183]), test=array([112744, 112746, 112763, ..., 171524, 171525, 171526]), verbose=2, parameters={'bootstrap': True, 'max_depth': 30, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 400}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    487         # _score will return dict if is_multimetric is True\n    488         test_scores = _score(estimator, X_test, y_test, scorer, is_multimetric)\n    489         score_time = time.time() - start_time - fit_time\n    490         if return_train_score:\n    491             train_scores = _score(estimator, X_train, y_train, scorer,\n--> 492                                   is_multimetric)\n        is_multimetric = True\n    493 \n    494     if verbose > 2:\n    495         if is_multimetric:\n    496             for scorer_name, score in test_scores.items():\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _score(estimator=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X_test=memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645, -0.55143271]]), y_test=array(['1004901', '1017', '1017', ..., '1007676', '1007676', '1007676'],\n      dtype=object), scorer={'score': <function _passthrough_scorer>}, is_multimetric=True)\n    518 \n    519     Will return a single float if is_multimetric is False and a dict of floats,\n    520     if is_multimetric is True\n    521     \"\"\"\n    522     if is_multimetric:\n--> 523         return _multimetric_score(estimator, X_test, y_test, scorer)\n        estimator = RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False)\n        X_test = memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645, -0.55143271]])\n        y_test = array(['1004901', '1017', '1017', ..., '1007676', '1007676', '1007676'],\n      dtype=object)\n        scorer = {'score': <function _passthrough_scorer>}\n    524     else:\n    525         if y_test is None:\n    526             score = scorer(estimator, X_test)\n    527         else:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _multimetric_score(estimator=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X_test=memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645, -0.55143271]]), y_test=array(['1004901', '1017', '1017', ..., '1007676', '1007676', '1007676'],\n      dtype=object), scorers={'score': <function _passthrough_scorer>})\n    548 \n    549     for name, scorer in scorers.items():\n    550         if y_test is None:\n    551             score = scorer(estimator, X_test)\n    552         else:\n--> 553             score = scorer(estimator, X_test, y_test)\n        score = undefined\n        scorer = <function _passthrough_scorer>\n        estimator = RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False)\n        X_test = memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645, -0.55143271]])\n        y_test = array(['1004901', '1017', '1017', ..., '1007676', '1007676', '1007676'],\n      dtype=object)\n    554 \n    555         if hasattr(score, 'item'):\n    556             try:\n    557                 # e.g. unwrap memmapped scalars\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py in _passthrough_scorer(estimator=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), *args=(memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645, -0.55143271]]), array(['1004901', '1017', '1017', ..., '1007676', '1007676', '1007676'],\n      dtype=object)), **kwargs={})\n    239     return scorer\n    240 \n    241 \n    242 def _passthrough_scorer(estimator, *args, **kwargs):\n    243     \"\"\"Function that wraps estimator.score\"\"\"\n--> 244     return estimator.score(*args, **kwargs)\n        estimator.score = <bound method ClassifierMixin.score of RandomFor...e=None, verbose=0,\n            warm_start=False)>\n        args = (memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645, -0.55143271]]), array(['1004901', '1017', '1017', ..., '1007676', '1007676', '1007676'],\n      dtype=object))\n        kwargs = {}\n    245 \n    246 \n    247 def check_scoring(estimator, scoring=None, allow_none=False):\n    248     \"\"\"Determine scorer from user options.\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in score(self=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645, -0.55143271]]), y=array(['1004901', '1017', '1017', ..., '1007676', '1007676', '1007676'],\n      dtype=object), sample_weight=None)\n    344         score : float\n    345             Mean accuracy of self.predict(X) wrt. y.\n    346 \n    347         \"\"\"\n    348         from .metrics import accuracy_score\n--> 349         return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n        accuracy_score = <function accuracy_score>\n        y = array(['1004901', '1017', '1017', ..., '1007676', '1007676', '1007676'],\n      dtype=object)\n        self.predict = <bound method ForestClassifier.predict of Random...e=None, verbose=0,\n            warm_start=False)>\n        X = memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645, -0.55143271]])\n        sample_weight = None\n    350 \n    351 \n    352 ###############################################################################\n    353 class RegressorMixin(object):\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py in predict(self=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645, -0.55143271]]))\n    533         Returns\n    534         -------\n    535         y : array of shape = [n_samples] or [n_samples, n_outputs]\n    536             The predicted classes.\n    537         \"\"\"\n--> 538         proba = self.predict_proba(X)\n        proba = undefined\n        self.predict_proba = <bound method ForestClassifier.predict_proba of ...e=None, verbose=0,\n            warm_start=False)>\n        X = memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645, -0.55143271]])\n    539 \n    540         if self.n_outputs_ == 1:\n    541             return self.classes_.take(np.argmax(proba, axis=1), axis=0)\n    542 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py in predict_proba(self=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=array([[-0.6471126 , -0.67223716, -0.7421939 , ....       -0.61905646, -0.5514327 ]], dtype=float32))\n    584         all_proba = [np.zeros((X.shape[0], j), dtype=np.float64)\n    585                      for j in np.atleast_1d(self.n_classes_)]\n    586         lock = threading.Lock()\n    587         Parallel(n_jobs=n_jobs, verbose=self.verbose, backend=\"threading\")(\n    588             delayed(accumulate_prediction)(e.predict_proba, X, all_proba, lock)\n--> 589             for e in self.estimators_)\n        self.estimators_ = [DecisionTreeClassifier(class_weight=None, criter...         random_state=139770109, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...        random_state=2092607730, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...        random_state=1871373720, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...         random_state=827927126, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...        random_state=1917753714, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...         random_state=105869161, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...         random_state=830410173, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...        random_state=1292302064, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...        random_state=1085566734, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...        random_state=1575630002, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...        random_state=1707872905, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...          random_state=24175579, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...         random_state=679395208, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...         random_state=345961450, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...        random_state=1656728939, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...         random_state=102556993, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...         random_state=836257690, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...          random_state=50688945, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...         random_state=527289821, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...         random_state=602920225, splitter='best'), ...]\n    590 \n    591         for proba in all_proba:\n    592             proba /= len(self.estimators_)\n    593 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object ForestClassifier.predict_proba.<locals>.<genexpr>>)\n    774         self.n_completed_tasks = 0\n    775         try:\n    776             # Only set self._iterating to True if at least a batch\n    777             # was dispatched. In particular this covers the edge\n    778             # case of Parallel used with an exhausted iterator.\n--> 779             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>\n        iterator = <generator object ForestClassifier.predict_proba.<locals>.<genexpr>>\n    780                 self._iterating = True\n    781             else:\n    782                 self._iterating = False\n    783 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object ForestClassifier.predict_proba.<locals>.<genexpr>>)\n    620             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    621             if len(tasks) == 0:\n    622                 # No more tasks available in the iterator: tell caller to stop.\n    623                 return False\n    624             else:\n--> 625                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    626                 return True\n    627 \n    628     def _print(self, msg, msg_args):\n    629         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    583         self.n_dispatched_tasks += len(batch)\n    584         self.n_dispatched_batches += 1\n    585 \n    586         dispatch_timestamp = time.time()\n    587         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n--> 588         job = self._backend.apply_async(batch, callback=cb)\n        job = undefined\n        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>\n    589         self._jobs.append(job)\n    590 \n    591     def dispatch_next(self):\n    592         \"\"\"Dispatch more data for parallel processing\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)\n    106             raise ValueError('n_jobs == 0 in Parallel has no meaning')\n    107         return 1\n    108 \n    109     def apply_async(self, func, callback=None):\n    110         \"\"\"Schedule a func to be run\"\"\"\n--> 111         result = ImmediateResult(func)\n        result = undefined\n        func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    112         if callback:\n    113             callback(result)\n    114         return result\n    115 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    327 \n    328 class ImmediateResult(object):\n    329     def __init__(self, batch):\n    330         # Don't delay the application, to avoid keeping the input\n    331         # arguments in memory\n--> 332         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    333 \n    334     def get(self):\n    335         return self.results\n    336 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function accumulate_prediction>, (<bound method DecisionTreeClassifier.predict_pro...        random_state=106647660, splitter='best')>, array([[-0.6471126 , -0.67223716, -0.7421939 , ....       -0.61905646, -0.5514327 ]], dtype=float32), [array([[0.00000000e+00, 1.24027582e+02, 0.000000...3.24675325e-03, 1.18223316e+01, 4.77850101e+01]])], <unlocked _thread.lock object>), {})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function accumulate_prediction>\n        args = (<bound method DecisionTreeClassifier.predict_pro...        random_state=106647660, splitter='best')>, array([[-0.6471126 , -0.67223716, -0.7421939 , ....       -0.61905646, -0.5514327 ]], dtype=float32), [array([[0.00000000e+00, 1.24027582e+02, 0.000000...3.24675325e-03, 1.18223316e+01, 4.77850101e+01]])], <unlocked _thread.lock object>)\n        kwargs = {}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py in accumulate_prediction(predict=<bound method DecisionTreeClassifier.predict_pro...        random_state=106647660, splitter='best')>, X=array([[-0.6471126 , -0.67223716, -0.7421939 , ....       -0.61905646, -0.5514327 ]], dtype=float32), out=[array([[0.00000000e+00, 1.24027582e+02, 0.000000...3.24675325e-03, 1.18223316e+01, 4.77850101e+01]])], lock=<unlocked _thread.lock object>)\n    378 # This is a utility function for joblib's Parallel. It can't go locally in\n    379 # ForestClassifier or ForestRegressor, because joblib complains that it cannot\n    380 # pickle it when placed there.\n    381 \n    382 def accumulate_prediction(predict, X, out, lock):\n--> 383     prediction = predict(X, check_input=False)\n        prediction = undefined\n        predict = <bound method DecisionTreeClassifier.predict_pro...        random_state=106647660, splitter='best')>\n        X = array([[-0.6471126 , -0.67223716, -0.7421939 , ....       -0.61905646, -0.5514327 ]], dtype=float32)\n    384     with lock:\n    385         if len(out) == 1:\n    386             out[0] += prediction\n    387         else:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py in predict_proba(self=DecisionTreeClassifier(class_weight=None, criter...         random_state=106647660, splitter='best'), X=array([[-0.6471126 , -0.67223716, -0.7421939 , ....       -0.61905646, -0.5514327 ]], dtype=float32), check_input=False)\n    817             The class probabilities of the input samples. The order of the\n    818             classes corresponds to that in the attribute `classes_`.\n    819         \"\"\"\n    820         check_is_fitted(self, 'tree_')\n    821         X = self._validate_X_predict(X, check_input)\n--> 822         proba = self.tree_.predict(X)\n        proba = undefined\n        self.tree_.predict = <built-in method predict of sklearn.tree._tree.Tree object>\n        X = array([[-0.6471126 , -0.67223716, -0.7421939 , ....       -0.61905646, -0.5514327 ]], dtype=float32)\n    823 \n    824         if self.n_outputs_ == 1:\n    825             proba = proba[:, :self.n_classes_]\n    826             normalizer = proba.sum(axis=1)[:, np.newaxis]\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_tree.cp36-win_amd64.pyd in sklearn.tree._tree.Tree.predict()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_tree.cp36-win_amd64.pyd in sklearn.tree._tree.Tree.predict()\n\nMemoryError: \n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 492, in _fit_and_score\n    is_multimetric)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 523, in _score\n    return _multimetric_score(estimator, X_test, y_test, scorer)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 553, in _multimetric_score\n    score = scorer(estimator, X_test, y_test)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py\", line 244, in _passthrough_scorer\n    return estimator.score(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 349, in score\n    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\", line 538, in predict\n    proba = self.predict_proba(X)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\", line 589, in predict_proba\n    for e in self.estimators_)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 779, in __call__\n    while self.dispatch_one_batch(iterator):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 625, in dispatch_one_batch\n    self._dispatch(tasks)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 588, in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 111, in apply_async\n    result = ImmediateResult(func)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 332, in __init__\n    self.results = batch()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\", line 383, in accumulate_prediction\n    prediction = predict(X, check_input=False)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\", line 822, in predict_proba\n    proba = self.tree_.predict(X)\n  File \"sklearn\\tree\\_tree.pyx\", line 764, in sklearn.tree._tree.Tree.predict\n  File \"sklearn\\tree\\_tree.pyx\", line 766, in sklearn.tree._tree.Tree.predict\nMemoryError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nMemoryError                                        Tue Jun 12 12:36:29 2018\nPID: 9936                 Python 3.6.5: C:\\ProgramData\\Anaconda3\\python.exe\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645,  0.60391137]]), array(['1004901', '1017', '1017', ..., '100901', '1019', '1007676'],\n      dtype=object), {'score': <function _passthrough_scorer>}, array([     0,      1,      2, ..., 115156, 115171, 115183]), array([112744, 112746, 112763, ..., 171524, 171525, 171526]), 2, {'bootstrap': True, 'max_depth': 30, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 400}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645,  0.60391137]]), array(['1004901', '1017', '1017', ..., '100901', '1019', '1007676'],\n      dtype=object), {'score': <function _passthrough_scorer>}, array([     0,      1,      2, ..., 115156, 115171, 115183]), array([112744, 112746, 112763, ..., 171524, 171525, 171526]), 2, {'bootstrap': True, 'max_depth': 30, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 400})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645,  0.60391137]]), y=array(['1004901', '1017', '1017', ..., '100901', '1019', '1007676'],\n      dtype=object), scorer={'score': <function _passthrough_scorer>}, train=array([     0,      1,      2, ..., 115156, 115171, 115183]), test=array([112744, 112746, 112763, ..., 171524, 171525, 171526]), verbose=2, parameters={'bootstrap': True, 'max_depth': 30, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 400}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    487         # _score will return dict if is_multimetric is True\n    488         test_scores = _score(estimator, X_test, y_test, scorer, is_multimetric)\n    489         score_time = time.time() - start_time - fit_time\n    490         if return_train_score:\n    491             train_scores = _score(estimator, X_train, y_train, scorer,\n--> 492                                   is_multimetric)\n        is_multimetric = True\n    493 \n    494     if verbose > 2:\n    495         if is_multimetric:\n    496             for scorer_name, score in test_scores.items():\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _score(estimator=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X_test=memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645, -0.55143271]]), y_test=array(['1004901', '1017', '1017', ..., '1007676', '1007676', '1007676'],\n      dtype=object), scorer={'score': <function _passthrough_scorer>}, is_multimetric=True)\n    518 \n    519     Will return a single float if is_multimetric is False and a dict of floats,\n    520     if is_multimetric is True\n    521     \"\"\"\n    522     if is_multimetric:\n--> 523         return _multimetric_score(estimator, X_test, y_test, scorer)\n        estimator = RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False)\n        X_test = memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645, -0.55143271]])\n        y_test = array(['1004901', '1017', '1017', ..., '1007676', '1007676', '1007676'],\n      dtype=object)\n        scorer = {'score': <function _passthrough_scorer>}\n    524     else:\n    525         if y_test is None:\n    526             score = scorer(estimator, X_test)\n    527         else:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _multimetric_score(estimator=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X_test=memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645, -0.55143271]]), y_test=array(['1004901', '1017', '1017', ..., '1007676', '1007676', '1007676'],\n      dtype=object), scorers={'score': <function _passthrough_scorer>})\n    548 \n    549     for name, scorer in scorers.items():\n    550         if y_test is None:\n    551             score = scorer(estimator, X_test)\n    552         else:\n--> 553             score = scorer(estimator, X_test, y_test)\n        score = undefined\n        scorer = <function _passthrough_scorer>\n        estimator = RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False)\n        X_test = memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645, -0.55143271]])\n        y_test = array(['1004901', '1017', '1017', ..., '1007676', '1007676', '1007676'],\n      dtype=object)\n    554 \n    555         if hasattr(score, 'item'):\n    556             try:\n    557                 # e.g. unwrap memmapped scalars\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py in _passthrough_scorer(estimator=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), *args=(memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645, -0.55143271]]), array(['1004901', '1017', '1017', ..., '1007676', '1007676', '1007676'],\n      dtype=object)), **kwargs={})\n    239     return scorer\n    240 \n    241 \n    242 def _passthrough_scorer(estimator, *args, **kwargs):\n    243     \"\"\"Function that wraps estimator.score\"\"\"\n--> 244     return estimator.score(*args, **kwargs)\n        estimator.score = <bound method ClassifierMixin.score of RandomFor...e=None, verbose=0,\n            warm_start=False)>\n        args = (memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645, -0.55143271]]), array(['1004901', '1017', '1017', ..., '1007676', '1007676', '1007676'],\n      dtype=object))\n        kwargs = {}\n    245 \n    246 \n    247 def check_scoring(estimator, scoring=None, allow_none=False):\n    248     \"\"\"Determine scorer from user options.\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in score(self=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645, -0.55143271]]), y=array(['1004901', '1017', '1017', ..., '1007676', '1007676', '1007676'],\n      dtype=object), sample_weight=None)\n    344         score : float\n    345             Mean accuracy of self.predict(X) wrt. y.\n    346 \n    347         \"\"\"\n    348         from .metrics import accuracy_score\n--> 349         return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n        accuracy_score = <function accuracy_score>\n        y = array(['1004901', '1017', '1017', ..., '1007676', '1007676', '1007676'],\n      dtype=object)\n        self.predict = <bound method ForestClassifier.predict of Random...e=None, verbose=0,\n            warm_start=False)>\n        X = memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645, -0.55143271]])\n        sample_weight = None\n    350 \n    351 \n    352 ###############################################################################\n    353 class RegressorMixin(object):\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py in predict(self=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645, -0.55143271]]))\n    533         Returns\n    534         -------\n    535         y : array of shape = [n_samples] or [n_samples, n_outputs]\n    536             The predicted classes.\n    537         \"\"\"\n--> 538         proba = self.predict_proba(X)\n        proba = undefined\n        self.predict_proba = <bound method ForestClassifier.predict_proba of ...e=None, verbose=0,\n            warm_start=False)>\n        X = memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645, -0.55143271]])\n    539 \n    540         if self.n_outputs_ == 1:\n    541             return self.classes_.take(np.argmax(proba, axis=1), axis=0)\n    542 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py in predict_proba(self=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=array([[-0.6471126 , -0.67223716, -0.7421939 , ....       -0.61905646, -0.5514327 ]], dtype=float32))\n    584         all_proba = [np.zeros((X.shape[0], j), dtype=np.float64)\n    585                      for j in np.atleast_1d(self.n_classes_)]\n    586         lock = threading.Lock()\n    587         Parallel(n_jobs=n_jobs, verbose=self.verbose, backend=\"threading\")(\n    588             delayed(accumulate_prediction)(e.predict_proba, X, all_proba, lock)\n--> 589             for e in self.estimators_)\n        self.estimators_ = [DecisionTreeClassifier(class_weight=None, criter...         random_state=139770109, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...        random_state=2092607730, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...        random_state=1871373720, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...         random_state=827927126, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...        random_state=1917753714, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...         random_state=105869161, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...         random_state=830410173, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...        random_state=1292302064, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...        random_state=1085566734, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...        random_state=1575630002, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...        random_state=1707872905, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...          random_state=24175579, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...         random_state=679395208, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...         random_state=345961450, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...        random_state=1656728939, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...         random_state=102556993, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...         random_state=836257690, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...          random_state=50688945, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...         random_state=527289821, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...         random_state=602920225, splitter='best'), ...]\n    590 \n    591         for proba in all_proba:\n    592             proba /= len(self.estimators_)\n    593 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object ForestClassifier.predict_proba.<locals>.<genexpr>>)\n    774         self.n_completed_tasks = 0\n    775         try:\n    776             # Only set self._iterating to True if at least a batch\n    777             # was dispatched. In particular this covers the edge\n    778             # case of Parallel used with an exhausted iterator.\n--> 779             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>\n        iterator = <generator object ForestClassifier.predict_proba.<locals>.<genexpr>>\n    780                 self._iterating = True\n    781             else:\n    782                 self._iterating = False\n    783 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object ForestClassifier.predict_proba.<locals>.<genexpr>>)\n    620             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    621             if len(tasks) == 0:\n    622                 # No more tasks available in the iterator: tell caller to stop.\n    623                 return False\n    624             else:\n--> 625                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    626                 return True\n    627 \n    628     def _print(self, msg, msg_args):\n    629         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    583         self.n_dispatched_tasks += len(batch)\n    584         self.n_dispatched_batches += 1\n    585 \n    586         dispatch_timestamp = time.time()\n    587         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n--> 588         job = self._backend.apply_async(batch, callback=cb)\n        job = undefined\n        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>\n    589         self._jobs.append(job)\n    590 \n    591     def dispatch_next(self):\n    592         \"\"\"Dispatch more data for parallel processing\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)\n    106             raise ValueError('n_jobs == 0 in Parallel has no meaning')\n    107         return 1\n    108 \n    109     def apply_async(self, func, callback=None):\n    110         \"\"\"Schedule a func to be run\"\"\"\n--> 111         result = ImmediateResult(func)\n        result = undefined\n        func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    112         if callback:\n    113             callback(result)\n    114         return result\n    115 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    327 \n    328 class ImmediateResult(object):\n    329     def __init__(self, batch):\n    330         # Don't delay the application, to avoid keeping the input\n    331         # arguments in memory\n--> 332         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    333 \n    334     def get(self):\n    335         return self.results\n    336 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function accumulate_prediction>, (<bound method DecisionTreeClassifier.predict_pro...        random_state=106647660, splitter='best')>, array([[-0.6471126 , -0.67223716, -0.7421939 , ....       -0.61905646, -0.5514327 ]], dtype=float32), [array([[0.00000000e+00, 1.24027582e+02, 0.000000...3.24675325e-03, 1.18223316e+01, 4.77850101e+01]])], <unlocked _thread.lock object>), {})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function accumulate_prediction>\n        args = (<bound method DecisionTreeClassifier.predict_pro...        random_state=106647660, splitter='best')>, array([[-0.6471126 , -0.67223716, -0.7421939 , ....       -0.61905646, -0.5514327 ]], dtype=float32), [array([[0.00000000e+00, 1.24027582e+02, 0.000000...3.24675325e-03, 1.18223316e+01, 4.77850101e+01]])], <unlocked _thread.lock object>)\n        kwargs = {}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py in accumulate_prediction(predict=<bound method DecisionTreeClassifier.predict_pro...        random_state=106647660, splitter='best')>, X=array([[-0.6471126 , -0.67223716, -0.7421939 , ....       -0.61905646, -0.5514327 ]], dtype=float32), out=[array([[0.00000000e+00, 1.24027582e+02, 0.000000...3.24675325e-03, 1.18223316e+01, 4.77850101e+01]])], lock=<unlocked _thread.lock object>)\n    378 # This is a utility function for joblib's Parallel. It can't go locally in\n    379 # ForestClassifier or ForestRegressor, because joblib complains that it cannot\n    380 # pickle it when placed there.\n    381 \n    382 def accumulate_prediction(predict, X, out, lock):\n--> 383     prediction = predict(X, check_input=False)\n        prediction = undefined\n        predict = <bound method DecisionTreeClassifier.predict_pro...        random_state=106647660, splitter='best')>\n        X = array([[-0.6471126 , -0.67223716, -0.7421939 , ....       -0.61905646, -0.5514327 ]], dtype=float32)\n    384     with lock:\n    385         if len(out) == 1:\n    386             out[0] += prediction\n    387         else:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py in predict_proba(self=DecisionTreeClassifier(class_weight=None, criter...         random_state=106647660, splitter='best'), X=array([[-0.6471126 , -0.67223716, -0.7421939 , ....       -0.61905646, -0.5514327 ]], dtype=float32), check_input=False)\n    817             The class probabilities of the input samples. The order of the\n    818             classes corresponds to that in the attribute `classes_`.\n    819         \"\"\"\n    820         check_is_fitted(self, 'tree_')\n    821         X = self._validate_X_predict(X, check_input)\n--> 822         proba = self.tree_.predict(X)\n        proba = undefined\n        self.tree_.predict = <built-in method predict of sklearn.tree._tree.Tree object>\n        X = array([[-0.6471126 , -0.67223716, -0.7421939 , ....       -0.61905646, -0.5514327 ]], dtype=float32)\n    823 \n    824         if self.n_outputs_ == 1:\n    825             proba = proba[:, :self.n_classes_]\n    826             normalizer = proba.sum(axis=1)[:, np.newaxis]\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_tree.cp36-win_amd64.pyd in sklearn.tree._tree.Tree.predict()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_tree.cp36-win_amd64.pyd in sklearn.tree._tree.Tree.predict()\n\nMemoryError: \n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nMemoryError                                        Tue Jun 12 12:36:29 2018\nPID: 9936                 Python 3.6.5: C:\\ProgramData\\Anaconda3\\python.exe\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645,  0.60391137]]), array(['1004901', '1017', '1017', ..., '100901', '1019', '1007676'],\n      dtype=object), {'score': <function _passthrough_scorer>}, array([     0,      1,      2, ..., 115156, 115171, 115183]), array([112744, 112746, 112763, ..., 171524, 171525, 171526]), 2, {'bootstrap': True, 'max_depth': 30, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 400}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645,  0.60391137]]), array(['1004901', '1017', '1017', ..., '100901', '1019', '1007676'],\n      dtype=object), {'score': <function _passthrough_scorer>}, array([     0,      1,      2, ..., 115156, 115171, 115183]), array([112744, 112746, 112763, ..., 171524, 171525, 171526]), 2, {'bootstrap': True, 'max_depth': 30, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 400})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645,  0.60391137]]), y=array(['1004901', '1017', '1017', ..., '100901', '1019', '1007676'],\n      dtype=object), scorer={'score': <function _passthrough_scorer>}, train=array([     0,      1,      2, ..., 115156, 115171, 115183]), test=array([112744, 112746, 112763, ..., 171524, 171525, 171526]), verbose=2, parameters={'bootstrap': True, 'max_depth': 30, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 400}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    487         # _score will return dict if is_multimetric is True\n    488         test_scores = _score(estimator, X_test, y_test, scorer, is_multimetric)\n    489         score_time = time.time() - start_time - fit_time\n    490         if return_train_score:\n    491             train_scores = _score(estimator, X_train, y_train, scorer,\n--> 492                                   is_multimetric)\n        is_multimetric = True\n    493 \n    494     if verbose > 2:\n    495         if is_multimetric:\n    496             for scorer_name, score in test_scores.items():\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _score(estimator=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X_test=memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645, -0.55143271]]), y_test=array(['1004901', '1017', '1017', ..., '1007676', '1007676', '1007676'],\n      dtype=object), scorer={'score': <function _passthrough_scorer>}, is_multimetric=True)\n    518 \n    519     Will return a single float if is_multimetric is False and a dict of floats,\n    520     if is_multimetric is True\n    521     \"\"\"\n    522     if is_multimetric:\n--> 523         return _multimetric_score(estimator, X_test, y_test, scorer)\n        estimator = RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False)\n        X_test = memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645, -0.55143271]])\n        y_test = array(['1004901', '1017', '1017', ..., '1007676', '1007676', '1007676'],\n      dtype=object)\n        scorer = {'score': <function _passthrough_scorer>}\n    524     else:\n    525         if y_test is None:\n    526             score = scorer(estimator, X_test)\n    527         else:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _multimetric_score(estimator=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X_test=memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645, -0.55143271]]), y_test=array(['1004901', '1017', '1017', ..., '1007676', '1007676', '1007676'],\n      dtype=object), scorers={'score': <function _passthrough_scorer>})\n    548 \n    549     for name, scorer in scorers.items():\n    550         if y_test is None:\n    551             score = scorer(estimator, X_test)\n    552         else:\n--> 553             score = scorer(estimator, X_test, y_test)\n        score = undefined\n        scorer = <function _passthrough_scorer>\n        estimator = RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False)\n        X_test = memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645, -0.55143271]])\n        y_test = array(['1004901', '1017', '1017', ..., '1007676', '1007676', '1007676'],\n      dtype=object)\n    554 \n    555         if hasattr(score, 'item'):\n    556             try:\n    557                 # e.g. unwrap memmapped scalars\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py in _passthrough_scorer(estimator=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), *args=(memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645, -0.55143271]]), array(['1004901', '1017', '1017', ..., '1007676', '1007676', '1007676'],\n      dtype=object)), **kwargs={})\n    239     return scorer\n    240 \n    241 \n    242 def _passthrough_scorer(estimator, *args, **kwargs):\n    243     \"\"\"Function that wraps estimator.score\"\"\"\n--> 244     return estimator.score(*args, **kwargs)\n        estimator.score = <bound method ClassifierMixin.score of RandomFor...e=None, verbose=0,\n            warm_start=False)>\n        args = (memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645, -0.55143271]]), array(['1004901', '1017', '1017', ..., '1007676', '1007676', '1007676'],\n      dtype=object))\n        kwargs = {}\n    245 \n    246 \n    247 def check_scoring(estimator, scoring=None, allow_none=False):\n    248     \"\"\"Determine scorer from user options.\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in score(self=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645, -0.55143271]]), y=array(['1004901', '1017', '1017', ..., '1007676', '1007676', '1007676'],\n      dtype=object), sample_weight=None)\n    344         score : float\n    345             Mean accuracy of self.predict(X) wrt. y.\n    346 \n    347         \"\"\"\n    348         from .metrics import accuracy_score\n--> 349         return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n        accuracy_score = <function accuracy_score>\n        y = array(['1004901', '1017', '1017', ..., '1007676', '1007676', '1007676'],\n      dtype=object)\n        self.predict = <bound method ForestClassifier.predict of Random...e=None, verbose=0,\n            warm_start=False)>\n        X = memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645, -0.55143271]])\n        sample_weight = None\n    350 \n    351 \n    352 ###############################################################################\n    353 class RegressorMixin(object):\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py in predict(self=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645, -0.55143271]]))\n    533         Returns\n    534         -------\n    535         y : array of shape = [n_samples] or [n_samples, n_outputs]\n    536             The predicted classes.\n    537         \"\"\"\n--> 538         proba = self.predict_proba(X)\n        proba = undefined\n        self.predict_proba = <bound method ForestClassifier.predict_proba of ...e=None, verbose=0,\n            warm_start=False)>\n        X = memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645, -0.55143271]])\n    539 \n    540         if self.n_outputs_ == 1:\n    541             return self.classes_.take(np.argmax(proba, axis=1), axis=0)\n    542 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py in predict_proba(self=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=array([[-0.6471126 , -0.67223716, -0.7421939 , ....       -0.61905646, -0.5514327 ]], dtype=float32))\n    584         all_proba = [np.zeros((X.shape[0], j), dtype=np.float64)\n    585                      for j in np.atleast_1d(self.n_classes_)]\n    586         lock = threading.Lock()\n    587         Parallel(n_jobs=n_jobs, verbose=self.verbose, backend=\"threading\")(\n    588             delayed(accumulate_prediction)(e.predict_proba, X, all_proba, lock)\n--> 589             for e in self.estimators_)\n        self.estimators_ = [DecisionTreeClassifier(class_weight=None, criter...         random_state=139770109, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...        random_state=2092607730, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...        random_state=1871373720, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...         random_state=827927126, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...        random_state=1917753714, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...         random_state=105869161, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...         random_state=830410173, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...        random_state=1292302064, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...        random_state=1085566734, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...        random_state=1575630002, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...        random_state=1707872905, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...          random_state=24175579, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...         random_state=679395208, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...         random_state=345961450, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...        random_state=1656728939, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...         random_state=102556993, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...         random_state=836257690, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...          random_state=50688945, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...         random_state=527289821, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...         random_state=602920225, splitter='best'), ...]\n    590 \n    591         for proba in all_proba:\n    592             proba /= len(self.estimators_)\n    593 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object ForestClassifier.predict_proba.<locals>.<genexpr>>)\n    774         self.n_completed_tasks = 0\n    775         try:\n    776             # Only set self._iterating to True if at least a batch\n    777             # was dispatched. In particular this covers the edge\n    778             # case of Parallel used with an exhausted iterator.\n--> 779             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>\n        iterator = <generator object ForestClassifier.predict_proba.<locals>.<genexpr>>\n    780                 self._iterating = True\n    781             else:\n    782                 self._iterating = False\n    783 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object ForestClassifier.predict_proba.<locals>.<genexpr>>)\n    620             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    621             if len(tasks) == 0:\n    622                 # No more tasks available in the iterator: tell caller to stop.\n    623                 return False\n    624             else:\n--> 625                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    626                 return True\n    627 \n    628     def _print(self, msg, msg_args):\n    629         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    583         self.n_dispatched_tasks += len(batch)\n    584         self.n_dispatched_batches += 1\n    585 \n    586         dispatch_timestamp = time.time()\n    587         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n--> 588         job = self._backend.apply_async(batch, callback=cb)\n        job = undefined\n        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>\n    589         self._jobs.append(job)\n    590 \n    591     def dispatch_next(self):\n    592         \"\"\"Dispatch more data for parallel processing\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)\n    106             raise ValueError('n_jobs == 0 in Parallel has no meaning')\n    107         return 1\n    108 \n    109     def apply_async(self, func, callback=None):\n    110         \"\"\"Schedule a func to be run\"\"\"\n--> 111         result = ImmediateResult(func)\n        result = undefined\n        func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    112         if callback:\n    113             callback(result)\n    114         return result\n    115 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    327 \n    328 class ImmediateResult(object):\n    329     def __init__(self, batch):\n    330         # Don't delay the application, to avoid keeping the input\n    331         # arguments in memory\n--> 332         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    333 \n    334     def get(self):\n    335         return self.results\n    336 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function accumulate_prediction>, (<bound method DecisionTreeClassifier.predict_pro...        random_state=106647660, splitter='best')>, array([[-0.6471126 , -0.67223716, -0.7421939 , ....       -0.61905646, -0.5514327 ]], dtype=float32), [array([[0.00000000e+00, 1.24027582e+02, 0.000000...3.24675325e-03, 1.18223316e+01, 4.77850101e+01]])], <unlocked _thread.lock object>), {})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function accumulate_prediction>\n        args = (<bound method DecisionTreeClassifier.predict_pro...        random_state=106647660, splitter='best')>, array([[-0.6471126 , -0.67223716, -0.7421939 , ....       -0.61905646, -0.5514327 ]], dtype=float32), [array([[0.00000000e+00, 1.24027582e+02, 0.000000...3.24675325e-03, 1.18223316e+01, 4.77850101e+01]])], <unlocked _thread.lock object>)\n        kwargs = {}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py in accumulate_prediction(predict=<bound method DecisionTreeClassifier.predict_pro...        random_state=106647660, splitter='best')>, X=array([[-0.6471126 , -0.67223716, -0.7421939 , ....       -0.61905646, -0.5514327 ]], dtype=float32), out=[array([[0.00000000e+00, 1.24027582e+02, 0.000000...3.24675325e-03, 1.18223316e+01, 4.77850101e+01]])], lock=<unlocked _thread.lock object>)\n    378 # This is a utility function for joblib's Parallel. It can't go locally in\n    379 # ForestClassifier or ForestRegressor, because joblib complains that it cannot\n    380 # pickle it when placed there.\n    381 \n    382 def accumulate_prediction(predict, X, out, lock):\n--> 383     prediction = predict(X, check_input=False)\n        prediction = undefined\n        predict = <bound method DecisionTreeClassifier.predict_pro...        random_state=106647660, splitter='best')>\n        X = array([[-0.6471126 , -0.67223716, -0.7421939 , ....       -0.61905646, -0.5514327 ]], dtype=float32)\n    384     with lock:\n    385         if len(out) == 1:\n    386             out[0] += prediction\n    387         else:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py in predict_proba(self=DecisionTreeClassifier(class_weight=None, criter...         random_state=106647660, splitter='best'), X=array([[-0.6471126 , -0.67223716, -0.7421939 , ....       -0.61905646, -0.5514327 ]], dtype=float32), check_input=False)\n    817             The class probabilities of the input samples. The order of the\n    818             classes corresponds to that in the attribute `classes_`.\n    819         \"\"\"\n    820         check_is_fitted(self, 'tree_')\n    821         X = self._validate_X_predict(X, check_input)\n--> 822         proba = self.tree_.predict(X)\n        proba = undefined\n        self.tree_.predict = <built-in method predict of sklearn.tree._tree.Tree object>\n        X = array([[-0.6471126 , -0.67223716, -0.7421939 , ....       -0.61905646, -0.5514327 ]], dtype=float32)\n    823 \n    824         if self.n_outputs_ == 1:\n    825             proba = proba[:, :self.n_classes_]\n    826             normalizer = proba.sum(axis=1)[:, np.newaxis]\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_tree.cp36-win_amd64.pyd in sklearn.tree._tree.Tree.predict()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_tree.cp36-win_amd64.pyd in sklearn.tree._tree.Tree.predict()\n\nMemoryError: \n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJoblibMemoryError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 639\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJoblibMemoryError\u001b[0m: JoblibMemoryError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x0000018D63144F60, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\ProgramD...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x0000018D63144F60, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\ProgramD...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    122         except (RuntimeError, AssertionError):\n    123             old_loop = None\n    124         try:\n    125             self._setup_logging()\n    126             asyncio.set_event_loop(self.asyncio_loop)\n--> 127             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Win...EventLoop running=True closed=False debug=False>>\n    128         finally:\n    129             asyncio.set_event_loop(old_loop)\n    130 \n    131     def stop(self):\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py in run_forever(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n    417             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    418                                    finalizer=self._asyncgen_finalizer_hook)\n    419         try:\n    420             events._set_running_loop(self)\n    421             while True:\n--> 422                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_Windo...EventLoop running=True closed=False debug=False>>\n    423                 if self._stopping:\n    424                     break\n    425         finally:\n    426             self._stopping = False\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py in _run_once(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n   1427                         logger.warning('Executing %s took %.3f seconds',\n   1428                                        _format_handle(handle), dt)\n   1429                 finally:\n   1430                     self._current_handle = None\n   1431             else:\n-> 1432                 handle._run()\n        handle._run = <bound method Handle._run of <Handle BaseAsyncIOLoop._handle_events(616, 1)>>\n   1433         handle = None  # Needed to break cycles when an exception occurs.\n   1434 \n   1435     def _set_coroutine_wrapper(self, enabled):\n   1436         try:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\asyncio\\events.py in _run(self=<Handle BaseAsyncIOLoop._handle_events(616, 1)>)\n    140             self._callback = None\n    141             self._args = None\n    142 \n    143     def _run(self):\n    144         try:\n--> 145             self._callback(*self._args)\n        self._callback = <bound method BaseAsyncIOLoop._handle_events of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (616, 1)\n    146         except Exception as exc:\n    147             cb = _format_callback_source(self._callback, self._args)\n    148             msg = 'Exception in callback {}'.format(cb)\n    149             context = {\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in _handle_events(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, fd=616, events=1)\n    112             self.writers.remove(fd)\n    113         del self.handlers[fd]\n    114 \n    115     def _handle_events(self, fd, events):\n    116         fileobj, handler_func = self.handlers[fd]\n--> 117         handler_func(fileobj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fileobj = <zmq.sugar.socket.Socket object>\n        events = 1\n    118 \n    119     def start(self):\n    120         try:\n    121             old_loop = asyncio.get_event_loop()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': '# Use the random grid to search for best hyperpa...earch model\\n%time rf_random.fit(x_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 6, 12, 19, 16, 2, 206172, tzinfo=tzutc()), 'msg_id': '8c68f77a9eaa4ab8809daecedaed75ad', 'msg_type': 'execute_request', 'session': '80fbe17cc4434eb688e083bb3a3ea874', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '8c68f77a9eaa4ab8809daecedaed75ad', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'80fbe17cc4434eb688e083bb3a3ea874']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': '# Use the random grid to search for best hyperpa...earch model\\n%time rf_random.fit(x_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 6, 12, 19, 16, 2, 206172, tzinfo=tzutc()), 'msg_id': '8c68f77a9eaa4ab8809daecedaed75ad', 'msg_type': 'execute_request', 'session': '80fbe17cc4434eb688e083bb3a3ea874', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '8c68f77a9eaa4ab8809daecedaed75ad', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'80fbe17cc4434eb688e083bb3a3ea874'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': '# Use the random grid to search for best hyperpa...earch model\\n%time rf_random.fit(x_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 6, 12, 19, 16, 2, 206172, tzinfo=tzutc()), 'msg_id': '8c68f77a9eaa4ab8809daecedaed75ad', 'msg_type': 'execute_request', 'session': '80fbe17cc4434eb688e083bb3a3ea874', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '8c68f77a9eaa4ab8809daecedaed75ad', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='# Use the random grid to search for best hyperpa...earch model\\n%time rf_random.fit(x_train, y_train)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = '# Use the random grid to search for best hyperpa...earch model\\n%time rf_random.fit(x_train, y_train)'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('# Use the random grid to search for best hyperpa...earch model\\n%time rf_random.fit(x_train, y_train)',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('# Use the random grid to search for best hyperpa...earch model\\n%time rf_random.fit(x_train, y_train)',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='# Use the random grid to search for best hyperpa...earch model\\n%time rf_random.fit(x_train, y_train)', store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = '# Use the random grid to search for best hyperpa...earch model\\n%time rf_random.fit(x_train, y_train)'\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='# Use the random grid to search for best hyperpa...earch model\\n%time rf_random.fit(x_train, y_train)', store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-77-8187a86681d1>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 18ff785d4a8, executio...rue silent=False shell_futures=True> result=None>)\n   2904                     return True\n   2905 \n   2906             for i, node in enumerate(to_run_interactive):\n   2907                 mod = ast.Interactive([node])\n   2908                 code = compiler(mod, cell_name, \"single\")\n-> 2909                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x0000018F76905B70, file \"<ipython-input-77-8187a86681d1>\", line 8>\n        result = <ExecutionResult object at 18ff785d4a8, executio...rue silent=False shell_futures=True> result=None>\n   2910                     return True\n   2911 \n   2912             # Flush softspace\n   2913             if softspace(sys.stdout, 0):\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x0000018F76905B70, file \"<ipython-input-77-8187a86681d1>\", line 8>, result=<ExecutionResult object at 18ff785d4a8, executio...rue silent=False shell_futures=True> result=None>)\n   2958         outflag = True  # happens in more places, so it's easier as default\n   2959         try:\n   2960             try:\n   2961                 self.hooks.pre_run_code_hook()\n   2962                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2963                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x0000018F76905B70, file \"<ipython-input-77-8187a86681d1>\", line 8>\n        self.user_global_ns = {'BaggingClassifier': <class 'sklearn.ensemble.bagging.BaggingClassifier'>, 'Bio': <module 'Bio' from 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\Bio\\\\__init__.py'>, 'Evaluator': <class 'mlens.model_selection.model_selection.Evaluator'>, 'In': ['', 'import Bio\\nfrom Bio import SeqIO\\nimport numpy as...ver\\n\\nsub_data_root = data_root + \"sample01split/\"', \"def make_features(seq, sub_seq_bank, lable):\\n   ...s)\\n    df['lable'] = lable    \\n    return df\\n    \", 'df1 = pd.read_pickle(data_root + \"DNA_data1.pickle\")', 'df2 = pd.read_pickle(data_root + \"DNA_data2.pickle\")', 'print(df1.shape)\\nprint(df2.shape)\\ndf = pd.concat([df1, df2]) \\n\\ndf.head()', 'df.shape', \"with open(data_root + 'taxid.txt') as f:\\n    keys = f.readlines()\\nkeys = [x.strip() for x in keys] \", \"some_values = keys[:10]\\ndf1 = df.loc[df['lable'].isin(some_values)]\", 'df1.head(10)', 'gc.collect()\\ndf1.shape', \"get_ipython().run_line_magic('time', 'df1 =  convert_read_to_numb(df1, 4)')\", 'df1.head(10)', 'columns = list(df1.columns.values)\\nprint(type(co...alues[:, :-1]\\ny = df1.values[:, -1]\\n# df.head(20)', '# pickle_file = data_root + \"DNA_data.pickle\"\\n\\n#...o save data to\\', pickle_file, \\':\\', e)\\n#     raise', 'x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)', '# %time gbm = xgb.XGBClassifier(max_depth=4, n_e... n_jobs=32).fit(x_train, y_train)\\n# print(\"done\")', '# %time y_pred = gbm.predict(x_test)\\n# print(\"done\")', '# accuracy_score(y_test, y_pred)', \"# plot_confusion_matrix(confusion_matrix(y_test, y_pred), ['a','b'], normalize=True)\", ...], 'LGBMClassifier': <class 'lightgbm.sklearn.LGBMClassifier'>, 'OneVsRestClassifier': <class 'sklearn.multiclass.OneVsRestClassifier'>, 'Out': {5:                                                 ...AGTACGGCCACGTGGTCTTCACGCTCGAACCATTGCC...   741091, 6: (78731623, 2), 9:                                                 ...CGGAGTGAACATCAGGAACAGCAGTGACGCGAAGGTG...  1004901, 10: (214419, 2), 12:    0    1    2    3    4    5    6    7    8    ...  0    1    1  1004901  \n\n[10 rows x 257 columns], 35: RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), 37: 0.6566624691012546, 38: array([[ 447,    0,  235,    8,  159,   39,  441... 20,  396,    6,  277, 6681]],\n      dtype=int64), 60: RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), 62: 0.6550767221678093, ...}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'RandomizedSearchCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, 'SVC': <class 'sklearn.svm.classes.SVC'>, ...}\n        self.user_ns = {'BaggingClassifier': <class 'sklearn.ensemble.bagging.BaggingClassifier'>, 'Bio': <module 'Bio' from 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\Bio\\\\__init__.py'>, 'Evaluator': <class 'mlens.model_selection.model_selection.Evaluator'>, 'In': ['', 'import Bio\\nfrom Bio import SeqIO\\nimport numpy as...ver\\n\\nsub_data_root = data_root + \"sample01split/\"', \"def make_features(seq, sub_seq_bank, lable):\\n   ...s)\\n    df['lable'] = lable    \\n    return df\\n    \", 'df1 = pd.read_pickle(data_root + \"DNA_data1.pickle\")', 'df2 = pd.read_pickle(data_root + \"DNA_data2.pickle\")', 'print(df1.shape)\\nprint(df2.shape)\\ndf = pd.concat([df1, df2]) \\n\\ndf.head()', 'df.shape', \"with open(data_root + 'taxid.txt') as f:\\n    keys = f.readlines()\\nkeys = [x.strip() for x in keys] \", \"some_values = keys[:10]\\ndf1 = df.loc[df['lable'].isin(some_values)]\", 'df1.head(10)', 'gc.collect()\\ndf1.shape', \"get_ipython().run_line_magic('time', 'df1 =  convert_read_to_numb(df1, 4)')\", 'df1.head(10)', 'columns = list(df1.columns.values)\\nprint(type(co...alues[:, :-1]\\ny = df1.values[:, -1]\\n# df.head(20)', '# pickle_file = data_root + \"DNA_data.pickle\"\\n\\n#...o save data to\\', pickle_file, \\':\\', e)\\n#     raise', 'x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)', '# %time gbm = xgb.XGBClassifier(max_depth=4, n_e... n_jobs=32).fit(x_train, y_train)\\n# print(\"done\")', '# %time y_pred = gbm.predict(x_test)\\n# print(\"done\")', '# accuracy_score(y_test, y_pred)', \"# plot_confusion_matrix(confusion_matrix(y_test, y_pred), ['a','b'], normalize=True)\", ...], 'LGBMClassifier': <class 'lightgbm.sklearn.LGBMClassifier'>, 'OneVsRestClassifier': <class 'sklearn.multiclass.OneVsRestClassifier'>, 'Out': {5:                                                 ...AGTACGGCCACGTGGTCTTCACGCTCGAACCATTGCC...   741091, 6: (78731623, 2), 9:                                                 ...CGGAGTGAACATCAGGAACAGCAGTGACGCGAAGGTG...  1004901, 10: (214419, 2), 12:    0    1    2    3    4    5    6    7    8    ...  0    1    1  1004901  \n\n[10 rows x 257 columns], 35: RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), 37: 0.6566624691012546, 38: array([[ 447,    0,  235,    8,  159,   39,  441... 20,  396,    6,  277, 6681]],\n      dtype=int64), 60: RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), 62: 0.6550767221678093, ...}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'RandomizedSearchCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, 'SVC': <class 'sklearn.svm.classes.SVC'>, ...}\n   2964             finally:\n   2965                 # Reset our crash handler in place\n   2966                 sys.excepthook = old_excepthook\n   2967         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\Administrator\\Repos\\Microbiomics\\<ipython-input-77-8187a86681d1> in <module>()\n      3 rf = RandomForestClassifier()\n      4 # Random search of parameters, using 3 fold cross validation, \n      5 # search across 100 different combinations, and use all available cores\n      6 rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n      7 # Fit the random search model\n----> 8 get_ipython().run_line_magic('time', 'rf_random.fit(x_train, y_train)')\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_line_magic(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, magic_name='time', line='rf_random.fit(x_train, y_train)', _stack_depth=1)\n   2126             kwargs = {}\n   2127             # Grab local namespace if we need it:\n   2128             if getattr(fn, \"needs_local_scope\", False):\n   2129                 kwargs['local_ns'] = sys._getframe(stack_depth).f_locals\n   2130             with self.builtin_trap:\n-> 2131                 result = fn(*args,**kwargs)\n        result = undefined\n        fn = <bound method ExecutionMagics.time of <IPython.core.magics.execution.ExecutionMagics object>>\n        args = ['rf_random.fit(x_train, y_train)']\n        kwargs = {'local_ns': {'BaggingClassifier': <class 'sklearn.ensemble.bagging.BaggingClassifier'>, 'Bio': <module 'Bio' from 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\Bio\\\\__init__.py'>, 'Evaluator': <class 'mlens.model_selection.model_selection.Evaluator'>, 'In': ['', 'import Bio\\nfrom Bio import SeqIO\\nimport numpy as...ver\\n\\nsub_data_root = data_root + \"sample01split/\"', \"def make_features(seq, sub_seq_bank, lable):\\n   ...s)\\n    df['lable'] = lable    \\n    return df\\n    \", 'df1 = pd.read_pickle(data_root + \"DNA_data1.pickle\")', 'df2 = pd.read_pickle(data_root + \"DNA_data2.pickle\")', 'print(df1.shape)\\nprint(df2.shape)\\ndf = pd.concat([df1, df2]) \\n\\ndf.head()', 'df.shape', \"with open(data_root + 'taxid.txt') as f:\\n    keys = f.readlines()\\nkeys = [x.strip() for x in keys] \", \"some_values = keys[:10]\\ndf1 = df.loc[df['lable'].isin(some_values)]\", 'df1.head(10)', 'gc.collect()\\ndf1.shape', \"get_ipython().run_line_magic('time', 'df1 =  convert_read_to_numb(df1, 4)')\", 'df1.head(10)', 'columns = list(df1.columns.values)\\nprint(type(co...alues[:, :-1]\\ny = df1.values[:, -1]\\n# df.head(20)', '# pickle_file = data_root + \"DNA_data.pickle\"\\n\\n#...o save data to\\', pickle_file, \\':\\', e)\\n#     raise', 'x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)', '# %time gbm = xgb.XGBClassifier(max_depth=4, n_e... n_jobs=32).fit(x_train, y_train)\\n# print(\"done\")', '# %time y_pred = gbm.predict(x_test)\\n# print(\"done\")', '# accuracy_score(y_test, y_pred)', \"# plot_confusion_matrix(confusion_matrix(y_test, y_pred), ['a','b'], normalize=True)\", ...], 'LGBMClassifier': <class 'lightgbm.sklearn.LGBMClassifier'>, 'OneVsRestClassifier': <class 'sklearn.multiclass.OneVsRestClassifier'>, 'Out': {5:                                                 ...AGTACGGCCACGTGGTCTTCACGCTCGAACCATTGCC...   741091, 6: (78731623, 2), 9:                                                 ...CGGAGTGAACATCAGGAACAGCAGTGACGCGAAGGTG...  1004901, 10: (214419, 2), 12:    0    1    2    3    4    5    6    7    8    ...  0    1    1  1004901  \n\n[10 rows x 257 columns], 35: RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), 37: 0.6566624691012546, 38: array([[ 447,    0,  235,    8,  159,   39,  441... 20,  396,    6,  277, 6681]],\n      dtype=int64), 60: RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), 62: 0.6550767221678093, ...}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'RandomizedSearchCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, 'SVC': <class 'sklearn.svm.classes.SVC'>, ...}}\n   2132             return result\n   2133 \n   2134     def run_cell_magic(self, magic_name, line, cell):\n   2135         \"\"\"Execute the given cell magic.\n\n...........................................................................\nC:\\Users\\Administrator\\Repos\\Microbiomics\\<decorator-gen-63> in time(self=<IPython.core.magics.execution.ExecutionMagics object>, line='rf_random.fit(x_train, y_train)', cell=None, local_ns={'BaggingClassifier': <class 'sklearn.ensemble.bagging.BaggingClassifier'>, 'Bio': <module 'Bio' from 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\Bio\\\\__init__.py'>, 'Evaluator': <class 'mlens.model_selection.model_selection.Evaluator'>, 'In': ['', 'import Bio\\nfrom Bio import SeqIO\\nimport numpy as...ver\\n\\nsub_data_root = data_root + \"sample01split/\"', \"def make_features(seq, sub_seq_bank, lable):\\n   ...s)\\n    df['lable'] = lable    \\n    return df\\n    \", 'df1 = pd.read_pickle(data_root + \"DNA_data1.pickle\")', 'df2 = pd.read_pickle(data_root + \"DNA_data2.pickle\")', 'print(df1.shape)\\nprint(df2.shape)\\ndf = pd.concat([df1, df2]) \\n\\ndf.head()', 'df.shape', \"with open(data_root + 'taxid.txt') as f:\\n    keys = f.readlines()\\nkeys = [x.strip() for x in keys] \", \"some_values = keys[:10]\\ndf1 = df.loc[df['lable'].isin(some_values)]\", 'df1.head(10)', 'gc.collect()\\ndf1.shape', \"get_ipython().run_line_magic('time', 'df1 =  convert_read_to_numb(df1, 4)')\", 'df1.head(10)', 'columns = list(df1.columns.values)\\nprint(type(co...alues[:, :-1]\\ny = df1.values[:, -1]\\n# df.head(20)', '# pickle_file = data_root + \"DNA_data.pickle\"\\n\\n#...o save data to\\', pickle_file, \\':\\', e)\\n#     raise', 'x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)', '# %time gbm = xgb.XGBClassifier(max_depth=4, n_e... n_jobs=32).fit(x_train, y_train)\\n# print(\"done\")', '# %time y_pred = gbm.predict(x_test)\\n# print(\"done\")', '# accuracy_score(y_test, y_pred)', \"# plot_confusion_matrix(confusion_matrix(y_test, y_pred), ['a','b'], normalize=True)\", ...], 'LGBMClassifier': <class 'lightgbm.sklearn.LGBMClassifier'>, 'OneVsRestClassifier': <class 'sklearn.multiclass.OneVsRestClassifier'>, 'Out': {5:                                                 ...AGTACGGCCACGTGGTCTTCACGCTCGAACCATTGCC...   741091, 6: (78731623, 2), 9:                                                 ...CGGAGTGAACATCAGGAACAGCAGTGACGCGAAGGTG...  1004901, 10: (214419, 2), 12:    0    1    2    3    4    5    6    7    8    ...  0    1    1  1004901  \n\n[10 rows x 257 columns], 35: RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), 37: 0.6566624691012546, 38: array([[ 447,    0,  235,    8,  159,   39,  441... 20,  396,    6,  277, 6681]],\n      dtype=int64), 60: RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), 62: 0.6550767221678093, ...}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'RandomizedSearchCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, 'SVC': <class 'sklearn.svm.classes.SVC'>, ...})\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\magic.py in <lambda>(f=<function ExecutionMagics.time>, *a=(<IPython.core.magics.execution.ExecutionMagics object>, 'rf_random.fit(x_train, y_train)', None, {'BaggingClassifier': <class 'sklearn.ensemble.bagging.BaggingClassifier'>, 'Bio': <module 'Bio' from 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\Bio\\\\__init__.py'>, 'Evaluator': <class 'mlens.model_selection.model_selection.Evaluator'>, 'In': ['', 'import Bio\\nfrom Bio import SeqIO\\nimport numpy as...ver\\n\\nsub_data_root = data_root + \"sample01split/\"', \"def make_features(seq, sub_seq_bank, lable):\\n   ...s)\\n    df['lable'] = lable    \\n    return df\\n    \", 'df1 = pd.read_pickle(data_root + \"DNA_data1.pickle\")', 'df2 = pd.read_pickle(data_root + \"DNA_data2.pickle\")', 'print(df1.shape)\\nprint(df2.shape)\\ndf = pd.concat([df1, df2]) \\n\\ndf.head()', 'df.shape', \"with open(data_root + 'taxid.txt') as f:\\n    keys = f.readlines()\\nkeys = [x.strip() for x in keys] \", \"some_values = keys[:10]\\ndf1 = df.loc[df['lable'].isin(some_values)]\", 'df1.head(10)', 'gc.collect()\\ndf1.shape', \"get_ipython().run_line_magic('time', 'df1 =  convert_read_to_numb(df1, 4)')\", 'df1.head(10)', 'columns = list(df1.columns.values)\\nprint(type(co...alues[:, :-1]\\ny = df1.values[:, -1]\\n# df.head(20)', '# pickle_file = data_root + \"DNA_data.pickle\"\\n\\n#...o save data to\\', pickle_file, \\':\\', e)\\n#     raise', 'x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)', '# %time gbm = xgb.XGBClassifier(max_depth=4, n_e... n_jobs=32).fit(x_train, y_train)\\n# print(\"done\")', '# %time y_pred = gbm.predict(x_test)\\n# print(\"done\")', '# accuracy_score(y_test, y_pred)', \"# plot_confusion_matrix(confusion_matrix(y_test, y_pred), ['a','b'], normalize=True)\", ...], 'LGBMClassifier': <class 'lightgbm.sklearn.LGBMClassifier'>, 'OneVsRestClassifier': <class 'sklearn.multiclass.OneVsRestClassifier'>, 'Out': {5:                                                 ...AGTACGGCCACGTGGTCTTCACGCTCGAACCATTGCC...   741091, 6: (78731623, 2), 9:                                                 ...CGGAGTGAACATCAGGAACAGCAGTGACGCGAAGGTG...  1004901, 10: (214419, 2), 12:    0    1    2    3    4    5    6    7    8    ...  0    1    1  1004901  \n\n[10 rows x 257 columns], 35: RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), 37: 0.6566624691012546, 38: array([[ 447,    0,  235,    8,  159,   39,  441... 20,  396,    6,  277, 6681]],\n      dtype=int64), 60: RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), 62: 0.6550767221678093, ...}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'RandomizedSearchCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, 'SVC': <class 'sklearn.svm.classes.SVC'>, ...}), **k={})\n    182     validate_type(magic_kind)\n    183 \n    184     # This is a closure to capture the magic_kind.  We could also use a class,\n    185     # but it's overkill for just that one bit of state.\n    186     def magic_deco(arg):\n--> 187         call = lambda f, *a, **k: f(*a, **k)\n        f = <function ExecutionMagics.time>\n        a = (<IPython.core.magics.execution.ExecutionMagics object>, 'rf_random.fit(x_train, y_train)', None, {'BaggingClassifier': <class 'sklearn.ensemble.bagging.BaggingClassifier'>, 'Bio': <module 'Bio' from 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\Bio\\\\__init__.py'>, 'Evaluator': <class 'mlens.model_selection.model_selection.Evaluator'>, 'In': ['', 'import Bio\\nfrom Bio import SeqIO\\nimport numpy as...ver\\n\\nsub_data_root = data_root + \"sample01split/\"', \"def make_features(seq, sub_seq_bank, lable):\\n   ...s)\\n    df['lable'] = lable    \\n    return df\\n    \", 'df1 = pd.read_pickle(data_root + \"DNA_data1.pickle\")', 'df2 = pd.read_pickle(data_root + \"DNA_data2.pickle\")', 'print(df1.shape)\\nprint(df2.shape)\\ndf = pd.concat([df1, df2]) \\n\\ndf.head()', 'df.shape', \"with open(data_root + 'taxid.txt') as f:\\n    keys = f.readlines()\\nkeys = [x.strip() for x in keys] \", \"some_values = keys[:10]\\ndf1 = df.loc[df['lable'].isin(some_values)]\", 'df1.head(10)', 'gc.collect()\\ndf1.shape', \"get_ipython().run_line_magic('time', 'df1 =  convert_read_to_numb(df1, 4)')\", 'df1.head(10)', 'columns = list(df1.columns.values)\\nprint(type(co...alues[:, :-1]\\ny = df1.values[:, -1]\\n# df.head(20)', '# pickle_file = data_root + \"DNA_data.pickle\"\\n\\n#...o save data to\\', pickle_file, \\':\\', e)\\n#     raise', 'x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)', '# %time gbm = xgb.XGBClassifier(max_depth=4, n_e... n_jobs=32).fit(x_train, y_train)\\n# print(\"done\")', '# %time y_pred = gbm.predict(x_test)\\n# print(\"done\")', '# accuracy_score(y_test, y_pred)', \"# plot_confusion_matrix(confusion_matrix(y_test, y_pred), ['a','b'], normalize=True)\", ...], 'LGBMClassifier': <class 'lightgbm.sklearn.LGBMClassifier'>, 'OneVsRestClassifier': <class 'sklearn.multiclass.OneVsRestClassifier'>, 'Out': {5:                                                 ...AGTACGGCCACGTGGTCTTCACGCTCGAACCATTGCC...   741091, 6: (78731623, 2), 9:                                                 ...CGGAGTGAACATCAGGAACAGCAGTGACGCGAAGGTG...  1004901, 10: (214419, 2), 12:    0    1    2    3    4    5    6    7    8    ...  0    1    1  1004901  \n\n[10 rows x 257 columns], 35: RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), 37: 0.6566624691012546, 38: array([[ 447,    0,  235,    8,  159,   39,  441... 20,  396,    6,  277, 6681]],\n      dtype=int64), 60: RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), 62: 0.6550767221678093, ...}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'RandomizedSearchCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, 'SVC': <class 'sklearn.svm.classes.SVC'>, ...})\n        k = {}\n    188 \n    189         if callable(arg):\n    190             # \"Naked\" decorator call (just @foo, no args)\n    191             func = arg\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\magics\\execution.py in time(self=<IPython.core.magics.execution.ExecutionMagics object>, line='rf_random.fit(x_train, y_train)', cell=None, local_ns={'BaggingClassifier': <class 'sklearn.ensemble.bagging.BaggingClassifier'>, 'Bio': <module 'Bio' from 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\Bio\\\\__init__.py'>, 'Evaluator': <class 'mlens.model_selection.model_selection.Evaluator'>, 'In': ['', 'import Bio\\nfrom Bio import SeqIO\\nimport numpy as...ver\\n\\nsub_data_root = data_root + \"sample01split/\"', \"def make_features(seq, sub_seq_bank, lable):\\n   ...s)\\n    df['lable'] = lable    \\n    return df\\n    \", 'df1 = pd.read_pickle(data_root + \"DNA_data1.pickle\")', 'df2 = pd.read_pickle(data_root + \"DNA_data2.pickle\")', 'print(df1.shape)\\nprint(df2.shape)\\ndf = pd.concat([df1, df2]) \\n\\ndf.head()', 'df.shape', \"with open(data_root + 'taxid.txt') as f:\\n    keys = f.readlines()\\nkeys = [x.strip() for x in keys] \", \"some_values = keys[:10]\\ndf1 = df.loc[df['lable'].isin(some_values)]\", 'df1.head(10)', 'gc.collect()\\ndf1.shape', \"get_ipython().run_line_magic('time', 'df1 =  convert_read_to_numb(df1, 4)')\", 'df1.head(10)', 'columns = list(df1.columns.values)\\nprint(type(co...alues[:, :-1]\\ny = df1.values[:, -1]\\n# df.head(20)', '# pickle_file = data_root + \"DNA_data.pickle\"\\n\\n#...o save data to\\', pickle_file, \\':\\', e)\\n#     raise', 'x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)', '# %time gbm = xgb.XGBClassifier(max_depth=4, n_e... n_jobs=32).fit(x_train, y_train)\\n# print(\"done\")', '# %time y_pred = gbm.predict(x_test)\\n# print(\"done\")', '# accuracy_score(y_test, y_pred)', \"# plot_confusion_matrix(confusion_matrix(y_test, y_pred), ['a','b'], normalize=True)\", ...], 'LGBMClassifier': <class 'lightgbm.sklearn.LGBMClassifier'>, 'OneVsRestClassifier': <class 'sklearn.multiclass.OneVsRestClassifier'>, 'Out': {5:                                                 ...AGTACGGCCACGTGGTCTTCACGCTCGAACCATTGCC...   741091, 6: (78731623, 2), 9:                                                 ...CGGAGTGAACATCAGGAACAGCAGTGACGCGAAGGTG...  1004901, 10: (214419, 2), 12:    0    1    2    3    4    5    6    7    8    ...  0    1    1  1004901  \n\n[10 rows x 257 columns], 35: RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), 37: 0.6566624691012546, 38: array([[ 447,    0,  235,    8,  159,   39,  441... 20,  396,    6,  277, 6681]],\n      dtype=int64), 60: RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), 62: 0.6550767221678093, ...}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'RandomizedSearchCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, 'SVC': <class 'sklearn.svm.classes.SVC'>, ...})\n   1225         # time execution\n   1226         wall_st = wtime()\n   1227         if mode=='eval':\n   1228             st = clock2()\n   1229             try:\n-> 1230                 out = eval(code, glob, local_ns)\n        out = undefined\n        code = <code object <module> at 0x0000019211076030, file \"<timed eval>\", line 1>\n        glob = {'BaggingClassifier': <class 'sklearn.ensemble.bagging.BaggingClassifier'>, 'Bio': <module 'Bio' from 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\Bio\\\\__init__.py'>, 'Evaluator': <class 'mlens.model_selection.model_selection.Evaluator'>, 'In': ['', 'import Bio\\nfrom Bio import SeqIO\\nimport numpy as...ver\\n\\nsub_data_root = data_root + \"sample01split/\"', \"def make_features(seq, sub_seq_bank, lable):\\n   ...s)\\n    df['lable'] = lable    \\n    return df\\n    \", 'df1 = pd.read_pickle(data_root + \"DNA_data1.pickle\")', 'df2 = pd.read_pickle(data_root + \"DNA_data2.pickle\")', 'print(df1.shape)\\nprint(df2.shape)\\ndf = pd.concat([df1, df2]) \\n\\ndf.head()', 'df.shape', \"with open(data_root + 'taxid.txt') as f:\\n    keys = f.readlines()\\nkeys = [x.strip() for x in keys] \", \"some_values = keys[:10]\\ndf1 = df.loc[df['lable'].isin(some_values)]\", 'df1.head(10)', 'gc.collect()\\ndf1.shape', \"get_ipython().run_line_magic('time', 'df1 =  convert_read_to_numb(df1, 4)')\", 'df1.head(10)', 'columns = list(df1.columns.values)\\nprint(type(co...alues[:, :-1]\\ny = df1.values[:, -1]\\n# df.head(20)', '# pickle_file = data_root + \"DNA_data.pickle\"\\n\\n#...o save data to\\', pickle_file, \\':\\', e)\\n#     raise', 'x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)', '# %time gbm = xgb.XGBClassifier(max_depth=4, n_e... n_jobs=32).fit(x_train, y_train)\\n# print(\"done\")', '# %time y_pred = gbm.predict(x_test)\\n# print(\"done\")', '# accuracy_score(y_test, y_pred)', \"# plot_confusion_matrix(confusion_matrix(y_test, y_pred), ['a','b'], normalize=True)\", ...], 'LGBMClassifier': <class 'lightgbm.sklearn.LGBMClassifier'>, 'OneVsRestClassifier': <class 'sklearn.multiclass.OneVsRestClassifier'>, 'Out': {5:                                                 ...AGTACGGCCACGTGGTCTTCACGCTCGAACCATTGCC...   741091, 6: (78731623, 2), 9:                                                 ...CGGAGTGAACATCAGGAACAGCAGTGACGCGAAGGTG...  1004901, 10: (214419, 2), 12:    0    1    2    3    4    5    6    7    8    ...  0    1    1  1004901  \n\n[10 rows x 257 columns], 35: RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), 37: 0.6566624691012546, 38: array([[ 447,    0,  235,    8,  159,   39,  441... 20,  396,    6,  277, 6681]],\n      dtype=int64), 60: RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), 62: 0.6550767221678093, ...}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'RandomizedSearchCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, 'SVC': <class 'sklearn.svm.classes.SVC'>, ...}\n        local_ns = {'BaggingClassifier': <class 'sklearn.ensemble.bagging.BaggingClassifier'>, 'Bio': <module 'Bio' from 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\Bio\\\\__init__.py'>, 'Evaluator': <class 'mlens.model_selection.model_selection.Evaluator'>, 'In': ['', 'import Bio\\nfrom Bio import SeqIO\\nimport numpy as...ver\\n\\nsub_data_root = data_root + \"sample01split/\"', \"def make_features(seq, sub_seq_bank, lable):\\n   ...s)\\n    df['lable'] = lable    \\n    return df\\n    \", 'df1 = pd.read_pickle(data_root + \"DNA_data1.pickle\")', 'df2 = pd.read_pickle(data_root + \"DNA_data2.pickle\")', 'print(df1.shape)\\nprint(df2.shape)\\ndf = pd.concat([df1, df2]) \\n\\ndf.head()', 'df.shape', \"with open(data_root + 'taxid.txt') as f:\\n    keys = f.readlines()\\nkeys = [x.strip() for x in keys] \", \"some_values = keys[:10]\\ndf1 = df.loc[df['lable'].isin(some_values)]\", 'df1.head(10)', 'gc.collect()\\ndf1.shape', \"get_ipython().run_line_magic('time', 'df1 =  convert_read_to_numb(df1, 4)')\", 'df1.head(10)', 'columns = list(df1.columns.values)\\nprint(type(co...alues[:, :-1]\\ny = df1.values[:, -1]\\n# df.head(20)', '# pickle_file = data_root + \"DNA_data.pickle\"\\n\\n#...o save data to\\', pickle_file, \\':\\', e)\\n#     raise', 'x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)', '# %time gbm = xgb.XGBClassifier(max_depth=4, n_e... n_jobs=32).fit(x_train, y_train)\\n# print(\"done\")', '# %time y_pred = gbm.predict(x_test)\\n# print(\"done\")', '# accuracy_score(y_test, y_pred)', \"# plot_confusion_matrix(confusion_matrix(y_test, y_pred), ['a','b'], normalize=True)\", ...], 'LGBMClassifier': <class 'lightgbm.sklearn.LGBMClassifier'>, 'OneVsRestClassifier': <class 'sklearn.multiclass.OneVsRestClassifier'>, 'Out': {5:                                                 ...AGTACGGCCACGTGGTCTTCACGCTCGAACCATTGCC...   741091, 6: (78731623, 2), 9:                                                 ...CGGAGTGAACATCAGGAACAGCAGTGACGCGAAGGTG...  1004901, 10: (214419, 2), 12:    0    1    2    3    4    5    6    7    8    ...  0    1    1  1004901  \n\n[10 rows x 257 columns], 35: RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), 37: 0.6566624691012546, 38: array([[ 447,    0,  235,    8,  159,   39,  441... 20,  396,    6,  277, 6681]],\n      dtype=int64), 60: RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), 62: 0.6550767221678093, ...}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'RandomizedSearchCV': <class 'sklearn.model_selection._search.RandomizedSearchCV'>, 'SVC': <class 'sklearn.svm.classes.SVC'>, ...}\n   1231             except:\n   1232                 self.shell.showtraceback()\n   1233                 return\n   1234             end = clock2()\n\n...........................................................................\nC:\\Users\\Administrator\\Repos\\Microbiomics\\<timed eval> in <module>()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py in fit(self=RandomizedSearchCV(cv=3, error_score='raise',\n  ...turn_train_score='warn', scoring=None, verbose=2), X=array([[-0.64711261, -0.67223719, -0.74219387, .... -0.62177941,\n        -0.61905645,  0.60391137]]), y=array(['1004901', '1017', '1017', ..., '100901', '1019', '1007676'],\n      dtype=object), groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=3, random_state=None, shuffle=False)>\n        X = array([[-0.64711261, -0.67223719, -0.74219387, .... -0.62177941,\n        -0.61905645,  0.60391137]])\n        y = array(['1004901', '1017', '1017', ..., '100901', '1019', '1007676'],\n      dtype=object)\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nMemoryError                                        Tue Jun 12 12:36:29 2018\nPID: 9936                 Python 3.6.5: C:\\ProgramData\\Anaconda3\\python.exe\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645,  0.60391137]]), array(['1004901', '1017', '1017', ..., '100901', '1019', '1007676'],\n      dtype=object), {'score': <function _passthrough_scorer>}, array([     0,      1,      2, ..., 115156, 115171, 115183]), array([112744, 112746, 112763, ..., 171524, 171525, 171526]), 2, {'bootstrap': True, 'max_depth': 30, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 400}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645,  0.60391137]]), array(['1004901', '1017', '1017', ..., '100901', '1019', '1007676'],\n      dtype=object), {'score': <function _passthrough_scorer>}, array([     0,      1,      2, ..., 115156, 115171, 115183]), array([112744, 112746, 112763, ..., 171524, 171525, 171526]), 2, {'bootstrap': True, 'max_depth': 30, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 400})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645,  0.60391137]]), y=array(['1004901', '1017', '1017', ..., '100901', '1019', '1007676'],\n      dtype=object), scorer={'score': <function _passthrough_scorer>}, train=array([     0,      1,      2, ..., 115156, 115171, 115183]), test=array([112744, 112746, 112763, ..., 171524, 171525, 171526]), verbose=2, parameters={'bootstrap': True, 'max_depth': 30, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 400}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    487         # _score will return dict if is_multimetric is True\n    488         test_scores = _score(estimator, X_test, y_test, scorer, is_multimetric)\n    489         score_time = time.time() - start_time - fit_time\n    490         if return_train_score:\n    491             train_scores = _score(estimator, X_train, y_train, scorer,\n--> 492                                   is_multimetric)\n        is_multimetric = True\n    493 \n    494     if verbose > 2:\n    495         if is_multimetric:\n    496             for scorer_name, score in test_scores.items():\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _score(estimator=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X_test=memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645, -0.55143271]]), y_test=array(['1004901', '1017', '1017', ..., '1007676', '1007676', '1007676'],\n      dtype=object), scorer={'score': <function _passthrough_scorer>}, is_multimetric=True)\n    518 \n    519     Will return a single float if is_multimetric is False and a dict of floats,\n    520     if is_multimetric is True\n    521     \"\"\"\n    522     if is_multimetric:\n--> 523         return _multimetric_score(estimator, X_test, y_test, scorer)\n        estimator = RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False)\n        X_test = memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645, -0.55143271]])\n        y_test = array(['1004901', '1017', '1017', ..., '1007676', '1007676', '1007676'],\n      dtype=object)\n        scorer = {'score': <function _passthrough_scorer>}\n    524     else:\n    525         if y_test is None:\n    526             score = scorer(estimator, X_test)\n    527         else:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _multimetric_score(estimator=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X_test=memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645, -0.55143271]]), y_test=array(['1004901', '1017', '1017', ..., '1007676', '1007676', '1007676'],\n      dtype=object), scorers={'score': <function _passthrough_scorer>})\n    548 \n    549     for name, scorer in scorers.items():\n    550         if y_test is None:\n    551             score = scorer(estimator, X_test)\n    552         else:\n--> 553             score = scorer(estimator, X_test, y_test)\n        score = undefined\n        scorer = <function _passthrough_scorer>\n        estimator = RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False)\n        X_test = memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645, -0.55143271]])\n        y_test = array(['1004901', '1017', '1017', ..., '1007676', '1007676', '1007676'],\n      dtype=object)\n    554 \n    555         if hasattr(score, 'item'):\n    556             try:\n    557                 # e.g. unwrap memmapped scalars\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py in _passthrough_scorer(estimator=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), *args=(memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645, -0.55143271]]), array(['1004901', '1017', '1017', ..., '1007676', '1007676', '1007676'],\n      dtype=object)), **kwargs={})\n    239     return scorer\n    240 \n    241 \n    242 def _passthrough_scorer(estimator, *args, **kwargs):\n    243     \"\"\"Function that wraps estimator.score\"\"\"\n--> 244     return estimator.score(*args, **kwargs)\n        estimator.score = <bound method ClassifierMixin.score of RandomFor...e=None, verbose=0,\n            warm_start=False)>\n        args = (memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645, -0.55143271]]), array(['1004901', '1017', '1017', ..., '1007676', '1007676', '1007676'],\n      dtype=object))\n        kwargs = {}\n    245 \n    246 \n    247 def check_scoring(estimator, scoring=None, allow_none=False):\n    248     \"\"\"Determine scorer from user options.\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in score(self=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645, -0.55143271]]), y=array(['1004901', '1017', '1017', ..., '1007676', '1007676', '1007676'],\n      dtype=object), sample_weight=None)\n    344         score : float\n    345             Mean accuracy of self.predict(X) wrt. y.\n    346 \n    347         \"\"\"\n    348         from .metrics import accuracy_score\n--> 349         return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n        accuracy_score = <function accuracy_score>\n        y = array(['1004901', '1017', '1017', ..., '1007676', '1007676', '1007676'],\n      dtype=object)\n        self.predict = <bound method ForestClassifier.predict of Random...e=None, verbose=0,\n            warm_start=False)>\n        X = memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645, -0.55143271]])\n        sample_weight = None\n    350 \n    351 \n    352 ###############################################################################\n    353 class RegressorMixin(object):\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py in predict(self=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645, -0.55143271]]))\n    533         Returns\n    534         -------\n    535         y : array of shape = [n_samples] or [n_samples, n_outputs]\n    536             The predicted classes.\n    537         \"\"\"\n--> 538         proba = self.predict_proba(X)\n        proba = undefined\n        self.predict_proba = <bound method ForestClassifier.predict_proba of ...e=None, verbose=0,\n            warm_start=False)>\n        X = memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645, -0.55143271]])\n    539 \n    540         if self.n_outputs_ == 1:\n    541             return self.classes_.take(np.argmax(proba, axis=1), axis=0)\n    542 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py in predict_proba(self=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=array([[-0.6471126 , -0.67223716, -0.7421939 , ....       -0.61905646, -0.5514327 ]], dtype=float32))\n    584         all_proba = [np.zeros((X.shape[0], j), dtype=np.float64)\n    585                      for j in np.atleast_1d(self.n_classes_)]\n    586         lock = threading.Lock()\n    587         Parallel(n_jobs=n_jobs, verbose=self.verbose, backend=\"threading\")(\n    588             delayed(accumulate_prediction)(e.predict_proba, X, all_proba, lock)\n--> 589             for e in self.estimators_)\n        self.estimators_ = [DecisionTreeClassifier(class_weight=None, criter...         random_state=139770109, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...        random_state=2092607730, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...        random_state=1871373720, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...         random_state=827927126, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...        random_state=1917753714, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...         random_state=105869161, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...         random_state=830410173, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...        random_state=1292302064, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...        random_state=1085566734, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...        random_state=1575630002, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...        random_state=1707872905, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...          random_state=24175579, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...         random_state=679395208, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...         random_state=345961450, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...        random_state=1656728939, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...         random_state=102556993, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...         random_state=836257690, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...          random_state=50688945, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...         random_state=527289821, splitter='best'), DecisionTreeClassifier(class_weight=None, criter...         random_state=602920225, splitter='best'), ...]\n    590 \n    591         for proba in all_proba:\n    592             proba /= len(self.estimators_)\n    593 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object ForestClassifier.predict_proba.<locals>.<genexpr>>)\n    774         self.n_completed_tasks = 0\n    775         try:\n    776             # Only set self._iterating to True if at least a batch\n    777             # was dispatched. In particular this covers the edge\n    778             # case of Parallel used with an exhausted iterator.\n--> 779             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>\n        iterator = <generator object ForestClassifier.predict_proba.<locals>.<genexpr>>\n    780                 self._iterating = True\n    781             else:\n    782                 self._iterating = False\n    783 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object ForestClassifier.predict_proba.<locals>.<genexpr>>)\n    620             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    621             if len(tasks) == 0:\n    622                 # No more tasks available in the iterator: tell caller to stop.\n    623                 return False\n    624             else:\n--> 625                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    626                 return True\n    627 \n    628     def _print(self, msg, msg_args):\n    629         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    583         self.n_dispatched_tasks += len(batch)\n    584         self.n_dispatched_batches += 1\n    585 \n    586         dispatch_timestamp = time.time()\n    587         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n--> 588         job = self._backend.apply_async(batch, callback=cb)\n        job = undefined\n        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>\n    589         self._jobs.append(job)\n    590 \n    591     def dispatch_next(self):\n    592         \"\"\"Dispatch more data for parallel processing\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)\n    106             raise ValueError('n_jobs == 0 in Parallel has no meaning')\n    107         return 1\n    108 \n    109     def apply_async(self, func, callback=None):\n    110         \"\"\"Schedule a func to be run\"\"\"\n--> 111         result = ImmediateResult(func)\n        result = undefined\n        func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    112         if callback:\n    113             callback(result)\n    114         return result\n    115 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    327 \n    328 class ImmediateResult(object):\n    329     def __init__(self, batch):\n    330         # Don't delay the application, to avoid keeping the input\n    331         # arguments in memory\n--> 332         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    333 \n    334     def get(self):\n    335         return self.results\n    336 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function accumulate_prediction>, (<bound method DecisionTreeClassifier.predict_pro...        random_state=106647660, splitter='best')>, array([[-0.6471126 , -0.67223716, -0.7421939 , ....       -0.61905646, -0.5514327 ]], dtype=float32), [array([[0.00000000e+00, 1.24027582e+02, 0.000000...3.24675325e-03, 1.18223316e+01, 4.77850101e+01]])], <unlocked _thread.lock object>), {})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function accumulate_prediction>\n        args = (<bound method DecisionTreeClassifier.predict_pro...        random_state=106647660, splitter='best')>, array([[-0.6471126 , -0.67223716, -0.7421939 , ....       -0.61905646, -0.5514327 ]], dtype=float32), [array([[0.00000000e+00, 1.24027582e+02, 0.000000...3.24675325e-03, 1.18223316e+01, 4.77850101e+01]])], <unlocked _thread.lock object>)\n        kwargs = {}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py in accumulate_prediction(predict=<bound method DecisionTreeClassifier.predict_pro...        random_state=106647660, splitter='best')>, X=array([[-0.6471126 , -0.67223716, -0.7421939 , ....       -0.61905646, -0.5514327 ]], dtype=float32), out=[array([[0.00000000e+00, 1.24027582e+02, 0.000000...3.24675325e-03, 1.18223316e+01, 4.77850101e+01]])], lock=<unlocked _thread.lock object>)\n    378 # This is a utility function for joblib's Parallel. It can't go locally in\n    379 # ForestClassifier or ForestRegressor, because joblib complains that it cannot\n    380 # pickle it when placed there.\n    381 \n    382 def accumulate_prediction(predict, X, out, lock):\n--> 383     prediction = predict(X, check_input=False)\n        prediction = undefined\n        predict = <bound method DecisionTreeClassifier.predict_pro...        random_state=106647660, splitter='best')>\n        X = array([[-0.6471126 , -0.67223716, -0.7421939 , ....       -0.61905646, -0.5514327 ]], dtype=float32)\n    384     with lock:\n    385         if len(out) == 1:\n    386             out[0] += prediction\n    387         else:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py in predict_proba(self=DecisionTreeClassifier(class_weight=None, criter...         random_state=106647660, splitter='best'), X=array([[-0.6471126 , -0.67223716, -0.7421939 , ....       -0.61905646, -0.5514327 ]], dtype=float32), check_input=False)\n    817             The class probabilities of the input samples. The order of the\n    818             classes corresponds to that in the attribute `classes_`.\n    819         \"\"\"\n    820         check_is_fitted(self, 'tree_')\n    821         X = self._validate_X_predict(X, check_input)\n--> 822         proba = self.tree_.predict(X)\n        proba = undefined\n        self.tree_.predict = <built-in method predict of sklearn.tree._tree.Tree object>\n        X = array([[-0.6471126 , -0.67223716, -0.7421939 , ....       -0.61905646, -0.5514327 ]], dtype=float32)\n    823 \n    824         if self.n_outputs_ == 1:\n    825             proba = proba[:, :self.n_classes_]\n    826             normalizer = proba.sum(axis=1)[:, np.newaxis]\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_tree.cp36-win_amd64.pyd in sklearn.tree._tree.Tree.predict()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_tree.cp36-win_amd64.pyd in sklearn.tree._tree.Tree.predict()\n\nMemoryError: \n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "%time rf_random.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 208 ms\n"
     ]
    }
   ],
   "source": [
    "%time y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6550767221678093"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 421,    0,  238,   10,  177,   29,  420,    0,   56,  319],\n",
       "       [   0, 4621,    0,  166,    2,    0,    7,  536,    3,    4],\n",
       "       [ 149,    3,  922,   22,  213,   53,  565,    1,  132,  636],\n",
       "       [   2,  130,    5, 4198,   38,    0,  244,  308,   38,  129],\n",
       "       [  78,    5,  171,   81, 1450,   30,  992,    0,  115,  573],\n",
       "       [  76,    0,  199,    4,  117,  205,  246,    0,   61,  348],\n",
       "       [ 104,    5,  260,  292,  419,   36, 4055,   10,  277,  850],\n",
       "       [   0,  630,    1,  547,   16,    0,   52, 4142,    8,   39],\n",
       "       [  44,    2,  135,  154,  116,   11,  623,    3, 1428, 1252],\n",
       "       [  54,    1,  194,   79,  139,   20,  378,    8,  301, 6649]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[2.52095808e-01 0.00000000e+00 1.42514970e-01 5.98802395e-03\n",
      "  1.05988024e-01 1.73652695e-02 2.51497006e-01 0.00000000e+00\n",
      "  3.35329341e-02 1.91017964e-01]\n",
      " [0.00000000e+00 8.65517887e-01 0.00000000e+00 3.10919648e-02\n",
      "  3.74601985e-04 0.00000000e+00 1.31110695e-03 1.00393332e-01\n",
      "  5.61902978e-04 7.49203971e-04]\n",
      " [5.52670623e-02 1.11275964e-03 3.41988131e-01 8.16023739e-03\n",
      "  7.90059347e-02 1.96587537e-02 2.09569733e-01 3.70919881e-04\n",
      "  4.89614243e-02 2.35905045e-01]\n",
      " [3.92772977e-04 2.55302435e-02 9.81932443e-04 8.24430479e-01\n",
      "  7.46268657e-03 0.00000000e+00 4.79183032e-02 6.04870385e-02\n",
      "  7.46268657e-03 2.53338570e-02]\n",
      " [2.23175966e-02 1.43061516e-03 4.89270386e-02 2.31759657e-02\n",
      "  4.14878398e-01 8.58369099e-03 2.83834049e-01 0.00000000e+00\n",
      "  3.29041488e-02 1.63948498e-01]\n",
      " [6.05095541e-02 0.00000000e+00 1.58439490e-01 3.18471338e-03\n",
      "  9.31528662e-02 1.63216561e-01 1.95859873e-01 0.00000000e+00\n",
      "  4.85668790e-02 2.77070064e-01]\n",
      " [1.64870006e-02 7.92644261e-04 4.12175016e-02 4.62904249e-02\n",
      "  6.64235891e-02 5.70703868e-03 6.42834496e-01 1.58528852e-03\n",
      "  4.39124921e-02 1.34749524e-01]\n",
      " [0.00000000e+00 1.15915363e-01 1.83992640e-04 1.00643974e-01\n",
      "  2.94388224e-03 0.00000000e+00 9.56761730e-03 7.62097516e-01\n",
      "  1.47194112e-03 7.17571297e-03]\n",
      " [1.16772824e-02 5.30785563e-04 3.58280255e-02 4.08704883e-02\n",
      "  3.07855626e-02 2.91932059e-03 1.65339703e-01 7.96178344e-04\n",
      "  3.78980892e-01 3.32271762e-01]\n",
      " [6.90272274e-03 1.27828199e-04 2.47986706e-02 1.00984277e-02\n",
      "  1.77681196e-02 2.55656398e-03 4.83190592e-02 1.02262559e-03\n",
      "  3.84762879e-02 8.49929694e-01]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(confusion_matrix(y_test, y_pred), some_values, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "print('Start training...')\n",
    "# train\n",
    "gbm = lgb.LGBMClassifier() #num_leaves=31, learning_rate=0.05, n_estimators=20)\n",
    "%time gbm.fit(x_train, y_train, eval_set=[(x_test, y_test)], eval_metric='l1')\n",
    "\n",
    "print('Start predicting...')\n",
    "# predict\n",
    "%time y_pred = gbm.predict(x_test)\n",
    "# eval\n",
    "# print('The rmse of prediction is:', mean_squared_error(y_test, y_pred) ** 0.5)\n",
    "\n",
    "# feature importances\n",
    "# print('Feature importances:', list(gbm.feature_importances_))\n",
    "\n",
    "# other scikit-learn modules\n",
    "# estimator = lgb.LGBMRegressor(num_leaves=31)\n",
    "\n",
    "# param_grid = {'learning_rate': [0.01, 0.1, 1], 'n_estimators': [20, 40]}\n",
    "\n",
    "# gbm = GridSearchCV(estimator, param_grid)\n",
    "\n",
    "# gbm.fit(X_train, y_train)\n",
    "\n",
    "# print('Best parameters found by grid search are:', gbm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(confusion_matrix(y_test, y_pred), ['a','b'], normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MLENS] backend: threading\n",
      "[MLENS] Found 1 residual cache(s):\n",
      "        1 (0): C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\1\\.mlens_tmp_cache_xgs6bavh\n",
      "        Total size: 0\n",
      "[MLENS] Removing... done.\n",
      "Launching job\n",
      "Evaluating 1 models for 2 parameter draws over 2 CV folds, totalling 4 fits\n"
     ]
    },
    {
     "ename": "JoblibTypeError",
     "evalue": "JoblibTypeError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x0000018D63144F60, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\ProgramD...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x0000018D63144F60, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\ProgramD...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    122         except (RuntimeError, AssertionError):\n    123             old_loop = None\n    124         try:\n    125             self._setup_logging()\n    126             asyncio.set_event_loop(self.asyncio_loop)\n--> 127             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Win...EventLoop running=True closed=False debug=False>>\n    128         finally:\n    129             asyncio.set_event_loop(old_loop)\n    130 \n    131     def stop(self):\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py in run_forever(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n    417             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    418                                    finalizer=self._asyncgen_finalizer_hook)\n    419         try:\n    420             events._set_running_loop(self)\n    421             while True:\n--> 422                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_Windo...EventLoop running=True closed=False debug=False>>\n    423                 if self._stopping:\n    424                     break\n    425         finally:\n    426             self._stopping = False\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py in _run_once(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n   1427                         logger.warning('Executing %s took %.3f seconds',\n   1428                                        _format_handle(handle), dt)\n   1429                 finally:\n   1430                     self._current_handle = None\n   1431             else:\n-> 1432                 handle._run()\n        handle._run = <bound method Handle._run of <Handle BaseAsyncIOLoop._handle_events(616, 1)>>\n   1433         handle = None  # Needed to break cycles when an exception occurs.\n   1434 \n   1435     def _set_coroutine_wrapper(self, enabled):\n   1436         try:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\asyncio\\events.py in _run(self=<Handle BaseAsyncIOLoop._handle_events(616, 1)>)\n    140             self._callback = None\n    141             self._args = None\n    142 \n    143     def _run(self):\n    144         try:\n--> 145             self._callback(*self._args)\n        self._callback = <bound method BaseAsyncIOLoop._handle_events of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (616, 1)\n    146         except Exception as exc:\n    147             cb = _format_callback_source(self._callback, self._args)\n    148             msg = 'Exception in callback {}'.format(cb)\n    149             context = {\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in _handle_events(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, fd=616, events=1)\n    112             self.writers.remove(fd)\n    113         del self.handlers[fd]\n    114 \n    115     def _handle_events(self, fd, events):\n    116         fileobj, handler_func = self.handlers[fd]\n--> 117         handler_func(fileobj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fileobj = <zmq.sugar.socket.Socket object>\n        events = 1\n    118 \n    119     def start(self):\n    120         try:\n    121             old_loop = asyncio.get_event_loop()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"from lightgbm import LGBMClassifier\\nfrom mlens.m...child_weight': randint(30,60)}\\n         }\\n      )\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 6, 12, 19, 6, 20, 827018, tzinfo=tzutc()), 'msg_id': 'd48e5cd8e07f4f5f8912272d67402421', 'msg_type': 'execute_request', 'session': '80fbe17cc4434eb688e083bb3a3ea874', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'd48e5cd8e07f4f5f8912272d67402421', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'80fbe17cc4434eb688e083bb3a3ea874']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"from lightgbm import LGBMClassifier\\nfrom mlens.m...child_weight': randint(30,60)}\\n         }\\n      )\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 6, 12, 19, 6, 20, 827018, tzinfo=tzutc()), 'msg_id': 'd48e5cd8e07f4f5f8912272d67402421', 'msg_type': 'execute_request', 'session': '80fbe17cc4434eb688e083bb3a3ea874', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'd48e5cd8e07f4f5f8912272d67402421', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'80fbe17cc4434eb688e083bb3a3ea874'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"from lightgbm import LGBMClassifier\\nfrom mlens.m...child_weight': randint(30,60)}\\n         }\\n      )\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 6, 12, 19, 6, 20, 827018, tzinfo=tzutc()), 'msg_id': 'd48e5cd8e07f4f5f8912272d67402421', 'msg_type': 'execute_request', 'session': '80fbe17cc4434eb688e083bb3a3ea874', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'd48e5cd8e07f4f5f8912272d67402421', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"from lightgbm import LGBMClassifier\\nfrom mlens.m...child_weight': randint(30,60)}\\n         }\\n      )\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"from lightgbm import LGBMClassifier\\nfrom mlens.m...child_weight': randint(30,60)}\\n         }\\n      )\"\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"from lightgbm import LGBMClassifier\\nfrom mlens.m...child_weight': randint(30,60)}\\n         }\\n      )\",), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"from lightgbm import LGBMClassifier\\nfrom mlens.m...child_weight': randint(30,60)}\\n         }\\n      )\",)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"from lightgbm import LGBMClassifier\\nfrom mlens.m...child_weight': randint(30,60)}\\n         }\\n      )\", store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = \"from lightgbm import LGBMClassifier\\nfrom mlens.m...child_weight': randint(30,60)}\\n         }\\n      )\"\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"from lightgbm import LGBMClassifier\\nfrom mlens.m...child_weight': randint(30,60)}\\n         }\\n      )\", store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-73-d1258a45676a>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 19027a5a208, executio...rue silent=False shell_futures=True> result=None>)\n   2904                     return True\n   2905 \n   2906             for i, node in enumerate(to_run_interactive):\n   2907                 mod = ast.Interactive([node])\n   2908                 code = compiler(mod, cell_name, \"single\")\n-> 2909                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x0000018D6A517420, file \"<ipython-input-73-d1258a45676a>\", line 10>\n        result = <ExecutionResult object at 19027a5a208, executio...rue silent=False shell_futures=True> result=None>\n   2910                     return True\n   2911 \n   2912             # Flush softspace\n   2913             if softspace(sys.stdout, 0):\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x0000018D6A517420, file \"<ipython-input-73-d1258a45676a>\", line 10>, result=<ExecutionResult object at 19027a5a208, executio...rue silent=False shell_futures=True> result=None>)\n   2958         outflag = True  # happens in more places, so it's easier as default\n   2959         try:\n   2960             try:\n   2961                 self.hooks.pre_run_code_hook()\n   2962                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2963                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x0000018D6A517420, file \"<ipython-input-73-d1258a45676a>\", line 10>\n        self.user_global_ns = {'BaggingClassifier': <class 'sklearn.ensemble.bagging.BaggingClassifier'>, 'Bio': <module 'Bio' from 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\Bio\\\\__init__.py'>, 'Evaluator': <class 'mlens.model_selection.model_selection.Evaluator'>, 'In': ['', 'import Bio\\nfrom Bio import SeqIO\\nimport numpy as...ver\\n\\nsub_data_root = data_root + \"sample01split/\"', \"def make_features(seq, sub_seq_bank, lable):\\n   ...s)\\n    df['lable'] = lable    \\n    return df\\n    \", 'df1 = pd.read_pickle(data_root + \"DNA_data1.pickle\")', 'df2 = pd.read_pickle(data_root + \"DNA_data2.pickle\")', 'print(df1.shape)\\nprint(df2.shape)\\ndf = pd.concat([df1, df2]) \\n\\ndf.head()', 'df.shape', \"with open(data_root + 'taxid.txt') as f:\\n    keys = f.readlines()\\nkeys = [x.strip() for x in keys] \", \"some_values = keys[:10]\\ndf1 = df.loc[df['lable'].isin(some_values)]\", 'df1.head(10)', 'gc.collect()\\ndf1.shape', \"get_ipython().run_line_magic('time', 'df1 =  convert_read_to_numb(df1, 4)')\", 'df1.head(10)', 'columns = list(df1.columns.values)\\nprint(type(co...alues[:, :-1]\\ny = df1.values[:, -1]\\n# df.head(20)', '# pickle_file = data_root + \"DNA_data.pickle\"\\n\\n#...o save data to\\', pickle_file, \\':\\', e)\\n#     raise', 'x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)', '# %time gbm = xgb.XGBClassifier(max_depth=4, n_e... n_jobs=32).fit(x_train, y_train)\\n# print(\"done\")', '# %time y_pred = gbm.predict(x_test)\\n# print(\"done\")', '# accuracy_score(y_test, y_pred)', \"# plot_confusion_matrix(confusion_matrix(y_test, y_pred), ['a','b'], normalize=True)\", ...], 'LGBMClassifier': <class 'lightgbm.sklearn.LGBMClassifier'>, 'OneVsRestClassifier': <class 'sklearn.multiclass.OneVsRestClassifier'>, 'Out': {5:                                                 ...AGTACGGCCACGTGGTCTTCACGCTCGAACCATTGCC...   741091, 6: (78731623, 2), 9:                                                 ...CGGAGTGAACATCAGGAACAGCAGTGACGCGAAGGTG...  1004901, 10: (214419, 2), 12:    0    1    2    3    4    5    6    7    8    ...  0    1    1  1004901  \n\n[10 rows x 257 columns], 35: RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), 37: 0.6566624691012546, 38: array([[ 447,    0,  235,    8,  159,   39,  441... 20,  396,    6,  277, 6681]],\n      dtype=int64), 60: RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), 62: 0.6550767221678093, ...}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'SVC': <class 'sklearn.svm.classes.SVC'>, 'SeqIO': <module 'Bio.SeqIO' from 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\Bio\\\\SeqIO\\\\__init__.py'>, ...}\n        self.user_ns = {'BaggingClassifier': <class 'sklearn.ensemble.bagging.BaggingClassifier'>, 'Bio': <module 'Bio' from 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\Bio\\\\__init__.py'>, 'Evaluator': <class 'mlens.model_selection.model_selection.Evaluator'>, 'In': ['', 'import Bio\\nfrom Bio import SeqIO\\nimport numpy as...ver\\n\\nsub_data_root = data_root + \"sample01split/\"', \"def make_features(seq, sub_seq_bank, lable):\\n   ...s)\\n    df['lable'] = lable    \\n    return df\\n    \", 'df1 = pd.read_pickle(data_root + \"DNA_data1.pickle\")', 'df2 = pd.read_pickle(data_root + \"DNA_data2.pickle\")', 'print(df1.shape)\\nprint(df2.shape)\\ndf = pd.concat([df1, df2]) \\n\\ndf.head()', 'df.shape', \"with open(data_root + 'taxid.txt') as f:\\n    keys = f.readlines()\\nkeys = [x.strip() for x in keys] \", \"some_values = keys[:10]\\ndf1 = df.loc[df['lable'].isin(some_values)]\", 'df1.head(10)', 'gc.collect()\\ndf1.shape', \"get_ipython().run_line_magic('time', 'df1 =  convert_read_to_numb(df1, 4)')\", 'df1.head(10)', 'columns = list(df1.columns.values)\\nprint(type(co...alues[:, :-1]\\ny = df1.values[:, -1]\\n# df.head(20)', '# pickle_file = data_root + \"DNA_data.pickle\"\\n\\n#...o save data to\\', pickle_file, \\':\\', e)\\n#     raise', 'x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)', '# %time gbm = xgb.XGBClassifier(max_depth=4, n_e... n_jobs=32).fit(x_train, y_train)\\n# print(\"done\")', '# %time y_pred = gbm.predict(x_test)\\n# print(\"done\")', '# accuracy_score(y_test, y_pred)', \"# plot_confusion_matrix(confusion_matrix(y_test, y_pred), ['a','b'], normalize=True)\", ...], 'LGBMClassifier': <class 'lightgbm.sklearn.LGBMClassifier'>, 'OneVsRestClassifier': <class 'sklearn.multiclass.OneVsRestClassifier'>, 'Out': {5:                                                 ...AGTACGGCCACGTGGTCTTCACGCTCGAACCATTGCC...   741091, 6: (78731623, 2), 9:                                                 ...CGGAGTGAACATCAGGAACAGCAGTGACGCGAAGGTG...  1004901, 10: (214419, 2), 12:    0    1    2    3    4    5    6    7    8    ...  0    1    1  1004901  \n\n[10 rows x 257 columns], 35: RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), 37: 0.6566624691012546, 38: array([[ 447,    0,  235,    8,  159,   39,  441... 20,  396,    6,  277, 6681]],\n      dtype=int64), 60: RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), 62: 0.6550767221678093, ...}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'SVC': <class 'sklearn.svm.classes.SVC'>, 'SeqIO': <module 'Bio.SeqIO' from 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\Bio\\\\SeqIO\\\\__init__.py'>, ...}\n   2964             finally:\n   2965                 # Reset our crash handler in place\n   2966                 sys.excepthook = old_excepthook\n   2967         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\Administrator\\Repos\\Microbiomics\\<ipython-input-73-d1258a45676a> in <module>()\n     10 evl.fit(x_train, y_train, [('model', LGBMClassifier(nthread=-1))],\n     11          {'model':\n     12                   {'learning_rate': uniform(0.02,0.04),\n     13                    'num_leaves': randint(50, 60),\n     14                   'n_estimators': randint(150,200),\n---> 15                   'min_child_weight': randint(30,60)}\n     16          }\n     17       )\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\model_selection\\model_selection.py in fit(self=<mlens.model_selection.model_selection.Evaluator object>, X=array([[-0.64711261, -0.67223719, -0.74219387, .... -0.62177941,\n        -0.61905645,  0.60391137]]), y=array(['1004901', '1017', '1017', ..., '100901', '1019', '1007676'],\n      dtype=object), estimators=[('model', LGBMClassifier(boosting_type='gbdt', class_weigh...=1.0, subsample_for_bin=200000, subsample_freq=1))], param_dicts={'model': {'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object>, 'min_child_weight': <scipy.stats._distn_infrastructure.rv_frozen object>, 'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object>, 'num_leaves': <scipy.stats._distn_infrastructure.rv_frozen object>}}, n_iter=2, preprocessing=None)\n    502             class instance with stored estimator evaluation results in\n    503             the ``results`` attribute.\n    504         \"\"\"\n    505         job = set_job(estimators, preprocessing)\n    506         self._initialize(job, estimators, preprocessing, param_dicts, n_iter)\n--> 507         self._fit(X, y, job)\n        self._fit = <bound method BaseEval._fit of <mlens.model_selection.model_selection.Evaluator object>>\n        X = array([[-0.64711261, -0.67223719, -0.74219387, .... -0.62177941,\n        -0.61905645,  0.60391137]])\n        y = array(['1004901', '1017', '1017', ..., '100901', '1019', '1007676'],\n      dtype=object)\n        job = 'evaluate'\n    508         self._get_results()\n    509         return self\n    510 \n    511     def _initialize(self, job, estimators, preprocessing, param_dicts, n_iter):\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\model_selection\\model_selection.py in _fit(self=<mlens.model_selection.model_selection.Evaluator object>, X=array([[-0.64711261, -0.67223719, -0.74219387, .... -0.62177941,\n        -0.61905645,  0.60391137]]), y=array(['1004901', '1017', '1017', ..., '100901', '1019', '1007676'],\n      dtype=object), job='evaluate')\n    175 \n    176     def _fit(self, X, y, job):\n    177         X, y = check_inputs(X, y, self.array_check)\n    178         verbose = max(self.verbose - 2, 0) if self.verbose < 15 else 0\n    179         with ParallelEvaluation(self.backend, self.n_jobs, verbose) as manager:\n--> 180             manager.process(self, job, X, y)\n        manager.process = <bound method ParallelEvaluation.process of <mlens.parallel.backend.ParallelEvaluation object>>\n        self = <mlens.model_selection.model_selection.Evaluator object>\n        job = 'evaluate'\n        X = array([[-0.64711261, -0.67223719, -0.74219387, .... -0.62177941,\n        -0.61905645,  0.60391137]])\n        y = array(['1004901', '1017', '1017', ..., '100901', '1019', '1007676'],\n      dtype=object)\n    181 \n    182     def collect(self, path, case):\n    183         \"\"\"Collect cache estimators\"\"\"\n    184         if case == 'transformers':\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\parallel\\backend.py in process(self=<mlens.parallel.backend.ParallelEvaluation object>, caller=<mlens.model_selection.model_selection.Evaluator object>, case='evaluate', X=array([[-0.64711261, -0.67223719, -0.74219387, .... -0.62177941,\n        -0.61905645,  0.60391137]]), y=array(['1004901', '1017', '1017', ..., '100901', '1019', '1007676'],\n      dtype=object), path=None, **kwargs={})\n    851         with Parallel(n_jobs=self.n_jobs, temp_folder=tf, max_nbytes=None,\n    852                       mmap_mode='w+', verbose=self.verbose,\n    853                       backend=self.backend) as parallel:\n    854 \n    855             caller.indexer.fit(self.job.predict_in, self.job.targets, self.job.job)\n--> 856             caller(parallel, self.job.args(**kwargs), case)\n        caller = <mlens.model_selection.model_selection.Evaluator object>\n        parallel = Parallel(n_jobs=-1)\n        self.job.args = <bound method Job.args of <mlens.parallel.backend.Job object>>\n        kwargs = {}\n        case = 'evaluate'\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\model_selection\\model_selection.py in __call__(self=<mlens.model_selection.model_selection.Evaluator object>, parallel=Parallel(n_jobs=-1), args={'auxiliary': {'P': None, 'X': memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645,  0.60391137]]), 'y': array(['1004901', '1017', '1017', ..., '100901', '1019', '1007676'],\n      dtype=object)}, 'dir': r'C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\1\\.mlens_tmp_cache_fg7ti_qu\\task_0', 'job': 'fit', 'main': {'P': None, 'X': memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645,  0.60391137]]), 'y': array(['1004901', '1017', '1017', ..., '100901', '1019', '1007676'],\n      dtype=object)}}, case='evaluate')\n    147         if 'evaluate' in case:\n    148             if self.verbose >= 2:\n    149                 safe_print(self._print_eval_start(), file=f)\n    150                 t1 = time()\n    151 \n--> 152             self._run('estimators', parallel, args)\n        self._run = <bound method BaseEval._run of <mlens.model_selection.model_selection.Evaluator object>>\n        parallel = Parallel(n_jobs=-1)\n        args = {'auxiliary': {'P': None, 'X': memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645,  0.60391137]]), 'y': array(['1004901', '1017', '1017', ..., '100901', '1019', '1007676'],\n      dtype=object)}, 'dir': r'C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\1\\.mlens_tmp_cache_fg7ti_qu\\task_0', 'job': 'fit', 'main': {'P': None, 'X': memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645,  0.60391137]]), 'y': array(['1004901', '1017', '1017', ..., '100901', '1019', '1007676'],\n      dtype=object)}}\n    153             self.collect(args['dir'], 'estimators')\n    154 \n    155             if self.verbose >= 2:\n    156                 print_time(t1, '{:<13} done'.format('Evaluation'), file=f)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\model_selection\\model_selection.py in _run(self=<mlens.model_selection.model_selection.Evaluator object>, case='estimators', parallel=Parallel(n_jobs=-1), args={'auxiliary': {'P': None, 'X': memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645,  0.60391137]]), 'y': array(['1004901', '1017', '1017', ..., '100901', '1019', '1007676'],\n      dtype=object)}, 'dir': r'C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\1\\.mlens_tmp_cache_fg7ti_qu\\task_0', 'job': 'fit', 'main': {'P': None, 'X': memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645,  0.60391137]]), 'y': array(['1004901', '1017', '1017', ..., '100901', '1019', '1007676'],\n      dtype=object)}})\n    169         else:\n    170             generator = self._learners\n    171             inp = 'main'\n    172 \n    173         parallel(delayed(subtask, not _threading)()\n--> 174                  for task in generator for subtask in task(args, inp))\n        generator = [EvalLearner(attr='predict', backend='threading',...True,\n      scorer=make_scorer(rmse), verbose=86), EvalLearner(attr='predict', backend='threading',...True,\n      scorer=make_scorer(rmse), verbose=86)]\n        args = {'auxiliary': {'P': None, 'X': memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645,  0.60391137]]), 'y': array(['1004901', '1017', '1017', ..., '100901', '1019', '1007676'],\n      dtype=object)}, 'dir': r'C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\1\\.mlens_tmp_cache_fg7ti_qu\\task_0', 'job': 'fit', 'main': {'P': None, 'X': memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645,  0.60391137]]), 'y': array(['1004901', '1017', '1017', ..., '100901', '1019', '1007676'],\n      dtype=object)}}\n    175 \n    176     def _fit(self, X, y, job):\n    177         X, y = check_inputs(X, y, self.array_check)\n    178         verbose = max(self.verbose - 2, 0) if self.verbose < 15 else 0\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseEval._run.<locals>.<genexpr>>)\n    788             if pre_dispatch == \"all\" or n_jobs == 1:\n    789                 # The iterable was consumed all at once by the above for loop.\n    790                 # No need to wait for async callbacks to trigger to\n    791                 # consumption.\n    792                 self._iterating = False\n--> 793             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    794             # Make sure that we get a last message telling us we are done\n    795             elapsed_time = time.time() - self._start_time\n    796             self._print('Done %3i out of %3i | elapsed: %s finished',\n    797                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nTypeError                                          Tue Jun 12 12:07:58 2018\nPID: 3556                 Python 3.6.5: C:\\ProgramData\\Anaconda3\\python.exe\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\externals\\joblib\\parallel.py in __call__(self=<mlens.externals.joblib.parallel.BatchedCalls object>)\n    130     def __init__(self, iterator_slice):\n    131         self.items = list(iterator_slice)\n    132         self._size = len(self.items)\n    133 \n    134     def __call__(self):\n--> 135         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<mlens.parallel.learner.EvalSubLearner object>, (), {})]\n    136 \n    137     def __len__(self):\n    138         return self._size\n    139 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    130     def __init__(self, iterator_slice):\n    131         self.items = list(iterator_slice)\n    132         self._size = len(self.items)\n    133 \n    134     def __call__(self):\n--> 135         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <mlens.parallel.learner.EvalSubLearner object>\n        args = ()\n        kwargs = {}\n    136 \n    137     def __len__(self):\n    138         return self._size\n    139 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\parallel\\learner.py in __call__(self=<mlens.parallel.learner.EvalSubLearner object>)\n    120         else:\n    121             self.processing_index = ''\n    122 \n    123     def __call__(self):\n    124         \"\"\"Launch job\"\"\"\n--> 125         return getattr(self, self.job)()\n        self = <mlens.parallel.learner.EvalSubLearner object>\n        self.job = 'fit'\n    126 \n    127     def fit(self, path=None):\n    128         \"\"\"Fit sub-learner\"\"\"\n    129         if path is None:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\parallel\\learner.py in fit(self=<mlens.parallel.learner.EvalSubLearner object>, path=r'C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\1\\.mlens_tmp_cache_fg7ti_qu\\task_0')\n    333         if self.scorer is None:\n    334             raise ValueError(\"Cannot generate CV-scores without a scorer\")\n    335         t0 = time()\n    336         transformers = self._load_preprocess(path)\n    337         self._fit(transformers)\n--> 338         self._predict(transformers)\n        self._predict = <bound method EvalSubLearner._predict of <mlens.parallel.learner.EvalSubLearner object>>\n        transformers = None\n    339 \n    340         o = IndexedEstimator(estimator=self.estimator,\n    341                              name=self.name_index,\n    342                              index=self.index,\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\parallel\\learner.py in _predict(self=<mlens.parallel.learner.EvalSubLearner object>, transformers=None, score_preds=None)\n    352 \n    353     def _predict(self, transformers, score_preds=None):\n    354         \"\"\"Sub-routine to with sublearner\"\"\"\n    355         # Train set\n    356         self.train_score_, self.train_pred_time_ = self._score_preds(\n--> 357             transformers, self.in_index)\n        transformers = None\n        self.in_index = ((85764, 171527),)\n    358 \n    359         # Validation set\n    360         self.test_score_, self.test_pred_time_ = self._score_preds(\n    361             transformers, self.out_index)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\parallel\\learner.py in _score_preds(self=<mlens.parallel.learner.EvalSubLearner object>, transformers=None, index=((85764, 171527),))\n    376                     \"Scoring failed. Setting error score %r.\"\n    377                     \"Details:\\n%r\" % (self.error_score, exc),\n    378                     FitFailedWarning)\n    379                 scores = self.error_score\n    380         else:\n--> 381             scores = self.scorer(self.estimator, xtemp, ytemp)\n        scores = undefined\n        self.scorer = make_scorer(rmse)\n        self.estimator = LGBMClassifier(boosting_type='gbdt', class_weigh...bsample_for_bin=200000,\n        subsample_freq=1)\n        xtemp = array([[-0.64711261,  1.72853073,  0.44659044, .... -0.62177941,\n        -0.61905645,  0.60391137]])\n        ytemp = array(['1010', '1019', '1010', ..., '100901', '1019', '1007676'],\n      dtype=object)\n    382         pred_time = time() - t0\n    383 \n    384         return scores, pred_time\n    385 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\externals\\sklearn\\scorer.py in __call__(self=make_scorer(rmse), estimator=LGBMClassifier(boosting_type='gbdt', class_weigh...bsample_for_bin=200000,\n        subsample_freq=1), X=array([[-0.64711261,  1.72853073,  0.44659044, .... -0.62177941,\n        -0.61905645,  0.60391137]]), y_true=array(['1010', '1019', '1010', ..., '100901', '1019', '1007676'],\n      dtype=object), sample_weight=None)\n     93             return self._sign * self._score_func(y_true, y_pred,\n     94                                                  sample_weight=sample_weight,\n     95                                                  **self._kwargs)\n     96         else:\n     97             return self._sign * self._score_func(y_true, y_pred,\n---> 98                                                  **self._kwargs)\n        self._kwargs = {}\n     99 \n    100 \n    101 class _ProbaScorer(_BaseScorer):\n    102     def __call__(self, clf, X, y, sample_weight=None):\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\metrics\\metrics.py in rmse(y=array(['1010', '1019', '1010', ..., '100901', '1019', '1007676'],\n      dtype=object), p=array(['1010', '1019', '1010', ..., '100901', '1019', '1007676'],\n      dtype=object))\n     36     Returns\n     37     -------\n     38     z: float\n     39         root mean squared error.\n     40     \"\"\"\n---> 41     z = y - p\n        z = undefined\n        y = array(['1010', '1019', '1010', ..., '100901', '1019', '1007676'],\n      dtype=object)\n        p = array(['1010', '1019', '1010', ..., '100901', '1019', '1007676'],\n      dtype=object)\n     42     return np.sqrt(np.mean(np.multiply(z, z)))\n     43 \n     44 \n     45 def mape(y, p):\n\nTypeError: unsupported operand type(s) for -: 'str' and 'str'\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\externals\\joblib\\_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\externals\\joblib\\parallel.py\", line 135, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\externals\\joblib\\parallel.py\", line 135, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\parallel\\learner.py\", line 125, in __call__\n    return getattr(self, self.job)()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\parallel\\learner.py\", line 338, in fit\n    self._predict(transformers)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\parallel\\learner.py\", line 357, in _predict\n    transformers, self.in_index)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\parallel\\learner.py\", line 381, in _score_preds\n    scores = self.scorer(self.estimator, xtemp, ytemp)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\externals\\sklearn\\scorer.py\", line 98, in __call__\n    **self._kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\metrics\\metrics.py\", line 41, in rmse\n    z = y - p\nTypeError: unsupported operand type(s) for -: 'str' and 'str'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\externals\\joblib\\_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nmlens.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nTypeError                                          Tue Jun 12 12:07:58 2018\nPID: 3556                 Python 3.6.5: C:\\ProgramData\\Anaconda3\\python.exe\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\externals\\joblib\\parallel.py in __call__(self=<mlens.externals.joblib.parallel.BatchedCalls object>)\n    130     def __init__(self, iterator_slice):\n    131         self.items = list(iterator_slice)\n    132         self._size = len(self.items)\n    133 \n    134     def __call__(self):\n--> 135         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<mlens.parallel.learner.EvalSubLearner object>, (), {})]\n    136 \n    137     def __len__(self):\n    138         return self._size\n    139 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    130     def __init__(self, iterator_slice):\n    131         self.items = list(iterator_slice)\n    132         self._size = len(self.items)\n    133 \n    134     def __call__(self):\n--> 135         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <mlens.parallel.learner.EvalSubLearner object>\n        args = ()\n        kwargs = {}\n    136 \n    137     def __len__(self):\n    138         return self._size\n    139 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\parallel\\learner.py in __call__(self=<mlens.parallel.learner.EvalSubLearner object>)\n    120         else:\n    121             self.processing_index = ''\n    122 \n    123     def __call__(self):\n    124         \"\"\"Launch job\"\"\"\n--> 125         return getattr(self, self.job)()\n        self = <mlens.parallel.learner.EvalSubLearner object>\n        self.job = 'fit'\n    126 \n    127     def fit(self, path=None):\n    128         \"\"\"Fit sub-learner\"\"\"\n    129         if path is None:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\parallel\\learner.py in fit(self=<mlens.parallel.learner.EvalSubLearner object>, path=r'C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\1\\.mlens_tmp_cache_fg7ti_qu\\task_0')\n    333         if self.scorer is None:\n    334             raise ValueError(\"Cannot generate CV-scores without a scorer\")\n    335         t0 = time()\n    336         transformers = self._load_preprocess(path)\n    337         self._fit(transformers)\n--> 338         self._predict(transformers)\n        self._predict = <bound method EvalSubLearner._predict of <mlens.parallel.learner.EvalSubLearner object>>\n        transformers = None\n    339 \n    340         o = IndexedEstimator(estimator=self.estimator,\n    341                              name=self.name_index,\n    342                              index=self.index,\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\parallel\\learner.py in _predict(self=<mlens.parallel.learner.EvalSubLearner object>, transformers=None, score_preds=None)\n    352 \n    353     def _predict(self, transformers, score_preds=None):\n    354         \"\"\"Sub-routine to with sublearner\"\"\"\n    355         # Train set\n    356         self.train_score_, self.train_pred_time_ = self._score_preds(\n--> 357             transformers, self.in_index)\n        transformers = None\n        self.in_index = ((85764, 171527),)\n    358 \n    359         # Validation set\n    360         self.test_score_, self.test_pred_time_ = self._score_preds(\n    361             transformers, self.out_index)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\parallel\\learner.py in _score_preds(self=<mlens.parallel.learner.EvalSubLearner object>, transformers=None, index=((85764, 171527),))\n    376                     \"Scoring failed. Setting error score %r.\"\n    377                     \"Details:\\n%r\" % (self.error_score, exc),\n    378                     FitFailedWarning)\n    379                 scores = self.error_score\n    380         else:\n--> 381             scores = self.scorer(self.estimator, xtemp, ytemp)\n        scores = undefined\n        self.scorer = make_scorer(rmse)\n        self.estimator = LGBMClassifier(boosting_type='gbdt', class_weigh...bsample_for_bin=200000,\n        subsample_freq=1)\n        xtemp = array([[-0.64711261,  1.72853073,  0.44659044, .... -0.62177941,\n        -0.61905645,  0.60391137]])\n        ytemp = array(['1010', '1019', '1010', ..., '100901', '1019', '1007676'],\n      dtype=object)\n    382         pred_time = time() - t0\n    383 \n    384         return scores, pred_time\n    385 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\externals\\sklearn\\scorer.py in __call__(self=make_scorer(rmse), estimator=LGBMClassifier(boosting_type='gbdt', class_weigh...bsample_for_bin=200000,\n        subsample_freq=1), X=array([[-0.64711261,  1.72853073,  0.44659044, .... -0.62177941,\n        -0.61905645,  0.60391137]]), y_true=array(['1010', '1019', '1010', ..., '100901', '1019', '1007676'],\n      dtype=object), sample_weight=None)\n     93             return self._sign * self._score_func(y_true, y_pred,\n     94                                                  sample_weight=sample_weight,\n     95                                                  **self._kwargs)\n     96         else:\n     97             return self._sign * self._score_func(y_true, y_pred,\n---> 98                                                  **self._kwargs)\n        self._kwargs = {}\n     99 \n    100 \n    101 class _ProbaScorer(_BaseScorer):\n    102     def __call__(self, clf, X, y, sample_weight=None):\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\metrics\\metrics.py in rmse(y=array(['1010', '1019', '1010', ..., '100901', '1019', '1007676'],\n      dtype=object), p=array(['1010', '1019', '1010', ..., '100901', '1019', '1007676'],\n      dtype=object))\n     36     Returns\n     37     -------\n     38     z: float\n     39         root mean squared error.\n     40     \"\"\"\n---> 41     z = y - p\n        z = undefined\n        y = array(['1010', '1019', '1010', ..., '100901', '1019', '1007676'],\n      dtype=object)\n        p = array(['1010', '1019', '1010', ..., '100901', '1019', '1007676'],\n      dtype=object)\n     42     return np.sqrt(np.mean(np.multiply(z, z)))\n     43 \n     44 \n     45 def mape(y, p):\n\nTypeError: unsupported operand type(s) for -: 'str' and 'str'\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    702\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 703\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    704\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nTypeError                                          Tue Jun 12 12:07:58 2018\nPID: 3556                 Python 3.6.5: C:\\ProgramData\\Anaconda3\\python.exe\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\externals\\joblib\\parallel.py in __call__(self=<mlens.externals.joblib.parallel.BatchedCalls object>)\n    130     def __init__(self, iterator_slice):\n    131         self.items = list(iterator_slice)\n    132         self._size = len(self.items)\n    133 \n    134     def __call__(self):\n--> 135         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<mlens.parallel.learner.EvalSubLearner object>, (), {})]\n    136 \n    137     def __len__(self):\n    138         return self._size\n    139 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    130     def __init__(self, iterator_slice):\n    131         self.items = list(iterator_slice)\n    132         self._size = len(self.items)\n    133 \n    134     def __call__(self):\n--> 135         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <mlens.parallel.learner.EvalSubLearner object>\n        args = ()\n        kwargs = {}\n    136 \n    137     def __len__(self):\n    138         return self._size\n    139 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\parallel\\learner.py in __call__(self=<mlens.parallel.learner.EvalSubLearner object>)\n    120         else:\n    121             self.processing_index = ''\n    122 \n    123     def __call__(self):\n    124         \"\"\"Launch job\"\"\"\n--> 125         return getattr(self, self.job)()\n        self = <mlens.parallel.learner.EvalSubLearner object>\n        self.job = 'fit'\n    126 \n    127     def fit(self, path=None):\n    128         \"\"\"Fit sub-learner\"\"\"\n    129         if path is None:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\parallel\\learner.py in fit(self=<mlens.parallel.learner.EvalSubLearner object>, path=r'C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\1\\.mlens_tmp_cache_fg7ti_qu\\task_0')\n    333         if self.scorer is None:\n    334             raise ValueError(\"Cannot generate CV-scores without a scorer\")\n    335         t0 = time()\n    336         transformers = self._load_preprocess(path)\n    337         self._fit(transformers)\n--> 338         self._predict(transformers)\n        self._predict = <bound method EvalSubLearner._predict of <mlens.parallel.learner.EvalSubLearner object>>\n        transformers = None\n    339 \n    340         o = IndexedEstimator(estimator=self.estimator,\n    341                              name=self.name_index,\n    342                              index=self.index,\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\parallel\\learner.py in _predict(self=<mlens.parallel.learner.EvalSubLearner object>, transformers=None, score_preds=None)\n    352 \n    353     def _predict(self, transformers, score_preds=None):\n    354         \"\"\"Sub-routine to with sublearner\"\"\"\n    355         # Train set\n    356         self.train_score_, self.train_pred_time_ = self._score_preds(\n--> 357             transformers, self.in_index)\n        transformers = None\n        self.in_index = ((85764, 171527),)\n    358 \n    359         # Validation set\n    360         self.test_score_, self.test_pred_time_ = self._score_preds(\n    361             transformers, self.out_index)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\parallel\\learner.py in _score_preds(self=<mlens.parallel.learner.EvalSubLearner object>, transformers=None, index=((85764, 171527),))\n    376                     \"Scoring failed. Setting error score %r.\"\n    377                     \"Details:\\n%r\" % (self.error_score, exc),\n    378                     FitFailedWarning)\n    379                 scores = self.error_score\n    380         else:\n--> 381             scores = self.scorer(self.estimator, xtemp, ytemp)\n        scores = undefined\n        self.scorer = make_scorer(rmse)\n        self.estimator = LGBMClassifier(boosting_type='gbdt', class_weigh...bsample_for_bin=200000,\n        subsample_freq=1)\n        xtemp = array([[-0.64711261,  1.72853073,  0.44659044, .... -0.62177941,\n        -0.61905645,  0.60391137]])\n        ytemp = array(['1010', '1019', '1010', ..., '100901', '1019', '1007676'],\n      dtype=object)\n    382         pred_time = time() - t0\n    383 \n    384         return scores, pred_time\n    385 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\externals\\sklearn\\scorer.py in __call__(self=make_scorer(rmse), estimator=LGBMClassifier(boosting_type='gbdt', class_weigh...bsample_for_bin=200000,\n        subsample_freq=1), X=array([[-0.64711261,  1.72853073,  0.44659044, .... -0.62177941,\n        -0.61905645,  0.60391137]]), y_true=array(['1010', '1019', '1010', ..., '100901', '1019', '1007676'],\n      dtype=object), sample_weight=None)\n     93             return self._sign * self._score_func(y_true, y_pred,\n     94                                                  sample_weight=sample_weight,\n     95                                                  **self._kwargs)\n     96         else:\n     97             return self._sign * self._score_func(y_true, y_pred,\n---> 98                                                  **self._kwargs)\n        self._kwargs = {}\n     99 \n    100 \n    101 class _ProbaScorer(_BaseScorer):\n    102     def __call__(self, clf, X, y, sample_weight=None):\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\metrics\\metrics.py in rmse(y=array(['1010', '1019', '1010', ..., '100901', '1019', '1007676'],\n      dtype=object), p=array(['1010', '1019', '1010', ..., '100901', '1019', '1007676'],\n      dtype=object))\n     36     Returns\n     37     -------\n     38     z: float\n     39         root mean squared error.\n     40     \"\"\"\n---> 41     z = y - p\n        z = undefined\n        y = array(['1010', '1019', '1010', ..., '100901', '1019', '1007676'],\n      dtype=object)\n        p = array(['1010', '1019', '1010', ..., '100901', '1019', '1007676'],\n      dtype=object)\n     42     return np.sqrt(np.mean(np.multiply(z, z)))\n     43 \n     44 \n     45 def mape(y, p):\n\nTypeError: unsupported operand type(s) for -: 'str' and 'str'\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJoblibTypeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-d1258a45676a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m                    \u001b[1;34m'num_leaves'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m60\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                   \u001b[1;34m'n_estimators'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                   'min_child_weight': randint(30,60)}\n\u001b[0m\u001b[0;32m     16\u001b[0m          }\n\u001b[0;32m     17\u001b[0m       )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\model_selection\\model_selection.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, estimators, param_dicts, n_iter, preprocessing)\u001b[0m\n\u001b[0;32m    505\u001b[0m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset_job\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimators\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimators\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_dicts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 507\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    508\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\model_selection\\model_selection.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, job)\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m15\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mParallelEvaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmanager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m             \u001b[0mmanager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\parallel\\backend.py\u001b[0m in \u001b[0;36mprocess\u001b[1;34m(self, caller, case, X, y, path, **kwargs)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    855\u001b[0m             \u001b[0mcaller\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 856\u001b[1;33m             \u001b[0mcaller\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparallel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\model_selection\\model_selection.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, parallel, args, case)\u001b[0m\n\u001b[0;32m    150\u001b[0m                 \u001b[0mt1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'estimators'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparallel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dir'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'estimators'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\model_selection\\model_selection.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, case, parallel, args)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         parallel(delayed(subtask, not _threading)()\n\u001b[1;32m--> 174\u001b[1;33m                  for task in generator for subtask in task(args, inp))\n\u001b[0m\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    791\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    792\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 793\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    794\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    795\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    742\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    743\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 744\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    745\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJoblibTypeError\u001b[0m: JoblibTypeError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x0000018D63144F60, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\ProgramD...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x0000018D63144F60, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\ProgramD...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    122         except (RuntimeError, AssertionError):\n    123             old_loop = None\n    124         try:\n    125             self._setup_logging()\n    126             asyncio.set_event_loop(self.asyncio_loop)\n--> 127             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Win...EventLoop running=True closed=False debug=False>>\n    128         finally:\n    129             asyncio.set_event_loop(old_loop)\n    130 \n    131     def stop(self):\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py in run_forever(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n    417             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    418                                    finalizer=self._asyncgen_finalizer_hook)\n    419         try:\n    420             events._set_running_loop(self)\n    421             while True:\n--> 422                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_Windo...EventLoop running=True closed=False debug=False>>\n    423                 if self._stopping:\n    424                     break\n    425         finally:\n    426             self._stopping = False\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py in _run_once(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n   1427                         logger.warning('Executing %s took %.3f seconds',\n   1428                                        _format_handle(handle), dt)\n   1429                 finally:\n   1430                     self._current_handle = None\n   1431             else:\n-> 1432                 handle._run()\n        handle._run = <bound method Handle._run of <Handle BaseAsyncIOLoop._handle_events(616, 1)>>\n   1433         handle = None  # Needed to break cycles when an exception occurs.\n   1434 \n   1435     def _set_coroutine_wrapper(self, enabled):\n   1436         try:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\asyncio\\events.py in _run(self=<Handle BaseAsyncIOLoop._handle_events(616, 1)>)\n    140             self._callback = None\n    141             self._args = None\n    142 \n    143     def _run(self):\n    144         try:\n--> 145             self._callback(*self._args)\n        self._callback = <bound method BaseAsyncIOLoop._handle_events of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (616, 1)\n    146         except Exception as exc:\n    147             cb = _format_callback_source(self._callback, self._args)\n    148             msg = 'Exception in callback {}'.format(cb)\n    149             context = {\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in _handle_events(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, fd=616, events=1)\n    112             self.writers.remove(fd)\n    113         del self.handlers[fd]\n    114 \n    115     def _handle_events(self, fd, events):\n    116         fileobj, handler_func = self.handlers[fd]\n--> 117         handler_func(fileobj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fileobj = <zmq.sugar.socket.Socket object>\n        events = 1\n    118 \n    119     def start(self):\n    120         try:\n    121             old_loop = asyncio.get_event_loop()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"from lightgbm import LGBMClassifier\\nfrom mlens.m...child_weight': randint(30,60)}\\n         }\\n      )\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 6, 12, 19, 6, 20, 827018, tzinfo=tzutc()), 'msg_id': 'd48e5cd8e07f4f5f8912272d67402421', 'msg_type': 'execute_request', 'session': '80fbe17cc4434eb688e083bb3a3ea874', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'd48e5cd8e07f4f5f8912272d67402421', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'80fbe17cc4434eb688e083bb3a3ea874']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"from lightgbm import LGBMClassifier\\nfrom mlens.m...child_weight': randint(30,60)}\\n         }\\n      )\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 6, 12, 19, 6, 20, 827018, tzinfo=tzutc()), 'msg_id': 'd48e5cd8e07f4f5f8912272d67402421', 'msg_type': 'execute_request', 'session': '80fbe17cc4434eb688e083bb3a3ea874', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'd48e5cd8e07f4f5f8912272d67402421', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'80fbe17cc4434eb688e083bb3a3ea874'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"from lightgbm import LGBMClassifier\\nfrom mlens.m...child_weight': randint(30,60)}\\n         }\\n      )\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 6, 12, 19, 6, 20, 827018, tzinfo=tzutc()), 'msg_id': 'd48e5cd8e07f4f5f8912272d67402421', 'msg_type': 'execute_request', 'session': '80fbe17cc4434eb688e083bb3a3ea874', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'd48e5cd8e07f4f5f8912272d67402421', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"from lightgbm import LGBMClassifier\\nfrom mlens.m...child_weight': randint(30,60)}\\n         }\\n      )\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"from lightgbm import LGBMClassifier\\nfrom mlens.m...child_weight': randint(30,60)}\\n         }\\n      )\"\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"from lightgbm import LGBMClassifier\\nfrom mlens.m...child_weight': randint(30,60)}\\n         }\\n      )\",), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"from lightgbm import LGBMClassifier\\nfrom mlens.m...child_weight': randint(30,60)}\\n         }\\n      )\",)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"from lightgbm import LGBMClassifier\\nfrom mlens.m...child_weight': randint(30,60)}\\n         }\\n      )\", store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = \"from lightgbm import LGBMClassifier\\nfrom mlens.m...child_weight': randint(30,60)}\\n         }\\n      )\"\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"from lightgbm import LGBMClassifier\\nfrom mlens.m...child_weight': randint(30,60)}\\n         }\\n      )\", store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-73-d1258a45676a>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 19027a5a208, executio...rue silent=False shell_futures=True> result=None>)\n   2904                     return True\n   2905 \n   2906             for i, node in enumerate(to_run_interactive):\n   2907                 mod = ast.Interactive([node])\n   2908                 code = compiler(mod, cell_name, \"single\")\n-> 2909                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x0000018D6A517420, file \"<ipython-input-73-d1258a45676a>\", line 10>\n        result = <ExecutionResult object at 19027a5a208, executio...rue silent=False shell_futures=True> result=None>\n   2910                     return True\n   2911 \n   2912             # Flush softspace\n   2913             if softspace(sys.stdout, 0):\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x0000018D6A517420, file \"<ipython-input-73-d1258a45676a>\", line 10>, result=<ExecutionResult object at 19027a5a208, executio...rue silent=False shell_futures=True> result=None>)\n   2958         outflag = True  # happens in more places, so it's easier as default\n   2959         try:\n   2960             try:\n   2961                 self.hooks.pre_run_code_hook()\n   2962                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2963                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x0000018D6A517420, file \"<ipython-input-73-d1258a45676a>\", line 10>\n        self.user_global_ns = {'BaggingClassifier': <class 'sklearn.ensemble.bagging.BaggingClassifier'>, 'Bio': <module 'Bio' from 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\Bio\\\\__init__.py'>, 'Evaluator': <class 'mlens.model_selection.model_selection.Evaluator'>, 'In': ['', 'import Bio\\nfrom Bio import SeqIO\\nimport numpy as...ver\\n\\nsub_data_root = data_root + \"sample01split/\"', \"def make_features(seq, sub_seq_bank, lable):\\n   ...s)\\n    df['lable'] = lable    \\n    return df\\n    \", 'df1 = pd.read_pickle(data_root + \"DNA_data1.pickle\")', 'df2 = pd.read_pickle(data_root + \"DNA_data2.pickle\")', 'print(df1.shape)\\nprint(df2.shape)\\ndf = pd.concat([df1, df2]) \\n\\ndf.head()', 'df.shape', \"with open(data_root + 'taxid.txt') as f:\\n    keys = f.readlines()\\nkeys = [x.strip() for x in keys] \", \"some_values = keys[:10]\\ndf1 = df.loc[df['lable'].isin(some_values)]\", 'df1.head(10)', 'gc.collect()\\ndf1.shape', \"get_ipython().run_line_magic('time', 'df1 =  convert_read_to_numb(df1, 4)')\", 'df1.head(10)', 'columns = list(df1.columns.values)\\nprint(type(co...alues[:, :-1]\\ny = df1.values[:, -1]\\n# df.head(20)', '# pickle_file = data_root + \"DNA_data.pickle\"\\n\\n#...o save data to\\', pickle_file, \\':\\', e)\\n#     raise', 'x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)', '# %time gbm = xgb.XGBClassifier(max_depth=4, n_e... n_jobs=32).fit(x_train, y_train)\\n# print(\"done\")', '# %time y_pred = gbm.predict(x_test)\\n# print(\"done\")', '# accuracy_score(y_test, y_pred)', \"# plot_confusion_matrix(confusion_matrix(y_test, y_pred), ['a','b'], normalize=True)\", ...], 'LGBMClassifier': <class 'lightgbm.sklearn.LGBMClassifier'>, 'OneVsRestClassifier': <class 'sklearn.multiclass.OneVsRestClassifier'>, 'Out': {5:                                                 ...AGTACGGCCACGTGGTCTTCACGCTCGAACCATTGCC...   741091, 6: (78731623, 2), 9:                                                 ...CGGAGTGAACATCAGGAACAGCAGTGACGCGAAGGTG...  1004901, 10: (214419, 2), 12:    0    1    2    3    4    5    6    7    8    ...  0    1    1  1004901  \n\n[10 rows x 257 columns], 35: RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), 37: 0.6566624691012546, 38: array([[ 447,    0,  235,    8,  159,   39,  441... 20,  396,    6,  277, 6681]],\n      dtype=int64), 60: RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), 62: 0.6550767221678093, ...}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'SVC': <class 'sklearn.svm.classes.SVC'>, 'SeqIO': <module 'Bio.SeqIO' from 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\Bio\\\\SeqIO\\\\__init__.py'>, ...}\n        self.user_ns = {'BaggingClassifier': <class 'sklearn.ensemble.bagging.BaggingClassifier'>, 'Bio': <module 'Bio' from 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\Bio\\\\__init__.py'>, 'Evaluator': <class 'mlens.model_selection.model_selection.Evaluator'>, 'In': ['', 'import Bio\\nfrom Bio import SeqIO\\nimport numpy as...ver\\n\\nsub_data_root = data_root + \"sample01split/\"', \"def make_features(seq, sub_seq_bank, lable):\\n   ...s)\\n    df['lable'] = lable    \\n    return df\\n    \", 'df1 = pd.read_pickle(data_root + \"DNA_data1.pickle\")', 'df2 = pd.read_pickle(data_root + \"DNA_data2.pickle\")', 'print(df1.shape)\\nprint(df2.shape)\\ndf = pd.concat([df1, df2]) \\n\\ndf.head()', 'df.shape', \"with open(data_root + 'taxid.txt') as f:\\n    keys = f.readlines()\\nkeys = [x.strip() for x in keys] \", \"some_values = keys[:10]\\ndf1 = df.loc[df['lable'].isin(some_values)]\", 'df1.head(10)', 'gc.collect()\\ndf1.shape', \"get_ipython().run_line_magic('time', 'df1 =  convert_read_to_numb(df1, 4)')\", 'df1.head(10)', 'columns = list(df1.columns.values)\\nprint(type(co...alues[:, :-1]\\ny = df1.values[:, -1]\\n# df.head(20)', '# pickle_file = data_root + \"DNA_data.pickle\"\\n\\n#...o save data to\\', pickle_file, \\':\\', e)\\n#     raise', 'x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)', '# %time gbm = xgb.XGBClassifier(max_depth=4, n_e... n_jobs=32).fit(x_train, y_train)\\n# print(\"done\")', '# %time y_pred = gbm.predict(x_test)\\n# print(\"done\")', '# accuracy_score(y_test, y_pred)', \"# plot_confusion_matrix(confusion_matrix(y_test, y_pred), ['a','b'], normalize=True)\", ...], 'LGBMClassifier': <class 'lightgbm.sklearn.LGBMClassifier'>, 'OneVsRestClassifier': <class 'sklearn.multiclass.OneVsRestClassifier'>, 'Out': {5:                                                 ...AGTACGGCCACGTGGTCTTCACGCTCGAACCATTGCC...   741091, 6: (78731623, 2), 9:                                                 ...CGGAGTGAACATCAGGAACAGCAGTGACGCGAAGGTG...  1004901, 10: (214419, 2), 12:    0    1    2    3    4    5    6    7    8    ...  0    1    1  1004901  \n\n[10 rows x 257 columns], 35: RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), 37: 0.6566624691012546, 38: array([[ 447,    0,  235,    8,  159,   39,  441... 20,  396,    6,  277, 6681]],\n      dtype=int64), 60: RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), 62: 0.6550767221678093, ...}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'SVC': <class 'sklearn.svm.classes.SVC'>, 'SeqIO': <module 'Bio.SeqIO' from 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\Bio\\\\SeqIO\\\\__init__.py'>, ...}\n   2964             finally:\n   2965                 # Reset our crash handler in place\n   2966                 sys.excepthook = old_excepthook\n   2967         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\Administrator\\Repos\\Microbiomics\\<ipython-input-73-d1258a45676a> in <module>()\n     10 evl.fit(x_train, y_train, [('model', LGBMClassifier(nthread=-1))],\n     11          {'model':\n     12                   {'learning_rate': uniform(0.02,0.04),\n     13                    'num_leaves': randint(50, 60),\n     14                   'n_estimators': randint(150,200),\n---> 15                   'min_child_weight': randint(30,60)}\n     16          }\n     17       )\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\model_selection\\model_selection.py in fit(self=<mlens.model_selection.model_selection.Evaluator object>, X=array([[-0.64711261, -0.67223719, -0.74219387, .... -0.62177941,\n        -0.61905645,  0.60391137]]), y=array(['1004901', '1017', '1017', ..., '100901', '1019', '1007676'],\n      dtype=object), estimators=[('model', LGBMClassifier(boosting_type='gbdt', class_weigh...=1.0, subsample_for_bin=200000, subsample_freq=1))], param_dicts={'model': {'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object>, 'min_child_weight': <scipy.stats._distn_infrastructure.rv_frozen object>, 'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object>, 'num_leaves': <scipy.stats._distn_infrastructure.rv_frozen object>}}, n_iter=2, preprocessing=None)\n    502             class instance with stored estimator evaluation results in\n    503             the ``results`` attribute.\n    504         \"\"\"\n    505         job = set_job(estimators, preprocessing)\n    506         self._initialize(job, estimators, preprocessing, param_dicts, n_iter)\n--> 507         self._fit(X, y, job)\n        self._fit = <bound method BaseEval._fit of <mlens.model_selection.model_selection.Evaluator object>>\n        X = array([[-0.64711261, -0.67223719, -0.74219387, .... -0.62177941,\n        -0.61905645,  0.60391137]])\n        y = array(['1004901', '1017', '1017', ..., '100901', '1019', '1007676'],\n      dtype=object)\n        job = 'evaluate'\n    508         self._get_results()\n    509         return self\n    510 \n    511     def _initialize(self, job, estimators, preprocessing, param_dicts, n_iter):\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\model_selection\\model_selection.py in _fit(self=<mlens.model_selection.model_selection.Evaluator object>, X=array([[-0.64711261, -0.67223719, -0.74219387, .... -0.62177941,\n        -0.61905645,  0.60391137]]), y=array(['1004901', '1017', '1017', ..., '100901', '1019', '1007676'],\n      dtype=object), job='evaluate')\n    175 \n    176     def _fit(self, X, y, job):\n    177         X, y = check_inputs(X, y, self.array_check)\n    178         verbose = max(self.verbose - 2, 0) if self.verbose < 15 else 0\n    179         with ParallelEvaluation(self.backend, self.n_jobs, verbose) as manager:\n--> 180             manager.process(self, job, X, y)\n        manager.process = <bound method ParallelEvaluation.process of <mlens.parallel.backend.ParallelEvaluation object>>\n        self = <mlens.model_selection.model_selection.Evaluator object>\n        job = 'evaluate'\n        X = array([[-0.64711261, -0.67223719, -0.74219387, .... -0.62177941,\n        -0.61905645,  0.60391137]])\n        y = array(['1004901', '1017', '1017', ..., '100901', '1019', '1007676'],\n      dtype=object)\n    181 \n    182     def collect(self, path, case):\n    183         \"\"\"Collect cache estimators\"\"\"\n    184         if case == 'transformers':\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\parallel\\backend.py in process(self=<mlens.parallel.backend.ParallelEvaluation object>, caller=<mlens.model_selection.model_selection.Evaluator object>, case='evaluate', X=array([[-0.64711261, -0.67223719, -0.74219387, .... -0.62177941,\n        -0.61905645,  0.60391137]]), y=array(['1004901', '1017', '1017', ..., '100901', '1019', '1007676'],\n      dtype=object), path=None, **kwargs={})\n    851         with Parallel(n_jobs=self.n_jobs, temp_folder=tf, max_nbytes=None,\n    852                       mmap_mode='w+', verbose=self.verbose,\n    853                       backend=self.backend) as parallel:\n    854 \n    855             caller.indexer.fit(self.job.predict_in, self.job.targets, self.job.job)\n--> 856             caller(parallel, self.job.args(**kwargs), case)\n        caller = <mlens.model_selection.model_selection.Evaluator object>\n        parallel = Parallel(n_jobs=-1)\n        self.job.args = <bound method Job.args of <mlens.parallel.backend.Job object>>\n        kwargs = {}\n        case = 'evaluate'\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\model_selection\\model_selection.py in __call__(self=<mlens.model_selection.model_selection.Evaluator object>, parallel=Parallel(n_jobs=-1), args={'auxiliary': {'P': None, 'X': memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645,  0.60391137]]), 'y': array(['1004901', '1017', '1017', ..., '100901', '1019', '1007676'],\n      dtype=object)}, 'dir': r'C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\1\\.mlens_tmp_cache_fg7ti_qu\\task_0', 'job': 'fit', 'main': {'P': None, 'X': memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645,  0.60391137]]), 'y': array(['1004901', '1017', '1017', ..., '100901', '1019', '1007676'],\n      dtype=object)}}, case='evaluate')\n    147         if 'evaluate' in case:\n    148             if self.verbose >= 2:\n    149                 safe_print(self._print_eval_start(), file=f)\n    150                 t1 = time()\n    151 \n--> 152             self._run('estimators', parallel, args)\n        self._run = <bound method BaseEval._run of <mlens.model_selection.model_selection.Evaluator object>>\n        parallel = Parallel(n_jobs=-1)\n        args = {'auxiliary': {'P': None, 'X': memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645,  0.60391137]]), 'y': array(['1004901', '1017', '1017', ..., '100901', '1019', '1007676'],\n      dtype=object)}, 'dir': r'C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\1\\.mlens_tmp_cache_fg7ti_qu\\task_0', 'job': 'fit', 'main': {'P': None, 'X': memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645,  0.60391137]]), 'y': array(['1004901', '1017', '1017', ..., '100901', '1019', '1007676'],\n      dtype=object)}}\n    153             self.collect(args['dir'], 'estimators')\n    154 \n    155             if self.verbose >= 2:\n    156                 print_time(t1, '{:<13} done'.format('Evaluation'), file=f)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\model_selection\\model_selection.py in _run(self=<mlens.model_selection.model_selection.Evaluator object>, case='estimators', parallel=Parallel(n_jobs=-1), args={'auxiliary': {'P': None, 'X': memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645,  0.60391137]]), 'y': array(['1004901', '1017', '1017', ..., '100901', '1019', '1007676'],\n      dtype=object)}, 'dir': r'C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\1\\.mlens_tmp_cache_fg7ti_qu\\task_0', 'job': 'fit', 'main': {'P': None, 'X': memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645,  0.60391137]]), 'y': array(['1004901', '1017', '1017', ..., '100901', '1019', '1007676'],\n      dtype=object)}})\n    169         else:\n    170             generator = self._learners\n    171             inp = 'main'\n    172 \n    173         parallel(delayed(subtask, not _threading)()\n--> 174                  for task in generator for subtask in task(args, inp))\n        generator = [EvalLearner(attr='predict', backend='threading',...True,\n      scorer=make_scorer(rmse), verbose=86), EvalLearner(attr='predict', backend='threading',...True,\n      scorer=make_scorer(rmse), verbose=86)]\n        args = {'auxiliary': {'P': None, 'X': memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645,  0.60391137]]), 'y': array(['1004901', '1017', '1017', ..., '100901', '1019', '1007676'],\n      dtype=object)}, 'dir': r'C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\1\\.mlens_tmp_cache_fg7ti_qu\\task_0', 'job': 'fit', 'main': {'P': None, 'X': memmap([[-0.64711261, -0.67223719, -0.74219387, ...-0.62177941,\n         -0.61905645,  0.60391137]]), 'y': array(['1004901', '1017', '1017', ..., '100901', '1019', '1007676'],\n      dtype=object)}}\n    175 \n    176     def _fit(self, X, y, job):\n    177         X, y = check_inputs(X, y, self.array_check)\n    178         verbose = max(self.verbose - 2, 0) if self.verbose < 15 else 0\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseEval._run.<locals>.<genexpr>>)\n    788             if pre_dispatch == \"all\" or n_jobs == 1:\n    789                 # The iterable was consumed all at once by the above for loop.\n    790                 # No need to wait for async callbacks to trigger to\n    791                 # consumption.\n    792                 self._iterating = False\n--> 793             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    794             # Make sure that we get a last message telling us we are done\n    795             elapsed_time = time.time() - self._start_time\n    796             self._print('Done %3i out of %3i | elapsed: %s finished',\n    797                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nTypeError                                          Tue Jun 12 12:07:58 2018\nPID: 3556                 Python 3.6.5: C:\\ProgramData\\Anaconda3\\python.exe\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\externals\\joblib\\parallel.py in __call__(self=<mlens.externals.joblib.parallel.BatchedCalls object>)\n    130     def __init__(self, iterator_slice):\n    131         self.items = list(iterator_slice)\n    132         self._size = len(self.items)\n    133 \n    134     def __call__(self):\n--> 135         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<mlens.parallel.learner.EvalSubLearner object>, (), {})]\n    136 \n    137     def __len__(self):\n    138         return self._size\n    139 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    130     def __init__(self, iterator_slice):\n    131         self.items = list(iterator_slice)\n    132         self._size = len(self.items)\n    133 \n    134     def __call__(self):\n--> 135         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <mlens.parallel.learner.EvalSubLearner object>\n        args = ()\n        kwargs = {}\n    136 \n    137     def __len__(self):\n    138         return self._size\n    139 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\parallel\\learner.py in __call__(self=<mlens.parallel.learner.EvalSubLearner object>)\n    120         else:\n    121             self.processing_index = ''\n    122 \n    123     def __call__(self):\n    124         \"\"\"Launch job\"\"\"\n--> 125         return getattr(self, self.job)()\n        self = <mlens.parallel.learner.EvalSubLearner object>\n        self.job = 'fit'\n    126 \n    127     def fit(self, path=None):\n    128         \"\"\"Fit sub-learner\"\"\"\n    129         if path is None:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\parallel\\learner.py in fit(self=<mlens.parallel.learner.EvalSubLearner object>, path=r'C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\1\\.mlens_tmp_cache_fg7ti_qu\\task_0')\n    333         if self.scorer is None:\n    334             raise ValueError(\"Cannot generate CV-scores without a scorer\")\n    335         t0 = time()\n    336         transformers = self._load_preprocess(path)\n    337         self._fit(transformers)\n--> 338         self._predict(transformers)\n        self._predict = <bound method EvalSubLearner._predict of <mlens.parallel.learner.EvalSubLearner object>>\n        transformers = None\n    339 \n    340         o = IndexedEstimator(estimator=self.estimator,\n    341                              name=self.name_index,\n    342                              index=self.index,\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\parallel\\learner.py in _predict(self=<mlens.parallel.learner.EvalSubLearner object>, transformers=None, score_preds=None)\n    352 \n    353     def _predict(self, transformers, score_preds=None):\n    354         \"\"\"Sub-routine to with sublearner\"\"\"\n    355         # Train set\n    356         self.train_score_, self.train_pred_time_ = self._score_preds(\n--> 357             transformers, self.in_index)\n        transformers = None\n        self.in_index = ((85764, 171527),)\n    358 \n    359         # Validation set\n    360         self.test_score_, self.test_pred_time_ = self._score_preds(\n    361             transformers, self.out_index)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\parallel\\learner.py in _score_preds(self=<mlens.parallel.learner.EvalSubLearner object>, transformers=None, index=((85764, 171527),))\n    376                     \"Scoring failed. Setting error score %r.\"\n    377                     \"Details:\\n%r\" % (self.error_score, exc),\n    378                     FitFailedWarning)\n    379                 scores = self.error_score\n    380         else:\n--> 381             scores = self.scorer(self.estimator, xtemp, ytemp)\n        scores = undefined\n        self.scorer = make_scorer(rmse)\n        self.estimator = LGBMClassifier(boosting_type='gbdt', class_weigh...bsample_for_bin=200000,\n        subsample_freq=1)\n        xtemp = array([[-0.64711261,  1.72853073,  0.44659044, .... -0.62177941,\n        -0.61905645,  0.60391137]])\n        ytemp = array(['1010', '1019', '1010', ..., '100901', '1019', '1007676'],\n      dtype=object)\n    382         pred_time = time() - t0\n    383 \n    384         return scores, pred_time\n    385 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\externals\\sklearn\\scorer.py in __call__(self=make_scorer(rmse), estimator=LGBMClassifier(boosting_type='gbdt', class_weigh...bsample_for_bin=200000,\n        subsample_freq=1), X=array([[-0.64711261,  1.72853073,  0.44659044, .... -0.62177941,\n        -0.61905645,  0.60391137]]), y_true=array(['1010', '1019', '1010', ..., '100901', '1019', '1007676'],\n      dtype=object), sample_weight=None)\n     93             return self._sign * self._score_func(y_true, y_pred,\n     94                                                  sample_weight=sample_weight,\n     95                                                  **self._kwargs)\n     96         else:\n     97             return self._sign * self._score_func(y_true, y_pred,\n---> 98                                                  **self._kwargs)\n        self._kwargs = {}\n     99 \n    100 \n    101 class _ProbaScorer(_BaseScorer):\n    102     def __call__(self, clf, X, y, sample_weight=None):\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mlens\\metrics\\metrics.py in rmse(y=array(['1010', '1019', '1010', ..., '100901', '1019', '1007676'],\n      dtype=object), p=array(['1010', '1019', '1010', ..., '100901', '1019', '1007676'],\n      dtype=object))\n     36     Returns\n     37     -------\n     38     z: float\n     39         root mean squared error.\n     40     \"\"\"\n---> 41     z = y - p\n        z = undefined\n        y = array(['1010', '1019', '1010', ..., '100901', '1019', '1007676'],\n      dtype=object)\n        p = array(['1010', '1019', '1010', ..., '100901', '1019', '1007676'],\n      dtype=object)\n     42     return np.sqrt(np.mean(np.multiply(z, z)))\n     43 \n     44 \n     45 def mape(y, p):\n\nTypeError: unsupported operand type(s) for -: 'str' and 'str'\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from mlens.model_selection import Evaluator\n",
    "from mlens.metrics import rmse, make_scorer\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "\n",
    "scorer = make_scorer(rmse)\n",
    "\n",
    "evl = Evaluator(scorer, n_jobs=-1, backend='multiprocessing', verbose=100)\n",
    "evl.fit(x_train, y_train, [('model', LGBMClassifier(nthread=-1))],\n",
    "         {'model':\n",
    "                  {'learning_rate': uniform(0.02,0.04),\n",
    "                   'num_leaves': randint(50, 60),\n",
    "                  'n_estimators': randint(150,200),\n",
    "                  'min_child_weight': randint(30,60)}\n",
    "         }\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time y_pred = evl.predict(x_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
