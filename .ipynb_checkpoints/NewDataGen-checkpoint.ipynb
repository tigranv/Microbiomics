{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Bio\n",
    "from Bio import SeqIO\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import pandas as pd \n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from itertools import product\n",
    "import random\n",
    "from six.moves import cPickle as pickle\n",
    "import xgboost as xgb\n",
    "from Bio.SeqIO.FastaIO import SimpleFastaParser\n",
    "import gc\n",
    "\n",
    "\n",
    "# data_root = \"C:\\\\Users\\\\Tigran PC\\\\Desktop\\\\MicrobiomicsData\\\\data\\\\\" # notebook\n",
    "# data_root = \"/Users/tigran/Desktop/sbv/data/\" # imac\n",
    "data_root = \"C:\\\\Users\\\\Administrator\\\\Repos\\\\Microbiomics\\\\data\\\\\" # server\n",
    "\n",
    "sub_data_root = data_root + \"sample01split/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_cut(full_seq, sub_seq_len, overlap_coef):\n",
    "    cut_indexes = random.sample(range(0, len(full_seq)-sub_seq_len), int(overlap_coef * (len(full_seq))/sub_seq_len))\n",
    "    seq_list = np.array([full_seq[i:i+sub_seq_len] for i in cut_indexes])\n",
    "    seq_list = [k for k in seq_list if 'N' not in k]\n",
    "    return seq_list\n",
    "    \n",
    "    \n",
    "def make_arrays(nb_rows, nb_features):\n",
    "    if nb_rows:\n",
    "        dataset = np.ndarray((nb_rows, nb_features),  dtype=np.float32)\n",
    "    else:\n",
    "        dataset, labels = None, None\n",
    "    return dataset\n",
    "\n",
    "def make_features(seq_list, sub_seq_bank):\n",
    "    features_list  = make_arrays(len(seq_list), len(sub_seq_bank))\n",
    "    for i, seq in enumerate(seq_list):    \n",
    "        sub_seq_count = []\n",
    "        for sub_seq in sub_seq_bank:\n",
    "            sub_seq_count.append(seq.count(sub_seq))\n",
    "        features_list[i] = sub_seq_count\n",
    "    return features_list\n",
    "\n",
    "def make_data_frame(features, lable):\n",
    "    df = pd.DataFrame(features)\n",
    "    df['lable'] = lable    \n",
    "    return df\n",
    "\n",
    "def make_sub_seq_bank(initial_string, sub_seq_len):\n",
    "    return [''.join(tup) for tup in  list(set(product(set(initial_string), repeat = sub_seq_len)))]\n",
    "   \n",
    "    \n",
    "def make_data_from_long_seq_list(long_seq_list):\n",
    "    df_list = []\n",
    "    sub_seq_bank = make_sub_seq_bank('ACTG', 4)\n",
    "    for i, long_seq in enumerate(long_seq_list):\n",
    "        seq_list = random_cut(long_seq, 151, 1)\n",
    "        df_tmp = make_data_frame(make_features(seq_list, sub_seq_bank), i)\n",
    "        df_list.append(df_tmp)\n",
    "    return pd.concat(df_list)\n",
    "\n",
    "\n",
    "def concat_reads(data_dict, sep):    \n",
    "    keys = list(data_dict.keys())\n",
    "    for n, key in enumerate(keys):\n",
    "        myString = sep.join(data_dict[key] )\n",
    "        data_dict[key] = myString\n",
    "    return data_dict\n",
    "    \n",
    "def describe_dict(data_dict):\n",
    "    keys = list(data_dict.keys()) \n",
    "    for n, key in enumerate(keys):\n",
    "        print(\"Key {2}- |{0}|- {1} : \".format(key, len(data_dict[key]), n))  \n",
    "            \n",
    "            \n",
    "            \n",
    "    \n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "def create_data_dict(data_dict, sep):\n",
    "\n",
    "    keys = list(data_dict.keys())\n",
    "    c1 = 0\n",
    "    c2 = 0\n",
    "    for n, key in enumerate(keys):\n",
    "        if len(data_dict[key]) == 1:\n",
    "            c1 +=1\n",
    "            data_dict[key] = data_dict[key][0]\n",
    "        else:\n",
    "            c2 += 1\n",
    "            ordered_reads = data_dict[key]\n",
    "            ordered_reads.sort(key = len)\n",
    "            concated_seq = sep.join([ordered_reads[-1], ordered_reads[0]])\n",
    "            data_dict[key] = concated_seq\n",
    "    print(\"single\", c1)\n",
    "    print(\"paired\", c2)\n",
    "    return data_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7311\n",
      "--- 414.71595525741577 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "count = 0\n",
    "seq_dict ={}\n",
    "with open(data_root + \"kraken_sequences_filtered_1.fasta\") as in_handle:\n",
    "     for name, seq in SimpleFastaParser(in_handle):\n",
    "            count += 1\n",
    "            taxid = name.split(sep = \"|\")\n",
    "            seq_dict.setdefault(taxid[1],[]).append(seq)\n",
    "print(count)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single 1939\n",
      "paired 559\n"
     ]
    }
   ],
   "source": [
    "seq_dict = create_data_dict(seq_dict, 5*\"N\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2498"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seq_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = data_root + \"RefDB.pickle\"\n",
    "\n",
    "try:   \n",
    "    f = open(pickle_file, 'wb')\n",
    "    pickle.dump(seq_dict, f, protocol=2)\n",
    "    f.close()\n",
    "except Exception as e:\n",
    "    print('Unable to save data to', pickle_file, ':', e)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_data = seq_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "seq_keys = list(prob_data.keys())\n",
    "for key in seq_keys:\n",
    "    seq_list = random_cut(prob_data[key], 151, 1)\n",
    "    df_tmp = make_data_frame(seq_list, key)\n",
    "    df_list.append(df_tmp)\n",
    "df = pd.concat(df_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39365811.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_list\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-611ee89a8259>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_list' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78821722, 2)\n",
      "(78731622, 2)\n"
     ]
    }
   ],
   "source": [
    "columns = list(df.columns.values)\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "print(df.shape)\n",
    "df = df.drop_duplicates(subset=columns[:-1])\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>lable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TTACGACACCTGGTCGACGGTGTACAACCAGCTCGAGGGCACTTGG...</td>\n",
       "      <td>1768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GAACGGCCGCAGCTCGTCGATCACCCCGGTCAGCGCCCGCGTCTCC...</td>\n",
       "      <td>1751294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AGCCTATATTAAATTGCTACCGCCTGAAAAACGAGGAGCGGAGAAC...</td>\n",
       "      <td>189834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TGGTATTTCTCTGTATCAAAATTGGCGTTTTGATAATAATACGGGA...</td>\n",
       "      <td>1954172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GTAAAGGTCAGTACGGCCACGTGGTCTTCACGCTCGAACCATTGCC...</td>\n",
       "      <td>741091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0    lable\n",
       "0  TTACGACACCTGGTCGACGGTGTACAACCAGCTCGAGGGCACTTGG...     1768\n",
       "1  GAACGGCCGCAGCTCGTCGATCACCCCGGTCAGCGCCCGCGTCTCC...  1751294\n",
       "2  AGCCTATATTAAATTGCTACCGCCTGAAAAACGAGGAGCGGAGAAC...   189834\n",
       "3  TGGTATTTCTCTGTATCAAAATTGGCGTTTTGATAATAATACGGGA...  1954172\n",
       "4  GTAAAGGTCAGTACGGCCACGTGGTCTTCACGCTCGAACCATTGCC...   741091"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()78731623"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39389753, 2)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_half = df.loc[df.shape[0]/2:]\n",
    "df_half.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = data_root + \"DNA_data2.pickle\"\n",
    "\n",
    "try:   \n",
    "    f = open(pickle_file, 'wb')\n",
    "    pickle.dump(df_half, f, pickle.HIGHEST_PROTOCOL)\n",
    "    f.close()\n",
    "except Exception as e:\n",
    "    print('Unable to save data to', pickle_file, ':', e)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
